{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "      <th>class label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in cm  petal length in cm  \\\n",
       "145                 6.7                3.0                 5.2   \n",
       "146                 6.3                2.5                 5.0   \n",
       "147                 6.5                3.0                 5.2   \n",
       "148                 6.2                3.4                 5.4   \n",
       "149                 5.9                3.0                 5.1   \n",
       "\n",
       "     petal width in cm     class label  \n",
       "145                2.3  Iris-virginica  \n",
       "146                1.9  Iris-virginica  \n",
       "147                2.0  Iris-virginica  \n",
       "148                2.3  Iris-virginica  \n",
       "149                1.8  Iris-virginica  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The link to the OG doc for LDA: https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/discriminant_analysis.py\n",
    "'''\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(4),\n",
    "                  ('sepal length in cm',\n",
    "                  'sepal width in cm',\n",
    "                  'petal length in cm',\n",
    "                  'petal width in cm', ))}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.io.parsers.read_csv(\n",
    "    filepath_or_buffer='https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',\n",
    "    header=None,\n",
    "    sep=',',\n",
    "    )\n",
    "df.columns = [l for i,l in sorted(feature_dict.items())] + ['class label']\n",
    "df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "df.tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.1  3.5  1.4  0.2] 150 [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df[['sepal length in cm','sepal width in cm','petal length in cm','petal width in cm']].values\n",
    "y = df['class label'].values\n",
    "\n",
    "\n",
    "\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(y)\n",
    "y = label_encoder.transform(y) + 1\n",
    "\n",
    "label_dict = {1: 'Setosa', 2: 'Versicolor', 3:'Virginica'}\n",
    "print(X[0],len(y),y)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# LDA\n",
    "sklearn_lda = LDA(n_components=3)\n",
    "X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "print(np.shape(X_lda_sklearn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_scikit_lda(X, title):\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    for label,marker,color in zip(\n",
    "        range(1,4),('^', 's', 'o'),('blue', 'red', 'green')):\n",
    "\n",
    "        plt.scatter(x=X[:,0][y == label],\n",
    "                    y=X[:,1][y == label] * -1, # flip the figure\n",
    "                    marker=marker,\n",
    "                    color=color,\n",
    "                    alpha=0.5,\n",
    "                    label=label_dict[label])\n",
    "\n",
    "    plt.xlabel('LD1')\n",
    "    plt.ylabel('LD2')\n",
    "\n",
    "    leg = plt.legend(loc='upper right', fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    plt.title(title)\n",
    "\n",
    "    # hide axis ticks\n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "    \n",
    "def plot_step_lda():\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    for label,marker,color in zip(\n",
    "        range(1,4),('^', 's', 'o'),('blue', 'red', 'green')):\n",
    "\n",
    "        plt.scatter(x=X_lda_sklearn[:,0].real[y == label],\n",
    "                y=X_lda_sklearn[:,1].real[y == label],\n",
    "                marker=marker,\n",
    "                color=color,\n",
    "                alpha=0.5,\n",
    "                label=label_dict[label]\n",
    "                )\n",
    "\n",
    "    plt.xlabel('LD1')\n",
    "    plt.ylabel('LD2')\n",
    "\n",
    "    leg = plt.legend(loc='upper right', fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    plt.title('LDA: Iris projection onto the first 2 linear discriminants')\n",
    "\n",
    "    # hide axis ticks\n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFEVRAFUIiqIoisP/AwXqgf4QcVYNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11817b7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_scikit_lda(X_lda_sklearn, title='Default LDA via scikit-learn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-19f21951efb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LDA_img_ratio_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_early_late_all.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#was '_view_all.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     )#,skiprows=10,nrows=10\n\u001b[1;32m     42\u001b[0m \u001b[0;31m#df=df.loc[df['Myr'] == 5 or df['Myr'] == 225]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "run='fg3_m_12'\n",
    "\n",
    "#LDA_img_ratio_fg3_m12_early_late_all.txt\n",
    "myr=5,200,180,185,190,195,205,210,220,225,230,240,250,260\n",
    "df2 = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all.txt',#was '_view_all.txt'\n",
    "    header=[0],\n",
    "    sep='\\t'\n",
    "    )#,skiprows=10,nrows=10\n",
    "#df=df.loc[df['Myr'] == 5 or df['Myr'] == 225]\n",
    "#df=df.loc[df['Myr'].isin([5,200,myr])]\n",
    "df2.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "df2.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "list_kins=['NONSCATTER_MILESHC_corrected','SCATTER_MILESHC_corrected','SCATTER','NONSCATTER']\n",
    "\n",
    "for i in range(len(list_kins)):\n",
    "   \n",
    "    add_on=list_kins[i]\n",
    "    print('run', add_on)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    feature_dict = {i:label for i,label in zip(\n",
    "                    range(9),\n",
    "                      ('Counter',\n",
    "                       'Myr',\n",
    "                      'Viewpoint',\n",
    "                      'Delta PA',\n",
    "                      'v_asym',\n",
    "                      's_asym',\n",
    "                      'K_tot',\n",
    "                      'resids',\n",
    "                      'i'))}\n",
    "\n",
    "    \n",
    "    df = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='PCA_kin_'+str(add_on)+'.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "    #df=df.loc[df['Myr'] == 5 or df['Myr'] == 225]\n",
    "    #df=df.loc[df['Myr'].isin([5,200,myr])]\n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['fiber']\n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "\n",
    "\n",
    "    merged = pd.merge(left=df2,right=df, on=['Myr','Viewpoint'])\n",
    "    if i==4:\n",
    "        print(merged)\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "    X = merged[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)', 'Sersic N', 'Shape Asymmetry',\n",
    "       'v_asym','s_asym']].values\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "    n_params=9\n",
    "\n",
    "\n",
    "    y = merged['class label'].values\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    sklearn_lda = LDA(priors=[0.8,0.2])\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    inter = sklearn_lda.intercept_\n",
    "    class_label = sklearn_lda.classes_\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(dec)#mean accuracy on the given test data and labels.\n",
    "    print(coef)\n",
    "    print(inter)\n",
    "    \n",
    "    from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "    \n",
    "    # QDA\n",
    "    sklearn_qda = QDA(priors=[0.8,0.2])\n",
    "    X_qda_sklearn = sklearn_qda.fit(X, y)\n",
    "    dec_qda = sklearn_qda.score(X,y)\n",
    "    \n",
    "    #coef = sklearn_qda.coef_\n",
    "    #inter = sklearn_qda.intercept_\n",
    "    print(dec_qda)#mean accuracy on the given test data and labels.\n",
    "\n",
    "    '''Make a histogram'''\n",
    "    from scipy import stats\n",
    "    import seaborn as sns\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    X_lda_1=[]\n",
    "    X_lda_2=[]\n",
    "    for j in range(len(X_lda_sklearn)):\n",
    "        if y[j] ==1:\n",
    "            X_lda_1.append(X_lda_sklearn[j][0])\n",
    "        else:\n",
    "            X_lda_2.append(X_lda_sklearn[j][0])\n",
    "    input_hist=X_lda_sklearn\n",
    "    \n",
    "    ax.hist(X_lda_1, label='NonMerger',  color=sns.xkcd_rgb[\"sky blue\"])\n",
    "    ax.hist(X_lda_2, label='Merger',  color=sns.xkcd_rgb[\"salmon\"])\n",
    "\n",
    "    '''for label,col in zip(range(1,4),  ('blue', 'red')):\n",
    "        input_hist=X_lda_sklearn\n",
    "        input_all=X_lda_sklearn\n",
    "        ax.hist(input_hist,\n",
    "                       color=col,\n",
    "                       label='class %s' %label_dict[label],\n",
    "                       alpha=0.5,)#bins=bins,\n",
    "        xt = plt.xticks()[0]  \n",
    "        xmin, xmax = -0.1,0.7#min(xt), max(xt)  \n",
    "        lnspc = np.linspace(xmin, xmax, len(input_hist))\n",
    "\n",
    "        # lets try the normal distribution first\n",
    "        m, s = stats.norm.fit(input_hist) # get mean and standard deviation  \n",
    "        pdf_g = stats.norm.pdf(lnspc, m, s) # now get theoretical values in our interval  \n",
    "        #ax.plot(lnspc, pdf_g,  color=col) # plot it\n",
    "\n",
    "\n",
    "\n",
    "    ylims = ax.get_ylim()\n",
    "\n",
    "    # plot annotation\n",
    "    leg = ax.legend(loc='upper right', fancybox=True, fontsize=8)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    ax.set_ylim([0, max(ylims)+2])'''\n",
    "\n",
    "    ax.set_xlabel('LD1', size=20)\n",
    "    #ax.set_title('Histogram #%s' %str(cnt+1), size=20)\n",
    "\n",
    "    # hide axis ticks\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\", labelsize=20)\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    ax.set_ylabel('Count', size=20)\n",
    "    \n",
    "    \n",
    "    plt.legend(loc=\"upper right\", fontsize=20)\n",
    "    #fig.tight_layout() \n",
    "    #plt.annotate(str(add_on), xy=(0.02,0.95),xycoords='axes fraction', size=20)\n",
    "    #plt.annotate('Mean Accuracy = '+str(dec), xy=(0.02,0.9),xycoords='axes fraction', size=20)\n",
    "    plt.show()\n",
    "    \n",
    "#    savefig('../MaNGA_Papers/Paper_I/Bayesian_Hist_'+str(run)+'.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCATTER -0.746634884\n",
      "NONSCATTER -0.69609521\n",
      "NONSCATTER_MILESHC_corrected -1.08988571\n",
      "SCATTER_MILESHC_corrected -0.81003349\n",
      "SCATTER 0.00265348228\n",
      "NONSCATTER -0.0078832\n",
      "NONSCATTER_MILESHC_corrected 0.02130446\n",
      "SCATTER_MILESHC_corrected -0.05767831\n",
      "SCATTER 4.05597665\n",
      "NONSCATTER 4.41491687\n",
      "NONSCATTER_MILESHC_corrected 4.17536727\n",
      "SCATTER_MILESHC_corrected 4.0528699\n",
      "SCATTER 6.91605057\n",
      "NONSCATTER 6.15332374\n",
      "NONSCATTER_MILESHC_corrected 6.55635034\n",
      "SCATTER_MILESHC_corrected 6.7326127\n",
      "SCATTER -3.6524561\n",
      "NONSCATTER -3.04132293\n",
      "NONSCATTER_MILESHC_corrected -3.41241524\n",
      "SCATTER_MILESHC_corrected -3.51244676\n",
      "SCATTER 0.68381577\n",
      "NONSCATTER 0.66753479\n",
      "NONSCATTER_MILESHC_corrected 1.34479293\n",
      "SCATTER_MILESHC_corrected 0.93881014\n",
      "SCATTER 0.785409412\n",
      "NONSCATTER 0.68833139\n",
      "NONSCATTER_MILESHC_corrected 0.55429217\n",
      "SCATTER_MILESHC_corrected 0.72658846\n",
      "SCATTER -0.769581706\n",
      "NONSCATTER -0.35440716\n",
      "NONSCATTER_MILESHC_corrected -1.72265744\n",
      "SCATTER_MILESHC_corrected -1.10888531\n",
      "SCATTER -0.0519556937\n",
      "NONSCATTER 0.80938349\n",
      "NONSCATTER_MILESHC_corrected 0.74637557\n",
      "SCATTER_MILESHC_corrected 0.27643255\n",
      "SCATTER vs SCATTER 0.0\n",
      "SCATTER vs NONSCATTER 8.420205374440267\n",
      "SCATTER vs NONSCATTER_MILESHC_corrected 9.87600044880428\n",
      "SCATTER vs SCATTER_MILESHC_corrected 3.7351776955937104\n",
      "NONSCATTER vs SCATTER 8.420205374440267\n",
      "Domain error NONSCATTER vs NONSCATTER\n",
      "NONSCATTER vs NONSCATTER 8.420205374440267\n",
      "NONSCATTER vs NONSCATTER_MILESHC_corrected 10.61252383355065\n",
      "NONSCATTER vs SCATTER_MILESHC_corrected 7.869113853338481\n",
      "NONSCATTER_MILESHC_corrected vs SCATTER 9.87600044880428\n",
      "NONSCATTER_MILESHC_corrected vs NONSCATTER 10.612523833550583\n",
      "NONSCATTER_MILESHC_corrected vs NONSCATTER_MILESHC_corrected 0.0\n",
      "NONSCATTER_MILESHC_corrected vs SCATTER_MILESHC_corrected 6.239535022517412\n",
      "SCATTER_MILESHC_corrected vs SCATTER 3.73517769559332\n",
      "SCATTER_MILESHC_corrected vs NONSCATTER 7.869113853338481\n",
      "SCATTER_MILESHC_corrected vs NONSCATTER_MILESHC_corrected 6.239535022517296\n",
      "SCATTER_MILESHC_corrected vs SCATTER_MILESHC_corrected 1.2074182697257333e-06\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "NONSCATTER=[-0.69609521, -0.0078832,   4.41491687,  6.15332374, -3.04132293,  0.66753479,\n",
    "   0.68833139, -0.35440716,  0.80938349]\n",
    "#A,C,S,sigma,G,A_S,n,vel,M20\n",
    "#1/10th\n",
    "SCATTER=[ -7.46634884e-01,   2.65348228e-03 ,  4.05597665e+00 ,  6.91605057e+00,\n",
    "   -3.65245610e+00 ,  6.83815770e-01 ,  7.85409412e-01,  -7.69581706e-01,\n",
    "   -5.19556937e-02]\n",
    "#A,C,S,A_S,vel,Gini,n,sigma,M20\n",
    "#1/10th\n",
    "SCATTER_MILESHC_corrected=[-0.81003349, -0.05767831 , 4.0528699  , 6.7326127,  -3.51244676,  0.93881014,\n",
    "   0.72658846, -1.10888531,  0.27643255]\n",
    "#A,C,S,vel,n,G,A_S,sigma,M20\n",
    "#OOM\n",
    "NONSCATTER_MILESHC_corrected=[-1.08988571,  0.02130446,  4.17536727,  6.55635034, -3.41241524,  1.34479293,\n",
    "   0.55429217, -1.72265744 , 0.74637557]\n",
    "#A,C,S,vel,n,Gini,sigma,A_S,M20\n",
    "#OOM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list_names=[SCATTER,NONSCATTER,NONSCATTER_MILESHC_corrected,SCATTER_MILESHC_corrected]\n",
    "act_names=['SCATTER','NONSCATTER','NONSCATTER_MILESHC_corrected','SCATTER_MILESHC_corrected']\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "for x in range(len(list_names)):\n",
    "    for y in range(len(list_names)):\n",
    "        try:\n",
    "            exp=math.degrees(math.acos(np.dot(list_names[x],list_names[y])/(np.linalg.norm(list_names[x])*np.linalg.norm(list_names[y]))))\n",
    "        except ValueError:\n",
    "            print('Domain error', act_names[x], 'vs', act_names[y])\n",
    "        if exp <90:\n",
    "            expnow=exp\n",
    "        else:\n",
    "            expnow=abs(180-exp)\n",
    "        print(act_names[x], 'vs', act_names[y], expnow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:376: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_scale mean [ 0.54507963 -1.77059676  3.28756292  0.20924545  0.11664004  1.40959046\n",
      "  0.22127319]\n",
      "std_scale var [0.05807988 0.39261558 0.82014827 0.18345029 0.06558203 0.73823792\n",
      " 0.19004855]\n",
      "input priors [0.9, 0.1]\n",
      "std_scale mean "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.54507963 -1.77059676  3.28756292  0.20924545  0.11664004  1.40959046\n",
      "  0.22127319]\n",
      "std_scale var [0.05807988 0.39261558 0.82014827 0.18345029 0.06558203 0.73823792\n",
      " 0.19004855]\n",
      "mean gini merger 0.5900150387723901\n",
      "mean gini nonmerger 0.49156564557035837\n",
      "mean gini merger std 0.7736828383039033\n",
      "mean gini nonmerger std -0.9213859256164681\n",
      "coefficients [[ 5.76387129 -1.85249314  1.2500407   5.01586697 -2.31987016  5.0070893\n",
      "   2.03218167]]\n",
      "Epoch 1/20\n",
      "192/192 [==============================] - 1s 5ms/step - loss: 0.5708 - acc: 0.8490  \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.2269 - acc: 0.9740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0870 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0502 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0356 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0289 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0246 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0220 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0201 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0180 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0165 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0156 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0139 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0124 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0115 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0095 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0090 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0077 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0071 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/20\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 0.0066 - acc: 0.9948\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "49/49 [==============================] - 0s 5ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "score [0.07361373214089141, 0.9795918379511152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:1247: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits [2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120]\n",
      "['Gini', 'Sersic N', 'Asymmetry (A)', 'Gini*n', 'A*n']\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=111.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "113\n",
      "114"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=112.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=113.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=114.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=115.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=116.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=117.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=118.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=119.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 110 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=120.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input passed into argument \"'y1'\"is not 1-dimensional.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4372c57e5ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgini_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_between\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgini_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgini_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgini_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgini_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'# k folds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Gini Mean and Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mfill_between\u001b[0;34m(x, y1, y2, where, interpolate, step, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3052\u001b[0m         ret = ax.fill_between(x, y1, y2=y2, where=where,\n\u001b[1;32m   3053\u001b[0m                               \u001b[0minterpolate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3054\u001b[0;31m                               **kwargs)\n\u001b[0m\u001b[1;32m   3055\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3056\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mfill_between\u001b[0;34m(self, x, y1, y2, where, interpolate, step, **kwargs)\u001b[0m\n\u001b[1;32m   5085\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5086\u001b[0m                 raise ValueError('Input passed into argument \"%r\"' % name +\n\u001b[0;32m-> 5087\u001b[0;31m                                  'is not 1-dimensional.')\n\u001b[0m\u001b[1;32m   5088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5089\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input passed into argument \"'y1'\"is not 1-dimensional."
     ]
    }
   ],
   "source": [
    "'''\n",
    "~~~\n",
    "Now just for the imaging part of it!\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "   # from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#example-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, target_names, title, cmap=plt.cm.Blues):\n",
    "    sns.set_style(\"dark\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    target_names=['Nonmerger','Merger']\n",
    "    plt.xticks(tick_marks, target_names)#, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('True label', size=20)\n",
    "    plt.xlabel('Predicted label', size=20)\n",
    "    \n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def lda_classify(v, levels, cutoffpoints):\n",
    "    for level, cutoff in zip(reversed(levels), reversed(cutoffpoints)):\n",
    "        if v > cutoff: return level\n",
    "    return levels[0]\n",
    "\n",
    "'''def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len((X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "        \n",
    "        print(( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ))\n",
    "\n",
    "        Xp = ( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det((X0)))) - (n_2-1)*(np.log(np.linalg.det((X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) '''\n",
    "\n",
    "def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len(np.cov(X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "\n",
    "        Xp = ( ((n_1-1)*np.cov(X0)) + ((n_2-1)*np.cov(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det(np.cov(X0)))) - (n_2-1)*(np.log(np.linalg.det(np.cov(X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) \n",
    "\n",
    "def plot_mean_and_CI(mean, lb, ub, color_mean=None, color_shading=None):\n",
    "        # plot the shaded range of the confidence intervals\n",
    "        plt.fill_between(range(mean.shape[0]), ub, lb,\n",
    "                         color=color_shading, alpha=.5)\n",
    "        # plot the mean on top\n",
    "        plt.plot(mean, color_mean)\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12_no_200', 'fg1_m13_no_200', 'fg3_m15_no_200', 'fg3_m1_10_no_200', 'all']\n",
    "inputs=[['Gini','Sersic N','Asymmetry (A)', 'Gini*n','A*n'],\n",
    "        ['Gini', 'M20','Concentration (C)','Asymmetry (A)','Clumpiness (S)','Sersic N','Shape Asymmetry','Gini*A_S', 'C*A_S', 'M20*S', 'C*A', 'M20*n'],\n",
    "       ['Gini','M20','Concentration (C)','Asymmetry (A)','Clumpiness (S)','Sersic N','Shape Asymmetry','Gini*C', 'M20*A_S', 'C*n', 'M20*A', 'A*A_S', 'Gini*A_S', 'C*S'],\n",
    "       ['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry','Gini*A_S', 'M20*A_S', 'M20*n', 'C*n', 'C*A', 'Gini*M20'],\n",
    "       ['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry','C*n', 'M20*A', 'Gini*C', 'Gini*A_S', 'Gini*n', 'C*S', 'A*n', 'C*A', 'M20*A_S', 'M20*n', 'C*A_S', 'n*A_S']]\n",
    "\n",
    "#list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "#'fg3_m12_comp_real','fg1_m13_comp_real','fg3_m15_comp_real','fg3_m1_10_comp_real']#,'fg3_m15_alliso','fg3_m1_10_alliso']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "add_noise='no'\n",
    "loop='yes'\n",
    "priors_list=[[0.9,0.1],[0.9,0.1],[0.7,0.3],[0.7,0.3],[0.75,0.25]]\n",
    "\n",
    "#list_runs=['fg3_m1_10']\n",
    "#priors_list=[[0.7,0.3]]\n",
    "\n",
    "\n",
    "gini_means_all=[]\n",
    "m20_means_all=[]\n",
    "color_means_all=[]\n",
    "A_means_all=[]\n",
    "A_S_means_all=[]\n",
    "C_means_all=[]\n",
    "n_means_all=[]\n",
    "S_means_all=[]\n",
    "\n",
    "gini_means_all_non=[]\n",
    "m20_means_all_non=[]\n",
    "color_means_all_non=[]\n",
    "A_means_all_non=[]\n",
    "A_S_means_all_non=[]\n",
    "C_means_all_non=[]\n",
    "n_means_all_non=[]\n",
    "S_means_all_non=[]\n",
    "\n",
    "colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"],sns.xkcd_rgb[\"black\"]]\n",
    "#colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"]]\n",
    "names=['q0.5_fg0.3','q0.333_fg0.1','q0.2_fg0.3_BT0.2','q0.1_fg0.3_BT0.2','All Combined']\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    if add_on=='all':\n",
    "        lists=['fg3_m1_10_alone', 'fg3_m15_alone', 'fg3_m12_alone', 'fg1_m13_alone']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "        #add_noise='yes'\n",
    "        '''\n",
    "        So the time covered differs for different simulations.\n",
    "        We want to retain this in the data.\n",
    "        Minor mergers are 3x as frequent.\n",
    "        Since galaxies merge on average w/i 1-2 Gyr a lot of this will be washed out.\n",
    "        Because of the frequency of most mergers a lot of this will be washed out meaning that\n",
    "        it is probably unrealistic to combine the simulations together.\n",
    "        But we do so anyway making sure we have 3x the number of minor mergers as major mergers.\n",
    "        So we are limited by the smallest sample size.\n",
    "        '''\n",
    "\n",
    "        lens=[]\n",
    "\n",
    "        for p in range(len(lists)):\n",
    "\n",
    "            add_on=lists[p]\n",
    "            run=lists[p]\n",
    "\n",
    "            df = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "            df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "            df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            '''index_list=[]\n",
    "            for j in range(len(df)):\n",
    "                if df[['class label']].values[j][0]==0:\n",
    "                    index_list.append(j)\n",
    "\n",
    "            df.drop(df.index[index_list], inplace=True)'''\n",
    "\n",
    "            counter=0\n",
    "\n",
    "            for j in range(len(df)):\n",
    "                \n",
    "                if df[['Myr']].values[counter][0]<40 and df[['Sep']].values[counter][0]==0.0 and df[['# Bulges']].values[counter][0]==1:#df[['Myr']].values[i][0]\n",
    "                    df.set_value(counter,'class label',0.0)\n",
    "                    df.drop(df.index[counter], inplace=True)\n",
    "                else:\n",
    "                    counter+=1\n",
    "\n",
    "            print(len(df))\n",
    "            lens.append(len(df))\n",
    "\n",
    "\n",
    "        print('lengths', lens, min(lens[0],lens[1])) \n",
    "        length=min(lens[0],lens[1])\n",
    "\n",
    "        names_df=['df1', 'df2', 'df3', 'df4']\n",
    "        dfs=[]\n",
    "\n",
    "        for p in range(len(lists)):\n",
    "\n",
    "            add_on=lists[p]\n",
    "            run=lists[p]\n",
    "\n",
    "            names_df[p] = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "            names_df[p].columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "            names_df[p].dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "            '''for j in range(len(names_df)):\n",
    "                if names_df[['class label']].values[j]<1:\n",
    "                    print(names_df[['Image']].values[j],names_df[['Myr']].values[j][0],names_df[['class label']].values[j])\n",
    "\n",
    "            '''\n",
    "\n",
    "            counter=0\n",
    "            OG_length=len(names_df[p])\n",
    "            for j in range(len(names_df[p])):\n",
    "                if names_df[p][['Myr']].values[j][0]<40 and names_df[p][['Sep']].values[j][0]==0.0 and names_df[p][['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "                    names_df[p].set_value(j,'class label',0)\n",
    "                        #names_df[p].drop(names_df[p].index[counter], inplace=True)\n",
    "                    \n",
    "            '''Now you need to drop the number off from the longest one'''\n",
    "            if add_on=='fg3_m12_alone' or add_on=='fg1_m13_alone':\n",
    "                length_limit=length/3\n",
    "            else:\n",
    "                length_limit=length\n",
    "\n",
    "            names_df[p].dropna(how=\"all\",inplace=True)\n",
    "\n",
    "            n_drop=int(len(names_df[p])-length_limit)\n",
    "            drop_indices = np.random.choice(names_df[p].index, n_drop, replace=False)\n",
    "            df_subset = names_df[p].drop(drop_indices)\n",
    "            print('LENGTH NOW', len(df_subset))\n",
    "            dfs.append(df_subset)\n",
    "\n",
    "        new_df=dfs[0].append(dfs[1]).append(dfs[2]).append(dfs[3]) \n",
    "\n",
    "        for j in range(len(new_df)):\n",
    "            if new_df[['class label']].values[j]<1:\n",
    "                print(new_df[['Image']].values[j],new_df[['Myr']].values[j][0],new_df[['class label']].values[j])\n",
    "\n",
    "\n",
    "        #These are the isolated galaxies:'LDA_img_ratio_statmorph_isolated.txt'\n",
    "        df = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_isolated_no_200.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "        df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "        df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "        new_df=new_df.append(df)\n",
    "\n",
    "        myr=[]\n",
    "        myr_non=[]\n",
    "        for j in range(len(new_df)):\n",
    "            if new_df[['class label']].values[j][0]==0.0:\n",
    "                myr_non.append(new_df[['Myr']].values[j][0])\n",
    "            else:\n",
    "                myr.append(new_df[['Myr']].values[j][0])\n",
    "\n",
    "        myr_non=sorted(list(set(myr_non)))\n",
    "        myr=sorted(list(set(myr)))\n",
    "        df=new_df\n",
    "        run='all'\n",
    "    else:\n",
    "        run=list_runs[i]\n",
    "\n",
    "        df = pd.io.parsers.read_table(\n",
    "            filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "            header=[0],\n",
    "            sep='\\t'\n",
    "            )#,skiprows=10,nrows=10\n",
    "            ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "        df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "        df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(len(df)):\n",
    "            if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "                df.set_value(j,'class label',0)\n",
    "        myr=[]\n",
    "        myr_non=[]\n",
    "        for j in range(len(df)):\n",
    "            if df[['class label']].values[j][0]==0.0:\n",
    "                myr_non.append(df[['Myr']].values[j][0])\n",
    "            else:\n",
    "                myr.append(df[['Myr']].values[j][0])\n",
    "\n",
    "        myr_non=sorted(list(set(myr_non)))\n",
    "        myr=sorted(list(set(myr)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.dropna(inplace=True) # to drop the empty line at file-end\n",
    "    #print(df)\n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    def gini_m20(row):\n",
    "        return row['Gini']*row['M20']\n",
    "    def gini_C(row):\n",
    "        return row['Gini']*row['Concentration (C)']\n",
    "    def gini_A(row):\n",
    "        return row['Gini']*row['Asymmetry (A)']\n",
    "    def gini_S(row):\n",
    "        return row['Gini']*row['Clumpiness (S)']\n",
    "    def gini_n(row):\n",
    "        return row['Gini']*row['Sersic N']\n",
    "    def gini_A_S(row):\n",
    "        return row['Gini']*row['Shape Asymmetry']\n",
    "    \n",
    "    def M20_C(row):\n",
    "        return row['M20']*row['Concentration (C)']\n",
    "    def M20_A(row):\n",
    "        return row['M20']*row['Asymmetry (A)']\n",
    "    def M20_S(row):\n",
    "        return row['M20']*row['Clumpiness (S)']\n",
    "    def M20_n(row):\n",
    "        return row['M20']*row['Sersic N']\n",
    "    def M20_A_S(row):\n",
    "        return row['M20']*row['Shape Asymmetry']\n",
    "    \n",
    "    def C_A(row):\n",
    "        return row['Concentration (C)']*row['Asymmetry (A)']\n",
    "    def C_S(row):\n",
    "        return row['Concentration (C)']*row['Clumpiness (S)']\n",
    "    def C_n(row):\n",
    "        return row['Concentration (C)']*row['Sersic N']\n",
    "    def C_A_S(row):\n",
    "        return row['Concentration (C)']*row['Shape Asymmetry']\n",
    "    \n",
    "    \n",
    "    def A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Clumpiness (S)']\n",
    "    def A_n(row):\n",
    "        return row['Asymmetry (A)']*row['Sersic N']\n",
    "    def A_A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def S_n(row):\n",
    "        return row['Clumpiness (S)']*row['Sersic N']\n",
    "    def S_A_S(row):\n",
    "        return row['Clumpiness (S)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def n_A_S(row):\n",
    "        return row['Sersic N']*row['Shape Asymmetry']\n",
    "    \n",
    "    df['Gini*M20'] = df.apply(gini_m20,axis=1)\n",
    "    df['Gini*C'] = df.apply(gini_C,axis=1)\n",
    "    df['Gini*A'] = df.apply(gini_A,axis=1)\n",
    "    df['Gini*S'] = df.apply(gini_S,axis=1)\n",
    "    df['Gini*n'] = df.apply(gini_n,axis=1)\n",
    "    df['Gini*A_S'] = df.apply(gini_A_S,axis=1)\n",
    "    \n",
    "    df['M20*C'] = df.apply(M20_C,axis=1)\n",
    "    df['M20*A'] = df.apply(M20_A,axis=1)\n",
    "    df['M20*S'] = df.apply(M20_S,axis=1)\n",
    "    df['M20*n'] = df.apply(M20_n,axis=1)\n",
    "    df['M20*A_S'] = df.apply(M20_A_S,axis=1)\n",
    "    \n",
    "    df['C*A'] = df.apply(C_A,axis=1)\n",
    "    df['C*S'] = df.apply(C_S,axis=1)\n",
    "    df['C*n'] = df.apply(C_n,axis=1)\n",
    "    df['C*A_S'] = df.apply(C_A_S,axis=1)\n",
    "    \n",
    "    df['A*S'] = df.apply(A_S,axis=1)\n",
    "    df['A*n'] = df.apply(A_n,axis=1)\n",
    "    df['A*A_S'] = df.apply(A_A_S,axis=1)\n",
    "    \n",
    "    df['S*n'] = df.apply(S_n,axis=1)\n",
    "    df['S*A_S'] = df.apply(S_A_S,axis=1)\n",
    "    \n",
    "    df['n*A_S'] = df.apply(n_A_S,axis=1)\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)','Clumpiness (S)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    #'Clumpiness (S)',\n",
    "    \n",
    "    \n",
    "    y = df['class label'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_nonmerg=[]\n",
    "    X_merg=[]\n",
    "    \n",
    "    for l in range(len(y)):\n",
    "        if y[l]==0:\n",
    "            X_nonmerg.append(X[l])\n",
    "        else:\n",
    "            X_merg.append(X[l])\n",
    "            \n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    print('std_scale mean', std_scale.mean_)\n",
    "    print('std_scale var', np.sqrt(std_scale.var_))\n",
    "    \n",
    "    \n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    \n",
    "    n_params=6\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    print('input priors', priors_list[i])\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    \n",
    "    \n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    \n",
    "    y = df['class label'].values\n",
    "    \n",
    "    \n",
    "    if add_noise=='yes':\n",
    "        '''\n",
    "        gini mean and std 0.5550252680173879 0.044777018337496165\n",
    "        m20 mean and std -1.9712343829804506 0.37871210199946886\n",
    "        C mean and std 3.5465035077152782 0.4881519277500404\n",
    "        A mean and std 0.09206940323506102 0.053844924631844704\n",
    "        S mean and std 0.10754825107906933 0.04718783593571886\n",
    "        A_S mean and std 0.131905632525 0.12206728280147515\n",
    "        n mean and std 1.7474 1.65464914861127\n",
    "        '''\n",
    "        noise_vec=np.array([0.045,0.379,0.488,0.054,0.047,1.655,0.122])\n",
    "        add=np.zeros((len(df), len(noise_vec)))\n",
    "        for j in range(len(df)):\n",
    "            \n",
    "            for k in range(len(noise_vec)):\n",
    "                if df[['class label']].values[j]==0:\n",
    "                    s = np.random.normal(0, noise_vec[k], 1)\n",
    "                    add[j,k]=s\n",
    "                else:\n",
    "                    s = np.random.normal(0, 0, 1)\n",
    "                    add[j,k]=s\n",
    "        X= df[['Gini','M20','Concentration (C)', 'Asymmetry (A)','Clumpiness (S)', 'Sersic N', 'Shape Asymmetry']].values+add\n",
    "    \n",
    "    else:\n",
    "        X= df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)','Sersic N', 'Shape Asymmetry']].values\n",
    "    \n",
    "    \n",
    "    '''Now I will make the actual plots of predictor space'''\n",
    "    \n",
    "\n",
    "\n",
    "    gini = {key:[] for key in myr}\n",
    "    m20 = {key:[] for key in myr}\n",
    "    \n",
    "    gini_std = {key:[] for key in myr}\n",
    "    m20_std = {key:[] for key in myr}\n",
    "\n",
    "    C = {key:[] for key in myr}\n",
    "    A = {key:[] for key in myr}\n",
    "    S = {key:[] for key in myr}\n",
    "\n",
    "    A_S = {key:[] for key in myr}\n",
    "    n = {key:[] for key in myr}\n",
    "\n",
    "    gini_non = {key:[] for key in myr_non}\n",
    "    m20_non = {key:[] for key in myr_non}\n",
    "    \n",
    "    gini_non_std = {key:[] for key in myr_non}\n",
    "    m20_non_std = {key:[] for key in myr_non}\n",
    "\n",
    "    C_non = {key:[] for key in myr_non}\n",
    "    A_non = {key:[] for key in myr_non}\n",
    "    S_non = {key:[] for key in myr_non}\n",
    "\n",
    "    n_non = {key:[] for key in myr_non}\n",
    "    A_S_non = {key:[] for key in myr_non}\n",
    "\n",
    "\n",
    "    print('std_scale mean', std_scale.mean_)\n",
    "    print('std_scale var', np.sqrt(std_scale.var_))\n",
    "\n",
    "    for l in range(len(df)):\n",
    "        if df[['class label']].values[l]==0:\n",
    "            \n",
    "            gini_non[df[['Myr']].values[l][0]].append(X[l,0])\n",
    "            m20_non[df[['Myr']].values[l][0]].append(X[l,1])\n",
    "            gini_non_std[df[['Myr']].values[l][0]].append((X[l,0]-std_scale.mean_[0])/np.sqrt(std_scale.var_[0]))\n",
    "            m20_non_std[df[['Myr']].values[l][0]].append((X[l,1]-std_scale.mean_[1])/np.sqrt(std_scale.var_[1]))\n",
    "            C_non[df[['Myr']].values[l][0]].append(X[l,2])\n",
    "            A_non[df[['Myr']].values[l][0]].append(X[l,3])\n",
    "            S_non[df[['Myr']].values[l][0]].append(X[l,4])\n",
    "            A_S_non[df[['Myr']].values[l][0]].append(X[l,6])\n",
    "            n_non[df[['Myr']].values[l][0]].append(X[l,5])\n",
    "            #print('concentration here', df[['Concentration (C)']].values[i][0])\n",
    "        else:\n",
    "            gini[df[['Myr']].values[l][0]].append(X[l,0])\n",
    "            m20[df[['Myr']].values[l][0]].append(X[l,1])\n",
    "            gini_std[df[['Myr']].values[l][0]].append((X[l,0]-std_scale.mean_[0])/np.sqrt(std_scale.var_[0]))\n",
    "            m20_std[df[['Myr']].values[l][0]].append((X[l,1]-std_scale.mean_[1])/np.sqrt(std_scale.var_[1]))\n",
    "            C[df[['Myr']].values[l][0]].append(X[l,2])\n",
    "            A[df[['Myr']].values[l][0]].append(X[l,3])\n",
    "            S[df[['Myr']].values[l][0]].append(X[l,4])\n",
    "            A_S[df[['Myr']].values[l][0]].append(X[l,6])\n",
    "            n[df[['Myr']].values[l][0]].append(X[l,5])\n",
    "    G_list_all_non=[]\n",
    "    M20_list_all_non=[]\n",
    "    G_list_all_non_std=[]\n",
    "    M20_list_all_non_std=[]\n",
    "    A_list_all_non=[]\n",
    "    C_list_all_non=[]\n",
    "    S_list_all_non=[]\n",
    "    A_S_list_all_non=[]\n",
    "    n_list_all_non=[]\n",
    "    color_list_all_non=[]\n",
    "    color_list_all_non_std=[]\n",
    "    \n",
    "\n",
    "    G_list_all=[]\n",
    "    M20_list_all=[]\n",
    "    G_list_all_std=[]\n",
    "    M20_list_all_std=[]\n",
    "    A_list_all=[]\n",
    "    C_list_all=[]\n",
    "    S_list_all=[]\n",
    "    A_S_list_all=[]\n",
    "    n_list_all=[]\n",
    "    color_list_all=[]\n",
    "    color_list_all_std=[]\n",
    "    \n",
    "    gini_means_non=[]\n",
    "    m20_means_non=[]\n",
    "    color_means_non=[]\n",
    "    A_means_non=[]\n",
    "    A_S_means_non=[]\n",
    "    C_means_non=[]\n",
    "    n_means_non=[]\n",
    "    S_means_non=[]\n",
    "    \n",
    "    for k in range(len(gini_non_std)):\n",
    "        for z in range(len(gini_non_std[myr_non[k]])):\n",
    "            M20_list_all_non_std.append((m20_non_std[myr_non[k]][z]))\n",
    "            G_list_all_non_std.append((gini_non_std[myr_non[k]][z]))\n",
    "            color_list_all_non_std.append(myr_non[k]/100)\n",
    "    for k in range(len(gini_non)):\n",
    "        for z in range(len(gini_non[myr_non[k]])):\n",
    "            M20_list_all_non.append((m20_non[myr_non[k]][z]))\n",
    "            G_list_all_non.append((gini_non[myr_non[k]][z]))\n",
    "            C_list_all_non.append((C_non[myr_non[k]][z]))\n",
    "            A_list_all_non.append((A_non[myr_non[k]][z]))\n",
    "            S_list_all_non.append((S_non[myr_non[k]][z]))\n",
    "            n_list_all_non.append((n_non[myr_non[k]][z]))\n",
    "            A_S_list_all_non.append((A_S_non[myr_non[k]][z]))\n",
    "            color_list_all_non.append(myr_non[k]/100)\n",
    "        A_means_non.append(np.mean(A_non[myr_non[k]][:]))\n",
    "        A_S_means_non.append(np.mean(A_S_non[myr_non[k]][:]))\n",
    "        color_means_non.append((myr_non[k]/100))\n",
    "        gini_means_non.append(np.mean(gini_non[myr_non[k]][:]))\n",
    "        m20_means_non.append(np.mean(m20_non[myr_non[k]][:]))\n",
    "        C_means_non.append(np.mean(C_non[myr_non[k]][:]))\n",
    "        n_means_non.append(np.mean(n_non[myr_non[k]][:]))\n",
    "        S_means_non.append(np.mean(S_non[myr_non[k]][:]))\n",
    "    gini_means=[]\n",
    "    m20_means=[]\n",
    "    color_means=[]\n",
    "    A_means=[]\n",
    "    A_S_means=[]\n",
    "    n_means=[]\n",
    "    C_means=[]\n",
    "    S_means=[]\n",
    "    for k in range(len(gini)):\n",
    "        for z in range(len(gini[myr[k]])):\n",
    "            M20_list_all.append((m20[myr[k]][z]))\n",
    "            G_list_all.append((gini[myr[k]][z]))\n",
    "            \n",
    "            C_list_all.append((C[myr[k]][z]))\n",
    "            A_list_all.append((A[myr[k]][z]))\n",
    "            S_list_all.append((S[myr[k]][z]))\n",
    "            n_list_all.append((n[myr[k]][z]))\n",
    "            A_S_list_all.append((A_S[myr[k]][z]))\n",
    "            color_list_all.append((myr[k]/100))#/((t_p-t_e)/2+t_e))\n",
    "        A_means.append(np.mean(A[myr[k]][:]))\n",
    "        A_S_means.append(np.mean(A_S[myr[k]][:]))\n",
    "        color_means.append((myr[k]/100))\n",
    "        gini_means.append(np.mean(gini[myr[k]][:]))\n",
    "        m20_means.append(np.mean(m20[myr[k]][:]))\n",
    "        C_means.append(np.mean(C[myr[k]][:]))\n",
    "        n_means.append(np.mean(n[myr[k]][:]))\n",
    "        S_means.append(np.mean(S[myr[k]][:]))\n",
    "    for k in range(len(gini_std)):\n",
    "        for z in range(len(gini_std[myr[k]])):\n",
    "            M20_list_all_std.append((m20_std[myr[k]][z]))\n",
    "            G_list_all_std.append((gini_std[myr[k]][z]))\n",
    "            color_list_all_std.append((myr[k]/100))\n",
    "    gini_means_all.append(gini_means)\n",
    "    m20_means_all.append(m20_means)\n",
    "    color_means_all.append(color_means)\n",
    "    A_means_all.append(A_means)\n",
    "    A_S_means_all.append(A_S_means)\n",
    "    C_means_all.append(C_means)\n",
    "    n_means_all.append(n_means)\n",
    "    S_means_all.append(S_means)\n",
    "    \n",
    "    gini_means_all_non.append(gini_means_non)\n",
    "    m20_means_all_non.append(m20_means_non)\n",
    "    color_means_all_non.append(color_means_non)\n",
    "    A_means_all_non.append(A_means_non)\n",
    "    A_S_means_all_non.append(A_S_means_non)\n",
    "    C_means_all_non.append(C_means_non)\n",
    "    n_means_all_non.append(n_means_non)\n",
    "    S_means_all_non.append(S_means_non)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Make the beautiful list of colors'''\n",
    "    # These are the \"Tableau 20\" colors as RGB.    \n",
    "    tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "                 (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "                 (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "                 (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "                 (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    \n",
    "\n",
    "    # Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "    for k in range(len(tableau20)):    \n",
    "        r, g, b = tableau20[k]    \n",
    "        tableau20[k] = (r / 255., g / 255., b / 255.)    \n",
    "\n",
    "\n",
    "    dashed_line_x=np.linspace(-0.5,-3,100)\n",
    "    dashed_line_y=[-0.14*x + 0.33 for x in dashed_line_x]\n",
    "\n",
    "    import seaborn\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax1=fig.add_subplot(111)\n",
    "    ax1.plot(dashed_line_x, dashed_line_y, ls='--', color='black')\n",
    "\n",
    "\n",
    "\n",
    "        #ax1.scatter(m20[myr[k]],gini[myr[k]],color=tableau20[k], label=myr[k])\n",
    "    #print(np.shape(m20),np.shape(myr))\n",
    "    #ax1.scatter(m20,gini,c=myr)\n",
    "    #plt.colorbar(im1)\n",
    "    \n",
    "    \n",
    "    im1=ax1.scatter(m20_means, gini_means, c=color_means, cmap='Reds', s=35)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "    \n",
    "    for j,k,l in zip(m20_means,gini_means,color_means):\n",
    "        ax1.annotate('%s' %l, xy=(j,k), xytext=(j,k))\n",
    "        \n",
    "        \n",
    "        '''A = anyarray\n",
    "B = anyotherarray\n",
    "\n",
    "plt.plot(A,B)\n",
    "for i,j in zip(A,B):\n",
    "    ax.annotate('%s)' %j, xy=(i,j), xytext=(30,0), textcoords='offset points')\n",
    "    ax.annotate('(%s,' %i, xy=(i,j))'''\n",
    "    \n",
    "    ax1.set_xlim([max(m20_means),min(m20_means)])\n",
    "    ax1.set_ylim([min(gini_means),max(gini_means)])#ax1.set_ylim([0.3,0.8])\n",
    "    ax1.set_xlabel(r'M$_{20}$')\n",
    "    ax1.set_ylabel(r'Gini')\n",
    "    ax1.set_aspect(abs(max(m20_means)-min(m20_means))/abs(min(gini_means)-max(gini_means)))\n",
    "\n",
    "\n",
    "\n",
    "    ax1.set_title('Mergers', loc='right')\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/time_evo_gini_m20_'+str(run)+'.pdf')\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(myr,A_means)\n",
    "    for j,k in zip(myr,A_means):\n",
    "        plt.annotate('%s' %j, xy=(j,k), xytext=(j,k))\n",
    "\n",
    "    plt.axhline(y=0.35)\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/time_evo_A_'+str(run)+'.pdf')\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(myr,A_S_means)\n",
    "    for j,k in zip(myr,A_S_means):\n",
    "        plt.annotate('%s' %j, xy=(j,k), xytext=(j,k))\n",
    "\n",
    "    plt.axhline(y=0.2)\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/time_evo_A_S_'+str(run)+'.pdf')\n",
    "    \n",
    "\n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax1=fig.add_subplot(121)\n",
    "    ax1.plot(dashed_line_x, dashed_line_y, ls='--', color='black')\n",
    "\n",
    "\n",
    "\n",
    "        #ax1.scatter(m20[myr[k]],gini[myr[k]],color=tableau20[k], label=myr[k])\n",
    "    #print(np.shape(m20),np.shape(myr))\n",
    "    #ax1.scatter(m20,gini,c=myr)\n",
    "    #plt.colorbar(im1)\n",
    "    \n",
    "    \n",
    "    im1=ax1.scatter(M20_list_all, G_list_all, c=color_list_all, cmap='Reds', s=35)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "    ax1.set_xlim([0,-3])\n",
    "    ax1.set_ylim([0.2,0.8])#ax1.set_ylim([0.3,0.8])\n",
    "    ax1.set_xlabel(r'M$_{20}$')\n",
    "    ax1.set_ylabel(r'Gini')\n",
    "    ax1.set_aspect(abs(3)/abs(0.6))\n",
    "\n",
    "\n",
    "\n",
    "    ax1.set_title('Mergers', loc='right')\n",
    "    #ax1.annotate('', xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "\n",
    "\n",
    "\n",
    "    ax2=fig.add_subplot(122)\n",
    "    ax2.plot(dashed_line_x, dashed_line_y, ls='--', color='black')\n",
    "\n",
    "\n",
    "        #ax1.scatter(m20[myr[k]],gini[myr[k]],color=tableau20[k], label=myr[k])\n",
    "    #print(np.shape(m20),np.shape(myr))\n",
    "    #ax1.scatter(m20,gini,c=myr)\n",
    "    #plt.colorbar(im1)\n",
    "    print('mean gini merger',np.mean(G_list_all))\n",
    "    print('mean gini nonmerger',np.mean(G_list_all_non))\n",
    "    im2=ax2.scatter(M20_list_all_non, G_list_all_non, c=color_list_all_non, cmap='Blues', s=35)\n",
    "    #ax2.scatter(np.mean(m20_non), np.mean(gini_non), s=40, color='red')\n",
    "    #ax2.errorbar(np.mean(m20_non), np.mean(gini_non),xerr=np.std(m20_non), yerr=np.std(gini_non), ecolor='red')\n",
    "\n",
    "    plt.colorbar(im2, label='Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "    ax2.set_xlim([0,-3])\n",
    "    ax2.set_ylim([0.2,0.8])#ax1.set_ylim([0.3,0.8])\n",
    "    ax2.set_xlabel(r'M$_{20}$')\n",
    "    ax2.set_ylabel(r'Gini')\n",
    "    ax2.set_aspect(abs(3)/abs(0.6))\n",
    "\n",
    "\n",
    "    ax2.set_title('Nonmergers', loc='right')\n",
    "    #ax1.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/gini_m20_cont_statmorph_nonoise_'+str(run)+'.pdf')\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax1=fig.add_subplot(121)\n",
    "    #ax1.plot(dashed_line_x, dashed_line_y, ls='--', color='black')\n",
    "\n",
    "\n",
    "\n",
    "        #ax1.scatter(m20[myr[k]],gini[myr[k]],color=tableau20[k], label=myr[k])\n",
    "    #print(np.shape(m20),np.shape(myr))\n",
    "    #ax1.scatter(m20,gini,c=myr)\n",
    "    #plt.colorbar(im1)\n",
    "    \n",
    "    \n",
    "    im1=ax1.scatter(M20_list_all_std, G_list_all_std, c=color_list_all, cmap='Reds', s=35)\n",
    "    ax1.scatter(np.mean(M20_list_all_std), np.mean(G_list_all_std), color='black', s=100)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "    ax1.set_xlim([-3,3])\n",
    "    ax1.set_ylim([-2,5])#ax1.set_ylim([0.3,0.8])\n",
    "    ax1.set_xlabel(r'M$_{20}$')\n",
    "    ax1.set_ylabel(r'Gini')\n",
    "    ax1.set_aspect(abs(6)/abs(7))\n",
    "\n",
    "\n",
    "\n",
    "    ax1.set_title('Mergers', loc='right')\n",
    "    #ax1.annotate('', xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "\n",
    "\n",
    "\n",
    "    ax2=fig.add_subplot(122)\n",
    "    #ax2.plot(dashed_line_x, dashed_line_y, ls='--', color='black')\n",
    "\n",
    "\n",
    "        #ax1.scatter(m20[myr[k]],gini[myr[k]],color=tableau20[k], label=myr[k])\n",
    "    #print(np.shape(m20),np.shape(myr))\n",
    "    #ax1.scatter(m20,gini,c=myr)\n",
    "    #plt.colorbar(im1)\n",
    "    print('mean gini merger std',np.mean(G_list_all_std))\n",
    "    print('mean gini nonmerger std',np.mean(G_list_all_non_std))\n",
    "    im2=ax2.scatter(M20_list_all_non_std, G_list_all_non_std, c=color_list_all_non, cmap='Blues', s=35)\n",
    "    ax2.scatter(np.mean(M20_list_all_non_std), np.mean(G_list_all_non_std), color='blue', s=100)\n",
    "    \n",
    "    #ax2.scatter(np.mean(m20_non), np.mean(gini_non), s=40, color='red')\n",
    "    #ax2.errorbar(np.mean(m20_non), np.mean(gini_non),xerr=np.std(m20_non), yerr=np.std(gini_non), ecolor='red')\n",
    "\n",
    "    plt.colorbar(im2, label='Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "    ax2.set_xlim([-3,3])\n",
    "    ax2.set_ylim([-2,5])#ax1.set_ylim([0.3,0.8])\n",
    "    ax2.set_xlabel(r'M$_{20}$')\n",
    "    ax2.set_ylabel(r'Gini')\n",
    "    ax2.set_aspect(abs(6)/abs(7))\n",
    "\n",
    "\n",
    "    ax2.set_title('Nonmergers', loc='right')\n",
    "    #ax1.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/gini_m20_cont_statmorph_nonoise_std_'+str(run)+'.pdf')\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax1=fig.add_subplot(121)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    im1=ax1.scatter(A_list_all, C_list_all, c=color_list_all, cmap='Reds', s=35)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "    #print(np.shape(m20),np.shape(myr))\n",
    "    #ax1.scatter(m20,gini,c=myr)\n",
    "    #plt.colorbar(im1)\n",
    "\n",
    "    ax1.set_xlim([0,1])\n",
    "    ax1.set_ylim([0,6])#ax1.set_ylim([0.3,0.8])\n",
    "    ax1.set_xlabel(r'A')\n",
    "    ax1.set_ylabel(r'C')\n",
    "    ax1.set_aspect(1/6)\n",
    "\n",
    "    #ax1.legend(loc='lower center',\n",
    "    #          ncol=2)\n",
    "    ax1.set_title('Mergers', loc='right')\n",
    "\n",
    "    #ax1.annotate(str(NAME), xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "    plt.axvline(x=0.35, ls='--', color='black')\n",
    "\n",
    "\n",
    "    ax2=fig.add_subplot(122)\n",
    "\n",
    "\n",
    "\n",
    "    im1=ax2.scatter(A_list_all_non, C_list_all_non, c=color_list_all_non, cmap='Blues', s=35)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "    ax2.set_xlim([0,1])\n",
    "    ax2.set_ylim([0,6])#ax1.set_ylim([0.3,0.8])\n",
    "    ax2.set_xlabel(r'A')\n",
    "    ax2.set_ylabel(r'C')\n",
    "    ax2.set_aspect(1/6)\n",
    "    plt.axvline(x=0.35, ls='--', color='black')\n",
    "\n",
    "\n",
    "    #ax2.legend(loc='lower center',\n",
    "    #          ncol=2)\n",
    "    ax2.set_title('Nonmergers', loc='right')\n",
    "    #ax1.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/C_A_cont_statmorph_nonoise_'+str(run)+'.pdf')\n",
    "    \n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax1=fig.add_subplot(121)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    im1=ax1.scatter(S_list_all, C_list_all, c=color_list_all, cmap='Reds', s=35)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "    #print(np.shape(m20),np.shape(myr))\n",
    "    #ax1.scatter(m20,gini,c=myr)\n",
    "    #plt.colorbar(im1)\n",
    "\n",
    "    ax1.set_xlim([0,1])\n",
    "    ax1.set_ylim([0,6])#ax1.set_ylim([0.3,0.8])\n",
    "    ax1.set_xlabel(r'S')\n",
    "    ax1.set_ylabel(r'C')\n",
    "    ax1.set_aspect(1/6)\n",
    "\n",
    "    #ax1.legend(loc='lower center',\n",
    "    #          ncol=2)\n",
    "    ax1.set_title('Mergers', loc='right')\n",
    "\n",
    "    #ax1.annotate(str(NAME), xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "    plt.axvline(x=0.35, ls='--', color='black')\n",
    "\n",
    "\n",
    "    ax2=fig.add_subplot(122)\n",
    "\n",
    "\n",
    "\n",
    "    im1=ax2.scatter(S_list_all_non, C_list_all_non, c=color_list_all_non, cmap='Blues', s=35)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "    ax2.set_xlim([0,1])\n",
    "    ax2.set_ylim([0,6])#ax1.set_ylim([0.3,0.8])\n",
    "    ax2.set_xlabel(r'S')\n",
    "    ax2.set_ylabel(r'C')\n",
    "    ax2.set_aspect(1/6)\n",
    "    plt.axvline(x=0.35, ls='--', color='black')\n",
    "\n",
    "\n",
    "    #ax2.legend(loc='lower center',\n",
    "    #          ncol=2)\n",
    "    ax2.set_title('Nonmergers', loc='right')\n",
    "    #ax1.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/C_S_cont_statmorph_nonoise_'+str(run)+'.pdf')\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    Now for n-A_S plot\n",
    "\n",
    "    '''\n",
    "    plt.clf()\n",
    "    fig=plt.figure()\n",
    "    ax1=fig.add_subplot(121)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    im1=ax1.scatter(A_S_list_all, n_list_all, c=color_list_all, cmap='Reds', s=35)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "    #print(np.shape(m20),np.shape(myr))\n",
    "    #ax1.scatter(m20,gini,c=myr)\n",
    "    #plt.colorbar(im1)\n",
    "\n",
    "    ax1.set_xlim([0,1])\n",
    "    ax1.set_ylim([0,4])#ax1.set_ylim([0.3,0.8])\n",
    "    ax1.set_xlabel(r'$A_S$')\n",
    "    ax1.set_ylabel(r'$n$')\n",
    "    ax1.set_aspect(1/4)\n",
    "\n",
    "    #ax1.legend(loc='lower center',\n",
    "    #          ncol=2)\n",
    "    ax1.set_title('Mergers', loc='right')\n",
    "\n",
    "    #ax1.annotate(str(NAME), xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "    plt.axvline(x=0.2, ls='--', color='black')\n",
    "\n",
    "\n",
    "    ax2=fig.add_subplot(122)\n",
    "\n",
    "\n",
    "    im1=ax2.scatter(A_S_list_all_non, n_list_all_non, c=color_list_all_non, cmap='Blues', s=35)\n",
    "    plt.colorbar(im1, label='Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "    ax2.set_xlim([0,1])\n",
    "    ax2.set_ylim([0,4])#ax1.set_ylim([0.3,0.8])\n",
    "    ax2.set_xlabel(r'$A_S$')\n",
    "    ax2.set_ylabel(r'$n$')\n",
    "    ax2.set_aspect(1/4)\n",
    "    plt.axvline(x=0.2, ls='--', color='black')\n",
    "\n",
    "\n",
    "    #ax2.legend(loc='lower center',\n",
    "    #          ncol=2)\n",
    "    ax2.set_title('Nonmergers', loc='right')\n",
    "    #ax1.set_aspect('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/n_A_S_cont_statmorph_nonoise_'+str(run)+'.pdf')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    X_nonmerg=[]\n",
    "    X_merg=[]\n",
    "    \n",
    "    for l in range(len(y)):\n",
    "        if y[l]==0:\n",
    "            X_nonmerg.append(X[l])\n",
    "        else:\n",
    "            X_merg.append(X[l])\n",
    "            \n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    n_params=7\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    print('coefficients', coef)\n",
    "    \n",
    "    inter = sklearn_lda.intercept_\n",
    "    class_label = sklearn_lda.classes_\n",
    "    cov = sklearn_lda.covariance_\n",
    "    \n",
    "    #print('covariance LDA', cov)\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''print('coef stand alone', coef)\n",
    "    \n",
    "    X_gal = [[0.562098854190755,-2.0047344485315897,\n",
    "             3.518338817199331,0.05954215159332954,\n",
    "             1.357,0.057142857],\n",
    "             [0.562098854190755,-2.0047344485315897,\n",
    "             1.518338817199331,0.05954215159332954,\n",
    "             1.357,0.057142857],\n",
    "             [0.6048765935043497,-1.1239109246696275,\n",
    "              1.365753065935824,0.6683389242149403,\n",
    "              1.5499,0.48453608],\n",
    "            [0.6020378718157088,-2.507254136663051,\n",
    "             4.709500635785499,0.05257676639428181,\n",
    "             15.863,0.16793893]]\n",
    "    \n",
    "    feature_dict2 = {i:label for i,label in zip(\n",
    "                range(12),\n",
    "                  ('Counter',\n",
    "                  'ID',\n",
    "                  'Merger?',\n",
    "                  '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "    \n",
    "    df2 = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='LDA_img_statmorph_Fu_mergers.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "        ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "          \n",
    "    df2.columns = [l for i,l in sorted(feature_dict2.items())] + ['Shape Asymmetry']\n",
    "    \n",
    "    df2.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "    \n",
    "\n",
    "\n",
    "    X_gal = df2[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    #'Clumpiness (S)',\n",
    "    X_gal = std_scale.transform(X_gal)\n",
    "    print(sklearn_lda.predict(X_gal))\n",
    "    print(sklearn_lda.predict_proba(X_gal))'''\n",
    "    \n",
    "    \n",
    "    pred = sklearn_lda.predict(X)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Run keras deep learning model'''\n",
    "    # Import `Sequential` from `keras.models`\n",
    "    from keras.models import Sequential\n",
    "\n",
    "    # Import `Dense` from `keras.layers`\n",
    "    from keras.layers import Dense\n",
    "\n",
    "    \n",
    "    \n",
    "    from keras.layers import Convolution2D, MaxPooling2D\n",
    "    # Initialize the constructor\n",
    "    model = Sequential()\n",
    "    # Add an input layer \n",
    "    model.add(Dense(12, activation='relu', input_shape=(n_params,)))\n",
    "    # Add one hidden layer \n",
    "    model.add(Dense(8, activation='relu'))\n",
    "\n",
    "    # Add an output layer \n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "        # 8. Compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    from keras import utils as np_utils\n",
    "    #print(list(y_train-1), np.shape(list(y_train-1)))\n",
    "    y_train = np_utils.to_categorical(list(y_train-1), 2)\n",
    "    y_test = np_utils.to_categorical(list(y_test-1), 2)\n",
    "    #print(y_train)\n",
    "        \n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train,epochs=20, batch_size=1, verbose=1)\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('score', score)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "    if loop=='yes':\n",
    "        splits_non=np.linspace(2,(len(X)-1)/2,(len(X)-1)/2)\n",
    "        splits=[int(x) for x in splits_non]\n",
    "        print('splits', splits)\n",
    "        print(inputs[i])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        X = df[inputs[i]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "        \n",
    "        cv_error=[]\n",
    "        gini_mean=[]\n",
    "        gini_std=[]\n",
    "        for k in range(len(splits)):\n",
    "            print(splits[k])\n",
    "            kf = StratifiedKFold(n_splits=splits[k], random_state=True, shuffle=True)#len(X))\n",
    "            \n",
    "\n",
    "            kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "            coef_list=[]\n",
    "            inter_list=[]\n",
    "            confusion_master=[]\n",
    "            y_test_master=[]\n",
    "            pred_master=[]\n",
    "            count=0\n",
    "            for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "                sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "                \n",
    "                X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "                coef = sklearn_lda.coef_\n",
    "                \n",
    "                pred =sklearn_lda.predict(X_test)\n",
    "\n",
    "                confusion_master.append(confusion_matrix(pred,y_test))\n",
    "                \n",
    "                count+=1\n",
    "                coef_list.append(coef)\n",
    "\n",
    "\n",
    "            \n",
    "            master=np.mean(confusion_master, axis=0).transpose()\n",
    "            cv_error.append(master[1][0]+master[0][1])\n",
    "            \n",
    "            gini_mean.append(np.mean(coef_list,axis=0)[0])\n",
    "            gini_std.append(np.std(coef_list,axis=0)[0])\n",
    "            \n",
    "        plt.clf()\n",
    "        plt.plot(splits, cv_error)\n",
    "        plt.xlabel('# k folds')\n",
    "        plt.ylabel('CV Error')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/kfold_cverror_'+str(run)+'.pdf')\n",
    "        \n",
    "        plt.clf()\n",
    "        plt.plot(splits, gini_mean, color='black')\n",
    "        plt.fill_between(splits, np.array(gini_mean)+np.array(gini_std), np.array(gini_mean)-np.array(gini_std), alpha=.5)\n",
    "        plt.xlabel('# k folds')\n",
    "        plt.ylabel('Gini Mean and Error')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/kfold_gini_'+str(run)+'.pdf')\n",
    "        continue\n",
    "    else:\n",
    "        kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "\n",
    "\n",
    "\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "\n",
    "            '''def predict_with_cutoff(colname, y_prob, df):\n",
    "                n_events = df[colname].values\n",
    "                event_rate = sum(n_events) / float(df.shape[0]) * 100\n",
    "                threshold = np.percentile(y_prob[:, 1], 100 - event_rate)\n",
    "                print \"Cutoff/threshold at: \" + str(threshold)\n",
    "                y_pred = [1 if x >= threshold else 0 for x in y_prob[:, 1]]\n",
    "                return y_pred'''\n",
    "\n",
    "            '''plt.clf()\n",
    "            fig=plt.figure()#figsize=(6,6)\n",
    "            plot_confusion_matrix(confusion_matrix(pred,y_test)/np.sum(confusion_matrix(pred,y_test)), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "            plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'_'+str(count)+'.pdf')\n",
    "            #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "            plt.clf()'''\n",
    "\n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "            pred_master.append(pred)\n",
    "            y_test_master.append(y_test)\n",
    "\n",
    "            count+=1\n",
    "\n",
    "\n",
    "        print('~~~~~Stratified K-fold validation means  ~~~~~~')\n",
    "        print(np.mean(coef_list, axis=0))\n",
    "        print(np.mean(inter_list, axis=0))\n",
    "        print('~~~~~Stratified K-fold validation STD ~~~~~~')\n",
    "        print(np.std(coef_list, axis=0))\n",
    "        print(np.std(inter_list, axis=0))\n",
    "\n",
    "        print(run+str(' & '))\n",
    "        for j in range(len(np.mean(coef_list,axis=0)[0])):\n",
    "            print(str(round(np.mean(coef_list,axis=0)[0][j],2))+r' $\\pm$ '+str(round(np.std(coef_list,axis=0)[0][j],2))+' & ')\n",
    "        print(str(round(np.mean(inter_list,axis=0)[0],2))+r' $\\pm$ '+str(round(np.std(inter_list,axis=0)[0],2))+ '//')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        print('~~~~~Comparing to last run~~~~~')\n",
    "        print(coef)\n",
    "        print(inter)\n",
    "\n",
    "        print('~~~~~Master Confusion~~~~~')\n",
    "        '''print(confusion_master)\n",
    "        print(np.shape(confusion_master))'''\n",
    "        master=np.mean(confusion_master, axis=0).transpose()\n",
    "        print(master)\n",
    "        print(master[1][0])#row, then column\n",
    "        print('~~~Accuracy~~~')\n",
    "        print((master[1][1]+master[0][0])/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "        print('~~~Precision~~~')\n",
    "        print(master[1][1]/(master[0][1]+master[1][1]))#TP/(TP+FP)\n",
    "        print('~~~Recall~~~')\n",
    "        print(master[1][1]/(master[1][0]+master[1][1]))#TP/(TP+FN)\n",
    "        print('~~~F1~~~')\n",
    "        print((2*master[1][1])/(master[0][1]+master[1][0]+2*master[1][1]))#2TP/(2TP+FP+FN)\n",
    "\n",
    "        print('before transposing', (np.mean(confusion_master,axis=0)/np.sum(np.mean(confusion_master,axis=0))))\n",
    "\n",
    "        print('after transposing', (np.mean(confusion_master,axis=0)/np.sum(np.mean(confusion_master,axis=0))).transpose())\n",
    "        plt.clf()\n",
    "        fig=plt.figure()#figsize=(6,6)\n",
    "        plot_confusion_matrix((np.mean(confusion_master,axis=0)/np.sum(np.mean(confusion_master,axis=0))).transpose(), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'.pdf')\n",
    "        #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "    plt.clf()\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Redo X_lda to make plots'''\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    #coef = sklearn_qda.coef_\n",
    "    #inter = sklearn_qda.intercept_\n",
    "    #print(dec_qda)#mean accuracy on the given test data and labels.\n",
    "\n",
    "    '''Make a histogram'''\n",
    "    from scipy import stats\n",
    "    import seaborn as sns\n",
    "    \n",
    "    X_lda_1=[]\n",
    "    X_lda_2=[]\n",
    "    for j in range(len(X_lda_sklearn)):\n",
    "        if y[j] ==1:\n",
    "            X_lda_1.append(X_lda_sklearn[j][0])\n",
    "        else:\n",
    "            X_lda_2.append(X_lda_sklearn[j][0])\n",
    "    input_hist=X_lda_sklearn\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(20,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.hist(X_lda_1, label='Nonmerger',  color=sns.xkcd_rgb[\"sky blue\"], normed=1)\n",
    "    ax.hist(X_lda_2, label='Merger',  color=sns.xkcd_rgb[\"salmon\"],alpha = 0.85,normed=1)\n",
    "\n",
    "    \n",
    "\n",
    "    ax.set_xlabel('LD1', size=25)\n",
    "    #ax.set_title('Histogram #%s' %str(cnt+1), size=20)\n",
    "\n",
    "    # hide axis ticks\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\", labelsize=20)\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    ax.set_ylabel('Relative Count', size=25)\n",
    "    \n",
    "    \n",
    "    plt.legend(loc=\"upper right\", fontsize=20)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Now measure LD1 for every row and then plot that'''\n",
    "    import seaborn as sns\n",
    "    \n",
    "\n",
    "    n_params=6\n",
    "\n",
    "\n",
    "\n",
    "    #coef is how you get the eigvecs (doesn't matter what slope offset is)\n",
    "    #print('real eigvecs',(eigvec_sc.real))\n",
    "    #print(len(X_lda[:,0].real[y==2]))#[y == label]\n",
    "    xs=[]\n",
    "    LDA1=[]\n",
    "    \n",
    "    my_lists = {key:[] for key in myr}\n",
    "    my_lists_non = {key:[] for key in myr_non}\n",
    "    my_lists_none = []\n",
    "    my_lists_merg = []\n",
    "    separations = {key:[] for key in myr}\n",
    "\n",
    "    \n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['class label']].values[j]==0:\n",
    "            my_lists_none.append(X_lda_sklearn[j][0])\n",
    "            my_lists_non[df[['Myr']].values[j][0]].append(X_lda_sklearn[j][0])\n",
    "            continue\n",
    "        else:\n",
    "            my_lists_merg.append(X_lda_sklearn[j][0])\n",
    "        \n",
    "            my_lists[df[['Myr']].values[j][0]].append(X_lda_sklearn[j][0])\n",
    "        \n",
    "            separations[df[['Myr']].values[j][0]].append(df[['Sep']].values[j][0])\n",
    "            L=X_lda_sklearn[j][0]\n",
    "            #df[['Gini']].values[i][0]*coef[0][0]+df[['M20']].values[i][0]*coef[0][1]+df[['Concentration (C)']].values[i][0]*coef[0][2]+df[['Asymmetry (A)']].values[i][0]*coef[0][3]+df[['Clumpiness (S)']].values[i][0]*coef[0][4]+df[['Sersic N']].values[i][0]*coef[0][5]+df[['Shape Asymmetry']].values[i][0]*coef[0][6]\n",
    "            LDA1.append(L)\n",
    "            xs.append(df[['Myr']].values[j][0])\n",
    "\n",
    "    #print(mean(my_lists[180]))\n",
    "    mean_non=(np.mean(my_lists_merg)+np.mean(my_lists_none))/2\n",
    "    print('DECISION BOUNDARY', mean_non, run)\n",
    "    \n",
    "    if run=='fg1_m13' or run=='fg1_m13_comp_real':\n",
    "        plt.annotate('q0.333_fg0.1', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    if run=='fg3_m12' or run=='fg3_m12_comp_real':\n",
    "        plt.annotate('q0.5_fg0.3', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    if run=='fg3_m15' or run=='fg3_m15_comp_real':\n",
    "        plt.annotate('q0.2_fg0.3_BT0.2', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    if run=='all':\n",
    "        plt.annotate('All', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    if run=='fg3_m1_10' or run=='fg3_m1_10_comp_real':\n",
    "        plt.annotate('q0.1_fg0.3_BT0.2', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    means=[]\n",
    "    std=[]\n",
    "    separation_value=[]\n",
    "    myr_here=[]\n",
    "    for j in range(len(myr)):\n",
    "        '''if math.isnan(np.mean(my_lists[myr[j]])):\n",
    "            separation_value.append(999)\n",
    "            continue\n",
    "        else:'''\n",
    "        if np.std(my_lists[myr[j]])==0:# or np.std(my_lists[myr[j]])< 0.01*np.mean(my_lists[myr[j]]):\n",
    "            continue\n",
    "        means.append(np.mean(my_lists[myr[j]]))\n",
    "        std.append(np.std(my_lists[myr[j]]))\n",
    "        separation_value.append(np.mean(separations[myr[j]]))\n",
    "        myr_here.append(myr[j])\n",
    "        print(my_lists[myr[j]])\n",
    "        \n",
    "    print('means',means)\n",
    "    \n",
    "    means=np.array(means)\n",
    "    std=np.array(std)\n",
    "    myr_here=np.array(myr_here)\n",
    "    \n",
    "    means_non=[]\n",
    "    std_non=[]\n",
    "    myr_here_non=[]\n",
    "    for j in range(len(myr_non)):\n",
    "        '''if math.isnan(np.mean(my_lists_non[myr_non[i]])):\n",
    "            \n",
    "            continue\n",
    "        else:'''\n",
    "        if np.std(my_lists_non[myr_non[j]])==0 or np.std(my_lists_non[myr_non[j]])< 0.01*np.mean(my_lists_non[myr_non[j]]):\n",
    "            continue\n",
    "        means_non.append(np.mean(my_lists_non[myr_non[j]]))\n",
    "        std_non.append(np.std(my_lists_non[myr_non[j]]))\n",
    "        myr_here_non.append(myr_non[j])\n",
    "        \n",
    "    \n",
    "    means_non=np.array(means_non)\n",
    "    std_non=np.array(std_non)\n",
    "    myr_here_non=np.array(myr_here_non)\n",
    "    \n",
    "    print(myr, std)\n",
    "    print('myr', myr)\n",
    "    print('myr_non', myr_non)\n",
    "    \n",
    "    '''delete places where there is only one point'''\n",
    "    \n",
    "    \n",
    "    plt.axvline(x=mean_non, color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/Hist_statmorph_nonoise_'+str(run)+'.pdf')\n",
    "    plt.clf()\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(18,6))\n",
    "    \n",
    "    print('means',means)\n",
    "    \n",
    "    if run=='fg1_m13' or run=='fg1_m13_comp_real' or run=='fg1_m13_alliso':\n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#-1.7583e-01\n",
    "        rescale_y_pm=7.13475416061/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color=sns.xkcd_rgb[\"amber\"])\n",
    "        \n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        #plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=215/100, color='black', ls='--')\n",
    "        plt.axvline(x=280/100, color='black', ls='--')\n",
    "\n",
    "        \n",
    "        plt.annotate('q0.333_fg0.1', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(1.7,max(new_means+std)-0.2),  size=20)\n",
    "        plt.annotate('Late', xy=(2.4,max(new_means+std)-0.2), size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(2.9,max(new_means+std)-0.2), size=20)\n",
    "\n",
    "    \n",
    "    if run=='fg3_m12' or run=='fg3_m12_alliso' or run=='fg3_m12_comp_real':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        rescale_y_pm=5.5684302120/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color='red')\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color='red')\n",
    "        \n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "\n",
    "        plt.annotate('q0.5_fg0.3', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(1.68,max(new_means+std)-0.2),  size=20)\n",
    "        plt.annotate('Late', xy=(2.1,max(new_means+std)-0.2),size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(2.22,max(new_means+std)-0.2),  size=20)\n",
    "    if run=='fg3_m15' or run=='fg3_m15_alliso' or run=='fg3_m15_comp_real':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        rescale_y_pm=5.5684302120/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "        \n",
    "        \n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color='green')\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color='green')\n",
    "        \n",
    "        \n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        plt.axvline(x=360/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "        plt.annotate('q0.2_fg0.3_BT0.2', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(1.55,max(new_means+std)-0.2),  size=20)\n",
    "        plt.annotate('Late', xy=(1.9,max(new_means+std)-0.2), size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(3.62,max(new_means+std)-0.2),  size=20)\n",
    "    if run=='all':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        \n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color='green')\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color='green')\n",
    "        \n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        \n",
    "        plt.axvline(x=270/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "\n",
    "        plt.annotate('All', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(1.5,0.97), size=20)\n",
    "        \n",
    "        plt.annotate('Late', xy=(1.9,0.97), size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(2.75,0.97), size=20)\n",
    "    if run=='fg3_m1_10' or run=='fg3_m1_10_alliso' or run=='fg3_m1_10_comp_real':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        \n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color='purple')\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color='purple')\n",
    "        \n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        plt.axvline(x=900/100, color='black', ls='--')\n",
    "        plt.axvline(x=410/100, color='black', ls='--')\n",
    "        plt.annotate('q0.1_fg0.3_BT0.2', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(3,max(new_means+std)-0.2), size=20)\n",
    "        \n",
    "        plt.annotate('Late', xy=(5,max(new_means+std)-0.2), size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(9.1,max(new_means+std)-0.2), size=20)\n",
    "    #plt.ylim([-1,1])\n",
    "    plt.xlim([min(myr)/100,max(myr)/100])\n",
    "    frame1 = plt.gca()\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    \n",
    "    #frame1.axes.yaxis.set_ticklabels([])\n",
    "    plt.axhline(y=mean_non, color='black')\n",
    "    plt.xlabel(r'Merger Timeline [Gyr]', size=20)\n",
    "    plt.ylabel(r'Detection Sensitivity (LD1)', size=20)\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/Mountain_plot_imaging_statmorph_nonoise_'+str(run)+'.pdf')\n",
    "\n",
    "    \n",
    "\n",
    "plt.clf()\n",
    "fig=plt.figure()\n",
    "ax1=fig.add_subplot(121)\n",
    "ax1.plot(dashed_line_x, dashed_line_y, ls='--', color='black')\n",
    "\n",
    "\n",
    "\n",
    "    #ax1.scatter(m20[myr[k]],gini[myr[k]],color=tableau20[k], label=myr[k])\n",
    "#print(np.shape(m20),np.shape(myr))\n",
    "#ax1.scatter(m20,gini,c=myr)\n",
    "#plt.colorbar(im1)\n",
    "\n",
    "\n",
    "im1=ax1.scatter(m20_means_all[0], gini_means_all[0], color='red',  s=25)\n",
    "\n",
    "im2=ax1.scatter(m20_means_all[1], gini_means_all[1], color=sns.xkcd_rgb[\"amber\"], s=25)\n",
    "\n",
    "im3=ax1.scatter(m20_means_all[2], gini_means_all[2], color='green', s=25)\n",
    "\n",
    "im4=ax1.scatter(m20_means_all[3], gini_means_all[3], color='purple', s=25)\n",
    "ax1.set_xlim([0,-3])\n",
    "ax1.set_ylim([0.2,0.8])#ax1.set_ylim([0.3,0.8])\n",
    "ax1.set_xlabel(r'M$_{20}$')\n",
    "ax1.set_ylabel(r'Gini')\n",
    "ax1.set_aspect(abs(3)/abs(0.6))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_title('Mergers', loc='right')\n",
    "#ax1.annotate('', xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "\n",
    "\n",
    "\n",
    "'''ax2=fig.add_subplot(132)\n",
    "plt.colorbar(im1, label='q0.5_fg0.3 Time [Gyr]',orientation='horizontal')\n",
    "plt.colorbar(im2, label='q0.333_fg0.1 Time [Gyr]',orientation='horizontal')\n",
    "plt.colorbar(im3, label='q0.2_fg0.3_BT0.2 Time [Gyr]',orientation='horizontal')\n",
    "plt.colorbar(im4, label='q0.1_fg0.3_BT0.2 Time [Gyr]',orientation='horizontal')\n",
    "'''\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(122)\n",
    "ax3.plot(dashed_line_x, dashed_line_y, ls='--', color='black')\n",
    "\n",
    "im5=ax3.scatter(m20_means_all_non[0], gini_means_all_non[0], color='red', s=25, label='q0.5_fg0.3')\n",
    "#plt.colorbar(im5, label='q0.5_fg0.3 IsolatedTime [Gyr]',orientation='horizontal')\n",
    "\n",
    "im6=ax3.scatter(m20_means_all_non[1], gini_means_all_non[1], color=sns.xkcd_rgb[\"amber\"],  s=25, label='q0.333_fg0.1')\n",
    "#plt.colorbar(im6, label='q0.333_fg0.1 Isolated Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "im7=ax3.scatter(m20_means_all_non[2], gini_means_all_non[2], color='green',  s=25, label='q0.2_fg0.3_BT0.2')\n",
    "#plt.colorbar(im7, label='q0.2_fg0.3_BT0.2 Isolated Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "im8=ax3.scatter(m20_means_all_non[3], gini_means_all_non[3], color='purple', s=25, label='q0.1_fg0.3_BT0.2')\n",
    "#plt.colorbar(im8, label='q0.1_fg0.3_BT0.2 Isolated Time [Gyr]',orientation='horizontal')\n",
    "\n",
    "\n",
    "ax3.set_xlim([0,-3])\n",
    "ax3.set_ylim([0.2,0.8])#ax1.set_ylim([0.3,0.8])\n",
    "ax3.set_xlabel(r'M$_{20}$')\n",
    "ax3.set_ylabel(r'Gini')\n",
    "ax3.set_aspect(abs(3)/abs(0.6))\n",
    "\n",
    "\n",
    "ax3.set_title('Nonmergers', loc='right')\n",
    "#ax1.set_aspect('equal')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../MaNGA_Papers/Paper_I/gini_m20_overall.pdf')\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "fig=plt.figure()\n",
    "ax1=fig.add_subplot(121)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "im1=ax1.scatter(A_means_all[0], C_means_all[0], color='red', s=25)\n",
    "im1=ax1.scatter(A_means_all[1], C_means_all[1], color=sns.xkcd_rgb[\"amber\"], s=25)\n",
    "im1=ax1.scatter(A_means_all[2], C_means_all[2], color='green', s=25)\n",
    "im1=ax1.scatter(A_means_all[3], C_means_all[3], color='purple', s=25)\n",
    "\n",
    "\n",
    "ax1.set_xlim([0,1])\n",
    "ax1.set_ylim([0,6])#ax1.set_ylim([0.3,0.8])\n",
    "ax1.set_xlabel(r'A')\n",
    "ax1.set_ylabel(r'C')\n",
    "ax1.set_aspect(1/6)\n",
    "\n",
    "#ax1.legend(loc='lower center',\n",
    "#          ncol=2)\n",
    "ax1.set_title('Mergers', loc='right')\n",
    "\n",
    "#ax1.annotate(str(NAME), xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "plt.axvline(x=0.35, ls='--', color='black')\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(122)\n",
    "\n",
    "\n",
    "\n",
    "im1=ax2.scatter(A_means_all_non[0], C_means_all_non[0], color='red', s=25, label='q0.5_fg0.3')\n",
    "im1=ax2.scatter(A_means_all_non[1], C_means_all_non[1], color=sns.xkcd_rgb[\"amber\"], s=25, label='q0.333_f0.1')\n",
    "im1=ax2.scatter(A_means_all_non[2], C_means_all_non[2], color='green', s=25, label='q0.2_fg0.3_BT0.2')\n",
    "im1=ax2.scatter(A_means_all_non[3], C_means_all_non[3], color='purple', s=25, label='q0.1_fg0.3_BT0.2')\n",
    "\n",
    "ax2.set_xlim([0,1])\n",
    "ax2.set_ylim([0,6])#ax1.set_ylim([0.3,0.8])\n",
    "ax2.set_xlabel(r'A')\n",
    "ax2.set_ylabel(r'C')\n",
    "ax2.set_aspect(1/6)\n",
    "plt.axvline(x=0.35, ls='--', color='black')\n",
    "#plt.legend()\n",
    "\n",
    "#ax2.legend(loc='lower center',\n",
    "#          ncol=2)\n",
    "ax2.set_title('Nonmergers', loc='right')\n",
    "#ax1.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../MaNGA_Papers/Paper_I/C_A_overall.pdf')\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "fig=plt.figure()\n",
    "ax1=fig.add_subplot(121)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "im1=ax1.scatter(S_means_all[0], C_means_all[0], color='red', s=25)\n",
    "im1=ax1.scatter(S_means_all[1], C_means_all[1], color=sns.xkcd_rgb[\"amber\"], s=25)\n",
    "im1=ax1.scatter(S_means_all[2], C_means_all[2], color='green', s=25)\n",
    "im1=ax1.scatter(S_means_all[3], C_means_all[3], color='purple', s=25)\n",
    "\n",
    "\n",
    "ax1.set_xlim([0,1])\n",
    "ax1.set_ylim([0,6])#ax1.set_ylim([0.3,0.8])\n",
    "ax1.set_xlabel(r'S')\n",
    "ax1.set_ylabel(r'C')\n",
    "ax1.set_aspect(1/6)\n",
    "\n",
    "#ax1.legend(loc='lower center',\n",
    "#          ncol=2)\n",
    "ax1.set_title('Mergers', loc='right')\n",
    "\n",
    "#ax1.annotate(str(NAME), xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "#plt.axvline(x=0.35, ls='--', color='black')\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(122)\n",
    "\n",
    "\n",
    "\n",
    "im1=ax2.scatter(S_means_all_non[0], C_means_all_non[0], color='red', s=25, label='q0.5_fg0.3')\n",
    "im1=ax2.scatter(S_means_all_non[1], C_means_all_non[1], color=sns.xkcd_rgb[\"amber\"], s=25, label='q0.333_f0.1')\n",
    "im1=ax2.scatter(S_means_all_non[2], C_means_all_non[2], color='green', s=25, label='q0.2_fg0.3_BT0.2')\n",
    "im1=ax2.scatter(S_means_all_non[3], C_means_all_non[3], color='purple', s=25, label='q0.1_fg0.3_BT0.2')\n",
    "\n",
    "ax2.set_xlim([0,1])\n",
    "ax2.set_ylim([0,6])#ax1.set_ylim([0.3,0.8])\n",
    "ax2.set_xlabel(r'S')\n",
    "ax2.set_ylabel(r'C')\n",
    "ax2.set_aspect(1/6)\n",
    "#plt.axvline(x=0.35, ls='--', color='black')\n",
    "#plt.legend()\n",
    "\n",
    "#ax2.legend(loc='lower center',\n",
    "#          ncol=2)\n",
    "ax2.set_title('Nonmergers', loc='right')\n",
    "#ax1.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../MaNGA_Papers/Paper_I/C_S_overall.pdf')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Now for n-A_S plot\n",
    "\n",
    "'''\n",
    "plt.clf()\n",
    "fig=plt.figure()\n",
    "ax1=fig.add_subplot(121)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "im1=ax1.scatter(A_S_means_all[0], n_means_all[0], color='red', s=25)\n",
    "im1=ax1.scatter(A_S_means_all[1], n_means_all[1], color=sns.xkcd_rgb[\"amber\"], s=25)\n",
    "im1=ax1.scatter(A_S_means_all[2], n_means_all[2], color='green', s=25)\n",
    "im1=ax1.scatter(A_S_means_all[3], n_means_all[3], color='purple', s=25)\n",
    "\n",
    "\n",
    "ax1.set_xlim([0,1])\n",
    "ax1.set_ylim([0,4])#ax1.set_ylim([0.3,0.8])\n",
    "ax1.set_xlabel(r'$A_S$')\n",
    "ax1.set_ylabel(r'$n$')\n",
    "ax1.set_aspect(1/4)\n",
    "\n",
    "#ax1.legend(loc='lower center',\n",
    "#          ncol=2)\n",
    "ax1.set_title('Mergers', loc='right')\n",
    "\n",
    "#ax1.annotate(str(NAME), xy=(0.03,1.05),xycoords='axes fraction',size=15)\n",
    "plt.axvline(x=0.2, ls='--', color='black')\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(122)\n",
    "\n",
    "\n",
    "im1=ax2.scatter(A_S_means_all_non[0], n_means_all_non[0], color='red', s=25, label='q0.5_fg0.3')\n",
    "im1=ax2.scatter(A_S_means_all_non[1], n_means_all_non[1], color=sns.xkcd_rgb[\"amber\"], s=25, label='q0.333_fg0.1')\n",
    "im1=ax2.scatter(A_S_means_all_non[2], n_means_all_non[2], color='green', s=25, label='q0.2_fg0.3_BT0.2')\n",
    "im1=ax2.scatter(A_S_means_all_non[3], n_means_all_non[3], color='purple', s=25, label='q0.1_fg0.3_BT0.2')\n",
    "\n",
    "ax2.set_xlim([0,1])\n",
    "ax2.set_ylim([0,4])#ax1.set_ylim([0.3,0.8])\n",
    "ax2.set_xlabel(r'$A_S$')\n",
    "ax2.set_ylabel(r'$n$')\n",
    "ax2.set_aspect(1/4)\n",
    "plt.axvline(x=0.2, ls='--', color='black')\n",
    "\n",
    "\n",
    "#ax2.legend(loc='lower center',\n",
    "#          ncol=2)\n",
    "ax2.set_title('Nonmergers', loc='right')\n",
    "#ax1.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../MaNGA_Papers/Paper_I/n_A_S_overall.pdf') \n",
    "\n",
    "    \n",
    "#    savefig('../MaNGA_Papers/ePaper_I/Bayesian_Hist_'+str(run)+'.pdf')\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('done')\n",
    "print(r'$\\pm$')\n",
    "print(str(round(np.std(coef_list,axis=0)[0][0],2))+r' $\\pm$ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run fg3_m12_alliso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:221: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myr [30, 40, 60, 80, 100, 120, 140, 160, 170, 180, 185, 190, 195, 205, 210, 220, 225, 230, 240, 250, 260]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "std_scale mean [ 0.5257748  -1.78554059  3.099091    0.14246161  1.21511054  0.15368987]\n",
      "std_scale var [0.04782654 0.28856416 0.62700362 0.15084112 0.59729942 0.15540656]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 4.1609288  -1.36543768  2.62179352  4.95185848  3.15791192  3.12215882]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 4.17470792 -1.36036639  2.65349867  4.9659255   3.15719159  3.15365088]]\n",
      "[-8.82642992]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.27982845 0.29195162 0.31190489 0.41448807 0.24252398 0.35931986]]\n",
      "[0.26368272]\n",
      "fg3_m12_alliso & \n",
      "4.17 $\\pm$ 0.28 & \n",
      "-1.36 $\\pm$ 0.29 & \n",
      "2.65 $\\pm$ 0.31 & \n",
      "4.97 $\\pm$ 0.41 & \n",
      "3.16 $\\pm$ 0.24 & \n",
      "3.15 $\\pm$ 0.36 & \n",
      "-8.83 $\\pm$ 0.26//\n",
      "['Gini', 'M20', 'C', 'A', 'n', 'A_S']\n",
      "[-9.592213483788935, 36.93179042287966, -4.499860544280136, 25.978832981230234, -14.18078579099236, 46.00499225175834]\n",
      "[0.7411045703071905, 1.9791274560141463, 1.3014799734157059, 1.4187743061717373, 2.7018878245663798, 4.683038549134117]\n",
      "All interaction terms\n",
      "[[ -2.80074314  45.98075541  32.27369529   2.2602355  -13.93855341\n",
      "   41.4513896  -40.67806523 -36.88548003  -3.02931277  33.73036537\n",
      "  -32.05019838  -9.01438692  -3.37982775  -3.94898064  -6.27349113\n",
      "    0.45028105  -9.35703454  -2.08343677 -13.65283195]]\n",
      "[[0.89539311 4.42025071 3.38829608 7.86690204 5.08434434 5.04608705\n",
      "  5.4583894  6.01745916 7.71577153 5.60964941 5.24321285 1.77662669\n",
      "  1.67453691 3.31169079 2.90545219 2.42870895 3.23982108 4.01740798\n",
      "  1.40686889]]\n",
      "run fg1_m13_alliso\n",
      "myr [40, 50, 60, 70, 90, 120, 130, 140, 195, 200, 210, 215, 220, 225, 230, 235, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "std_scale mean [ 0.53363518 -1.82254835  3.26111063  0.12195174  1.22868713  0.1678297 ]\n",
      "std_scale var [0.05286595 0.34245219 0.69366965 0.11605439 0.55653594 0.1822133 ]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 5.35439029 -3.11516512  5.03083188  5.13697363 -0.07564073  1.95949274]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 5.37212044 -3.1336563   5.06492987  5.1648362  -0.08225323  1.97009566]]\n",
      "[-7.02952831]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.31584729 0.23738732 0.33663775 0.27308469 0.20825999 0.33283881]]\n",
      "[0.32955927]\n",
      "fg1_m13_alliso & \n",
      "5.37 $\\pm$ 0.32 & \n",
      "-3.13 $\\pm$ 0.24 & \n",
      "5.06 $\\pm$ 0.34 & \n",
      "5.16 $\\pm$ 0.27 & \n",
      "-0.08 $\\pm$ 0.21 & \n",
      "1.97 $\\pm$ 0.33 & \n",
      "-7.03 $\\pm$ 0.33//\n",
      "['Gini', 'M20', 'C', 'A', 'n', 'A_S']\n",
      "[13.439771533737181, 16.90332750391746, 34.98272960406784, 41.85931729249352, -14.93615249080814, 68.53904913892016]\n",
      "[2.2514439208511288, 4.04282672332046, 4.378383743752622, 2.6891149349732504, 3.8784936061226523, 2.1308663570758264]\n",
      "All interaction terms\n",
      "[[  9.67519563  15.76292119  51.5518533   24.21124038 -38.08518156\n",
      "   51.14743912 -15.76815594 -42.35388562 -15.05740089  46.51699611\n",
      "  -35.88829544   6.47832962  -0.0584804   -9.31350368  -3.52716577\n",
      "   -8.31313444  -7.54355005 -12.69210055  -5.17168407]]\n",
      "[[ 3.25722179  4.86003485  7.54247446  4.64349924  7.81619764  6.27695883\n",
      "   5.99674311 11.06460136  5.30460514 12.29919787  5.89565127  2.85154588\n",
      "   0.64831383  2.35488334  1.07653024  2.91973549  3.41019627  3.00676348\n",
      "   2.02022864]]\n",
      "run fg3_m15_alliso\n",
      "myr [60, 120, 150, 180, 210, 240, 270, 300, 320, 340, 360, 400, 420]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "std_scale mean [ 0.5097741  -1.76897196  2.93548409  0.10541085  1.00981552  0.12086474]\n",
      "std_scale var [0.03123415 0.16180426 0.22013719 0.0937227  0.30274627 0.1262214 ]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[-0.22792703 -1.41400938  3.08578835  1.95205955 -0.20283869  2.5501287 ]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[-0.23859387 -1.44197796  3.11751884  2.01489341 -0.21913467  2.59945767]]\n",
      "[-3.7556185]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.22085931 0.15975014 0.23376086 0.36367523 0.19983012 0.34019277]]\n",
      "[0.16662209]\n",
      "fg3_m15_alliso & \n",
      "-0.24 $\\pm$ 0.22 & \n",
      "-1.44 $\\pm$ 0.16 & \n",
      "3.12 $\\pm$ 0.23 & \n",
      "2.01 $\\pm$ 0.36 & \n",
      "-0.22 $\\pm$ 0.2 & \n",
      "2.6 $\\pm$ 0.34 & \n",
      "-3.76 $\\pm$ 0.17//\n",
      "['Gini', 'M20', 'C', 'A', 'n', 'A_S']\n",
      "[5.671311544282862, 7.749887797981661, 6.342549166779776, 11.124934473076173, -18.487187139639243, 22.985175740410952]\n",
      "[1.5130437429865355, 3.4370918260757164, 2.415736530628653, 6.895391606070273, 2.342252101640292, 4.887359554435755]\n",
      "All interaction terms\n",
      "[[ 36.47593541  -4.59073809 -10.40940935   4.54636465 -28.66093897\n",
      "   14.67967361  38.54884211 -28.62686339 -27.37254835   0.88898163\n",
      "  -24.62069752 -38.5150782    3.4703952    1.16661876  -8.83527579\n",
      "   30.56214646  31.98187051   3.73854407  -0.16017226]]\n",
      "[[ 6.33041284  5.67113016  4.38942542  4.79506652  6.08961766  4.48385459\n",
      "  10.80167288  8.88447222  7.53982768  6.64761955  4.0296372  10.74027431\n",
      "   4.75239287  4.48546141  3.73933863  6.65467386  3.56800323  1.9493423\n",
      "   0.79865815]]\n",
      "run fg3_m1_10_alliso\n",
      "myr [40, 60, 100, 200, 300, 400, 410, 420, 700, 800, 900, 1000, 1100]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "std_scale mean [ 0.50656757 -1.80118976  2.93667634  0.08823279  1.040786    0.10463782]\n",
      "std_scale var [0.0271898  0.12035291 0.22483636 0.04725672 0.38746827 0.09073321]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[-0.91442933  0.48277772  3.15923624  1.76366461  1.43398539  1.67437562]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[-0.91125938  0.46639468  3.1771289   1.77187396  1.41462381  1.7293407 ]]\n",
      "[-3.63536507]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.15569373 0.16916736 0.10637672 0.10207328 0.23908671 0.37418008]]\n",
      "[0.13124036]\n",
      "fg3_m1_10_alliso & \n",
      "-0.91 $\\pm$ 0.16 & \n",
      "0.47 $\\pm$ 0.17 & \n",
      "3.18 $\\pm$ 0.11 & \n",
      "1.77 $\\pm$ 0.1 & \n",
      "1.41 $\\pm$ 0.24 & \n",
      "1.73 $\\pm$ 0.37 & \n",
      "-3.64 $\\pm$ 0.13//\n",
      "['Gini', 'M20', 'C', 'A', 'n', 'A_S']\n",
      "[0.3275189600925268, -14.996468051201868, -0.1519636880577206, 8.899790283524796, 13.681991455863075, 12.498666037399333]\n",
      "[2.69167906902434, 2.3990107648915324, 3.1841741464664097, 2.4671846765581713, 2.5516100517350524, 2.1928631168962136]\n",
      "All interaction terms\n",
      "[[ 17.44470086 -15.91116221 -16.54800869   4.43718933  -2.63653449\n",
      "   34.0510644   39.02976281  16.29180491 -24.36038801 -17.07818627\n",
      "   -6.91110758 -13.56940371 -11.19402898 -17.80723685  22.28124999\n",
      "    9.64911487   5.9848795   -2.53229879  -0.31250606]]\n",
      "[[ 5.52932493  6.0769553   4.66901393  2.57039201  6.71149178  4.33452385\n",
      "  11.98170049  6.87743849  4.50772292 10.99765787  4.81757618 10.84349904\n",
      "   3.64274347  4.49511755  6.31679211  1.85638455  6.98889798  3.55133837\n",
      "   0.95873928]]\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "~~~\n",
    "Introducing Interaction terms\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "   # from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#example-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, target_names, title, cmap=plt.cm.Blues):\n",
    "    sns.set_style(\"dark\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    target_names=['Nonmerger','Merger']\n",
    "    plt.xticks(tick_marks, target_names)#, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('True label', size=20)\n",
    "    plt.xlabel('Predicted label', size=20)\n",
    "    \n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def lda_classify(v, levels, cutoffpoints):\n",
    "    for level, cutoff in zip(reversed(levels), reversed(cutoffpoints)):\n",
    "        if v > cutoff: return level\n",
    "    return levels[0]\n",
    "\n",
    "'''def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len((X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "        \n",
    "        print(( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ))\n",
    "\n",
    "        Xp = ( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det((X0)))) - (n_2-1)*(np.log(np.linalg.det((X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) '''\n",
    "\n",
    "def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len(np.cov(X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "\n",
    "        Xp = ( ((n_1-1)*np.cov(X0)) + ((n_2-1)*np.cov(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det(np.cov(X0)))) - (n_2-1)*(np.log(np.linalg.det(np.cov(X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) \n",
    "\n",
    "def plot_mean_and_CI(mean, lb, ub, color_mean=None, color_shading=None):\n",
    "        # plot the shaded range of the confidence intervals\n",
    "        plt.fill_between(range(mean.shape[0]), ub, lb,\n",
    "                         color=color_shading, alpha=.5)\n",
    "        # plot the mean on top\n",
    "        plt.plot(mean, color_mean)\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "\n",
    "#list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "#'fg3_m12_comp_real','fg1_m13_comp_real','fg3_m15_comp_real','fg3_m1_10_comp_real']#,'fg3_m15_alliso','fg3_m1_10_alliso']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "add_noise='no'\n",
    "priors_list=[[0.9,0.1],[0.9,0.1],[0.7,0.3],[0.7,0.3]]\n",
    "\n",
    "#list_runs=[ 'fg3_m12', 'fg1_m13', 'fg3_m15', 'fg3_m1_10']\n",
    "#priors_list=[[0.7,0.3],[0.9,0.1]]\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    print('run', add_on)\n",
    "    \n",
    "\n",
    "    run=list_runs[i]\n",
    "    \n",
    "    df = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "        ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "          \n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "    \n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "            df.set_value(j,'class label',0)\n",
    "    myr=[]\n",
    "    myr_non=[]\n",
    "    for j in range(len(df)):\n",
    "        if df[['class label']].values[j][0]==0.0:\n",
    "            myr_non.append(df[['Myr']].values[j][0])\n",
    "        else:\n",
    "            myr.append(df[['Myr']].values[j][0])\n",
    "    \n",
    "    myr_non=sorted(list(set(myr_non)))\n",
    "    myr=sorted(list(set(myr)))\n",
    "    \n",
    "    print('myr', myr)\n",
    "    print('myr_non', myr_non)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.dropna(inplace=True) # to drop the empty line at file-end\n",
    "    #print(df)\n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    def gini_m20(row):\n",
    "        return row['Gini']*row['M20']\n",
    "    def gini_C(row):\n",
    "        return row['Gini']*row['Concentration (C)']\n",
    "    def gini_A(row):\n",
    "        return row['Gini']*row['Asymmetry (A)']\n",
    "    def gini_n(row):\n",
    "        return row['Gini']*row['Sersic N']\n",
    "    def gini_A_S(row):\n",
    "        return row['Gini']*row['Shape Asymmetry']\n",
    "    \n",
    "    def M20_C(row):\n",
    "        return row['M20']*row['Concentration (C)']\n",
    "    def M20_A(row):\n",
    "        return row['M20']*row['Asymmetry (A)']\n",
    "    def M20_n(row):\n",
    "        return row['M20']*row['Sersic N']\n",
    "    def M20_A_S(row):\n",
    "        return row['M20']*row['Shape Asymmetry']\n",
    "    \n",
    "    def C_A(row):\n",
    "        return row['Concentration (C)']*row['Asymmetry (A)']\n",
    "    def C_n(row):\n",
    "        return row['Concentration (C)']*row['Sersic N']\n",
    "    def C_A_S(row):\n",
    "        return row['Concentration (C)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def A_n(row):\n",
    "        return row['Asymmetry (A)']*row['Sersic N']\n",
    "    def A_A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def n_A_S(row):\n",
    "        return row['Sersic N']*row['Shape Asymmetry']\n",
    "    \n",
    "    df['Gini*M20'] = df.apply(gini_m20,axis=1)\n",
    "    df['Gini*C'] = df.apply(gini_C,axis=1)\n",
    "    df['Gini*A'] = df.apply(gini_A,axis=1)\n",
    "    df['Gini*n'] = df.apply(gini_n,axis=1)\n",
    "    df['Gini*A_S'] = df.apply(gini_A_S,axis=1)\n",
    "    \n",
    "    df['M20*C'] = df.apply(M20_C,axis=1)\n",
    "    df['M20*A'] = df.apply(M20_A,axis=1)\n",
    "    df['M20*n'] = df.apply(M20_n,axis=1)\n",
    "    df['M20*A_S'] = df.apply(M20_A_S,axis=1)\n",
    "    \n",
    "    df['C*A'] = df.apply(C_A,axis=1)\n",
    "    df['C*n'] = df.apply(C_n,axis=1)\n",
    "    df['C*A_S'] = df.apply(C_A_S,axis=1)\n",
    "    \n",
    "    df['A*n'] = df.apply(A_n,axis=1)\n",
    "    df['A*A_S'] = df.apply(A_A_S,axis=1)\n",
    "    \n",
    "    df['n*A_S'] = df.apply(n_A_S,axis=1)\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    #'Clumpiness (S)',\n",
    "    \n",
    "    \n",
    "    y = df['class label'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_nonmerg=[]\n",
    "    X_merg=[]\n",
    "    \n",
    "    for l in range(len(y)):\n",
    "        if y[l]==0:\n",
    "            X_nonmerg.append(X[l])\n",
    "        else:\n",
    "            X_merg.append(X[l])\n",
    "            \n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    print('std_scale mean', std_scale.mean_)\n",
    "    print('std_scale var', np.sqrt(std_scale.var_))\n",
    "    \n",
    "    \n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    \n",
    "    n_params=6\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    print('input priors', priors_list[i])\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    \n",
    "    \n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    \n",
    "    print('coef', coef)\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    kf.get_n_splits(X, y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    coef_list=[]\n",
    "    inter_list=[]\n",
    "    confusion_master=[]\n",
    "    y_test_master=[]\n",
    "    pred_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        \n",
    "        sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "        #priors=[0.1,0.9],\n",
    "    \n",
    "    \n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        #print('coef kfold', coef)\n",
    "        coef_list.append(coef)\n",
    "        inter_list.append(inter)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred =sklearn_lda.predict(X_test)\n",
    "        \n",
    "        '''def predict_with_cutoff(colname, y_prob, df):\n",
    "            n_events = df[colname].values\n",
    "            event_rate = sum(n_events) / float(df.shape[0]) * 100\n",
    "            threshold = np.percentile(y_prob[:, 1], 100 - event_rate)\n",
    "            print \"Cutoff/threshold at: \" + str(threshold)\n",
    "            y_pred = [1 if x >= threshold else 0 for x in y_prob[:, 1]]\n",
    "            return y_pred'''\n",
    "        \n",
    "        '''plt.clf()\n",
    "        fig=plt.figure()#figsize=(6,6)\n",
    "        plot_confusion_matrix(confusion_matrix(pred,y_test)/np.sum(confusion_matrix(pred,y_test)), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'_'+str(count)+'.pdf')\n",
    "        #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "        plt.clf()'''\n",
    "        \n",
    "        confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        pred_master.append(pred)\n",
    "        y_test_master.append(y_test)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    print('~~~~~Stratified K-fold validation means  ~~~~~~')\n",
    "    print(np.mean(coef_list, axis=0))\n",
    "    print(np.mean(inter_list, axis=0))\n",
    "    print('~~~~~Stratified K-fold validation STD ~~~~~~')\n",
    "    print(np.std(coef_list, axis=0))\n",
    "    print(np.std(inter_list, axis=0))\n",
    "    \n",
    "    print(run+str(' & '))\n",
    "    for j in range(len(np.mean(coef_list,axis=0)[0])):\n",
    "        print(str(round(np.mean(coef_list,axis=0)[0][j],2))+r' $\\pm$ '+str(round(np.std(coef_list,axis=0)[0][j],2))+' & ')\n",
    "    print(str(round(np.mean(inter_list,axis=0)[0],2))+r' $\\pm$ '+str(round(np.std(inter_list,axis=0)[0],2))+ '//')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs=[['Gini','Gini*M20','Gini*C','Gini*A','Gini*n','Gini*A_S','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry'],\n",
    "           ['Gini','M20','Gini*M20','M20*C','M20*A','M20*n','M20*A_S','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry'],\n",
    "            ['Gini','M20','Concentration (C)','Gini*C','M20*C','C*A','C*n','C*A_S', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry'],\n",
    "           ['Gini','M20','Concentration (C)', 'Asymmetry (A)','Gini*A','M20*A','C*A','A*n','A*A_S', 'Sersic N', 'Shape Asymmetry'],\n",
    "            ['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N','Gini*n','M20*n','C*n','A*n','n*A_S', 'Shape Asymmetry'],\n",
    "            ['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry','Gini*A_S','M20*A_S','C*A_S','A*A_S','n*A_S']]\n",
    "    names=['Gini','M20','C','A','n','A_S']\n",
    "    coef_mean=[]\n",
    "    coef_std=[]\n",
    "    for k in range(len(names)):\n",
    "        X = df[inputs[k]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        n_params=11\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "        # LDA\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "        \n",
    "\n",
    "        from sklearn.model_selection import KFold\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "\n",
    "\n",
    "\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "\n",
    "            '''def predict_with_cutoff(colname, y_prob, df):\n",
    "                n_events = df[colname].values\n",
    "                event_rate = sum(n_events) / float(df.shape[0]) * 100\n",
    "                threshold = np.percentile(y_prob[:, 1], 100 - event_rate)\n",
    "                print \"Cutoff/threshold at: \" + str(threshold)\n",
    "                y_pred = [1 if x >= threshold else 0 for x in y_prob[:, 1]]\n",
    "                return y_pred'''\n",
    "\n",
    "            '''plt.clf()\n",
    "            fig=plt.figure()#figsize=(6,6)\n",
    "            plot_confusion_matrix(confusion_matrix(pred,y_test)/np.sum(confusion_matrix(pred,y_test)), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "            plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'_'+str(count)+'.pdf')\n",
    "            #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "            plt.clf()'''\n",
    "\n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "            pred_master.append(pred)\n",
    "            y_test_master.append(y_test)\n",
    "\n",
    "            count+=1\n",
    "\n",
    "        '''print(names[k])\n",
    "        print('~~~~~Stratified K-fold validation means  ~~~~~~')\n",
    "        print(np.mean(coef_list, axis=0))\n",
    "        print(np.mean(inter_list, axis=0))\n",
    "        print('~~~~~Stratified K-fold validation STD ~~~~~~')\n",
    "        print(np.std(coef_list, axis=0))\n",
    "        print(np.std(inter_list, axis=0))\n",
    "\n",
    "        print(run+str(' & '))\n",
    "        for j in range(len(np.mean(coef_list,axis=0)[0])):\n",
    "            print(str(round(np.mean(coef_list,axis=0)[0][j],2))+r' $\\pm$ '+str(round(np.std(coef_list,axis=0)[0][j],2))+' & ')\n",
    "        print(str(round(np.mean(inter_list,axis=0)[0],2))+r' $\\pm$ '+str(round(np.std(inter_list,axis=0)[0],2))+ '//')\n",
    "    \n",
    "    \n",
    "        print('This one remains', np.mean(coef_list, axis=0)[0][k],np.std(coef_list, axis=0)[0][k])\n",
    "        '''\n",
    "        coef_mean.append(np.mean(coef_list, axis=0)[0][k])\n",
    "        coef_std.append(np.std(coef_list, axis=0)[0][k])\n",
    "    print(names)\n",
    "    print(coef_mean)\n",
    "    print(coef_std)\n",
    "    \n",
    "    X = df[['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry',\n",
    "            'Gini*M20','Gini*C','Gini*A','Gini*n','Gini*A_S',\n",
    "            'M20*C','M20*A', 'M20*n', 'M20*A_S', \n",
    "            'C*A','C*n','C*A_S',\n",
    "           'A*n','A*A_S',\n",
    "           'n*A_S']].values\n",
    "    #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "    y = df['class label'].values\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "    n_params=11\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "    coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "\n",
    "\n",
    "    kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "    coef_list=[]\n",
    "    inter_list=[]\n",
    "    confusion_master=[]\n",
    "    y_test_master=[]\n",
    "    pred_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "        #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        #print('coef kfold', coef)\n",
    "        coef_list.append(coef)\n",
    "        inter_list.append(inter)\n",
    "    \n",
    "    print('All interaction terms')\n",
    "    print(np.mean(coef_list, axis=0))\n",
    "    print(np.std(coef_list, axis=0))\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run fg3_m12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:224: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myr [30, 40, 60, 80, 100, 120, 140, 160, 170, 180, 185, 190, 195, 205, 210, 220, 225, 230, 240, 250, 260]\n",
      "myr_non [5, 10, 20, 30, 100, 200]\n",
      "std_scale mean [ 0.56216358 -1.80708126  3.45039145  0.24625143  1.63168073  0.25897415]\n",
      "std_scale var [0.05245041 0.43745715 0.84951719 0.18940201 0.73393774 0.19572035]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 3.36780115 -1.14786965  0.66627301  2.08329974  1.95955989  1.76928175]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 3.37761798 -1.16378     0.67053273  2.10795748  1.98634493  1.77803902]]\n",
      "[0.36817424]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.16055875 0.2753071  0.14521916 0.27906921 0.34976501 0.10031492]]\n",
      "[0.14518777]\n",
      "fg3_m12 & \n",
      "3.38 $\\pm$ 0.16 & \n",
      "-1.16 $\\pm$ 0.28 & \n",
      "0.67 $\\pm$ 0.15 & \n",
      "2.11 $\\pm$ 0.28 & \n",
      "1.99 $\\pm$ 0.35 & \n",
      "1.78 $\\pm$ 0.1 & \n",
      "0.37 $\\pm$ 0.15//\n",
      "accuracy [4.2, 13.1, 12.5, 10.5, 8.2, 10.3, 13.1, 8.6, 10.5, 6.0, 10.1, 13.1, 8.8, 10.5, 9.4, 9.7, 8.0, 8.9, 11.1, 11.5, 9.5]\n",
      "4.2\n",
      "0\n",
      "Gini\n",
      "Gini Shape Asymmetry Gini*A_S M20 Concentration (C) Gini*M20 M20*A_S A*n Asymmetry (A) Sersic N Gini*C Gini*A\n",
      "4.2 2.7 0.5 0.5 0.5 0.5 0.5 0.5 0.6 0.4 0.4 0.4\n",
      "run fg1_m13\n",
      "myr [40, 50, 60, 70, 90, 120, 130, 140, 195, 200, 210, 215, 220, 225, 230, 235, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350]\n",
      "myr_non [5, 10, 100, 200]\n",
      "std_scale mean [ 0.58130262 -1.89237464  3.81202728  0.18793845  1.62151394  0.28658967]\n",
      "std_scale var [0.04401358 0.50083605 0.74646078 0.14935711 0.60166644 0.22385394]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 2.74402862 -1.68383841  1.09625417  2.12395182  0.55040387  0.91283295]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 2.77853774 -1.70716267  1.08524616  2.13729646  0.56862387  0.92615728]]\n",
      "[0.54692188]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.37481362 0.2152711  0.14694985 0.15857684 0.15095697 0.10872245]]\n",
      "[0.25078341]\n",
      "fg1_m13 & \n",
      "2.78 $\\pm$ 0.37 & \n",
      "-1.71 $\\pm$ 0.22 & \n",
      "1.09 $\\pm$ 0.15 & \n",
      "2.14 $\\pm$ 0.16 & \n",
      "0.57 $\\pm$ 0.15 & \n",
      "0.93 $\\pm$ 0.11 & \n",
      "0.55 $\\pm$ 0.25//\n",
      "accuracy [4.8, 15.9, 8.9, 15.0, 11.6, 13.9, 15.9, 7.0, 14.6, 7.1, 13.9, 15.5, 14.4, 13.9, 14.1, 14.1, 7.6, 13.6, 14.7, 15.2, 13.5]\n",
      "4.8\n",
      "0\n",
      "Gini\n",
      "Gini M20*A_S C*A Gini*A_S Shape Asymmetry Concentration (C) Gini*C M20 Asymmetry (A) Sersic N M20*A Gini*A\n",
      "4.8 3.5 3.1 3.0 1.5 1.3 1.2 1.2 1.1 1.1 1.1 1.0\n",
      "run fg3_m15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:212: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myr [60, 120, 150, 180, 210, 240, 270, 300, 320, 340, 360, 400, 420]\n",
      "myr_non [5, 30, 60, 90, 100, 120, 150, 180, 200]\n",
      "std_scale mean [ 0.52471852 -1.77587145  3.06981206  0.15880186  1.14262795  0.18224385]\n",
      "std_scale var [0.03821655 0.22925201 0.25485353 0.1251487  0.31417179 0.17997723]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[-0.20396525 -1.159875    2.24621667  0.76049949  0.4765361   2.27562377]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[-0.23617694 -1.19256967  2.30850936  0.77948841  0.47969295  2.32383962]]\n",
      "[-0.50346329]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.19029432 0.15777826 0.312806   0.25996582 0.06507179 0.31776047]]\n",
      "[0.04876467]\n",
      "fg3_m15 & \n",
      "-0.24 $\\pm$ 0.19 & \n",
      "-1.19 $\\pm$ 0.16 & \n",
      "2.31 $\\pm$ 0.31 & \n",
      "0.78 $\\pm$ 0.26 & \n",
      "0.48 $\\pm$ 0.07 & \n",
      "2.32 $\\pm$ 0.32 & \n",
      "-0.5 $\\pm$ 0.05//\n",
      "accuracy [4.5, 8.7, 4.5, 6.4, 7.1, 6.2, 9.1, 4.4, 6.3, 6.3, 6.1, 9.1, 5.2, 8.0, 6.2, 6.0, 6.0, 6.1, 6.5, 7.9, 6.5]\n",
      "4.4\n",
      "7\n",
      "Gini*C\n",
      "Gini*C Shape Asymmetry Gini*A_S A*A_S Concentration (C) Gini Asymmetry (A) M20*C M20*A_S M20 Gini*M20 Sersic N\n",
      "4.4 3.4 2.9 2.6 2.5 2.1 2.1 1.6 1.3 1.3 1.3 1.4\n",
      "run fg3_m1_10\n",
      "myr [40, 60, 100, 200, 300, 400, 410, 420, 700, 800, 900, 1000, 1100]\n",
      "myr_non [5, 30, 60, 90, 100, 120, 150, 180, 200]\n",
      "std_scale mean [ 0.51702376 -1.8590944   3.07832384  0.11498909  1.22778     0.1416191 ]\n",
      "std_scale var [0.03281041 0.13408227 0.26317988 0.05212599 0.47229924 0.13208071]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[-1.17495086  0.61889605  2.41649771  1.3082302   1.33403202  1.29208028]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[-1.19060878  0.61865801  2.44552161  1.32494476  1.33373825  1.34326485]]\n",
      "[-0.61311656]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.2761167  0.20903746 0.19955563 0.14757103 0.14049231 0.27790259]]\n",
      "[0.05159335]\n",
      "fg3_m1_10 & \n",
      "-1.19 $\\pm$ 0.28 & \n",
      "0.62 $\\pm$ 0.21 & \n",
      "2.45 $\\pm$ 0.2 & \n",
      "1.32 $\\pm$ 0.15 & \n",
      "1.33 $\\pm$ 0.14 & \n",
      "1.34 $\\pm$ 0.28 & \n",
      "-0.61 $\\pm$ 0.05//\n",
      "accuracy [5.8, 6.6, 4.1, 5.8, 5.8, 6.5, 5.2, 4.2, 5.7, 5.7, 6.8, 5.3, 5.3, 5.8, 6.5, 5.3, 5.4, 6.4, 5.0, 7.4, 5.6]\n",
      "4.1\n",
      "2\n",
      "Concentration (C)\n",
      "Concentration (C) M20*A_S Gini*M20 Sersic N C*n M20*n Asymmetry (A) C*A Shape Asymmetry n*A_S C*A_S Gini*n\n",
      "4.1 3.3 3.3 3.1 2.6 2.2 2.2 1.5 1.4 1.4 1.4 1.3\n"
     ]
    }
   ],
   "source": [
    "'''Selection of which predictors including interaction terms'''\n",
    "\n",
    "'''\n",
    "~~~\n",
    "Introducing Interaction terms\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "   # from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#example-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, target_names, title, cmap=plt.cm.Blues):\n",
    "    sns.set_style(\"dark\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    target_names=['Nonmerger','Merger']\n",
    "    plt.xticks(tick_marks, target_names)#, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('True label', size=20)\n",
    "    plt.xlabel('Predicted label', size=20)\n",
    "    \n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def lda_classify(v, levels, cutoffpoints):\n",
    "    for level, cutoff in zip(reversed(levels), reversed(cutoffpoints)):\n",
    "        if v > cutoff: return level\n",
    "    return levels[0]\n",
    "\n",
    "'''def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len((X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "        \n",
    "        print(( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ))\n",
    "\n",
    "        Xp = ( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det((X0)))) - (n_2-1)*(np.log(np.linalg.det((X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) '''\n",
    "\n",
    "def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len(np.cov(X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "\n",
    "        Xp = ( ((n_1-1)*np.cov(X0)) + ((n_2-1)*np.cov(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det(np.cov(X0)))) - (n_2-1)*(np.log(np.linalg.det(np.cov(X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) \n",
    "\n",
    "def plot_mean_and_CI(mean, lb, ub, color_mean=None, color_shading=None):\n",
    "        # plot the shaded range of the confidence intervals\n",
    "        plt.fill_between(range(mean.shape[0]), ub, lb,\n",
    "                         color=color_shading, alpha=.5)\n",
    "        # plot the mean on top\n",
    "        plt.plot(mean, color_mean)\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12_no_200', 'fg1_m13_no_200', 'fg3_m15_no_200', 'fg3_m1_10_no_200']\n",
    "colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"]]\n",
    "names=['q0.5_fg0.3','q0.333_fg0.1','q0.2_fg0.3_BT0.2','q0.1_fg0.3_BT0.2']\n",
    "#list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "#'fg3_m12_comp_real','fg1_m13_comp_real','fg3_m15_comp_real','fg3_m1_10_comp_real']#,'fg3_m15_alliso','fg3_m1_10_alliso']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "add_noise='no'\n",
    "priors_list=[[0.9,0.1],[0.9,0.1],[0.7,0.3],[0.7,0.3]]\n",
    "plt.clf()\n",
    "#list_runs=[ 'fg3_m12', 'fg1_m13', 'fg3_m15', 'fg3_m1_10']\n",
    "#priors_list=[[0.7,0.3],[0.9,0.1]]\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    print('run', add_on)\n",
    "    \n",
    "\n",
    "    run=list_runs[i]\n",
    "    \n",
    "    df = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "        ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "          \n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "    \n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "            df.set_value(j,'class label',0)\n",
    "    myr=[]\n",
    "    myr_non=[]\n",
    "    for j in range(len(df)):\n",
    "        if df[['class label']].values[j][0]==0.0:\n",
    "            myr_non.append(df[['Myr']].values[j][0])\n",
    "        else:\n",
    "            myr.append(df[['Myr']].values[j][0])\n",
    "    \n",
    "    myr_non=sorted(list(set(myr_non)))\n",
    "    myr=sorted(list(set(myr)))\n",
    "    \n",
    "    print('myr', myr)\n",
    "    print('myr_non', myr_non)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.dropna(inplace=True) # to drop the empty line at file-end\n",
    "    #print(df)\n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    def gini_m20(row):\n",
    "        return row['Gini']*row['M20']\n",
    "    def gini_C(row):\n",
    "        return row['Gini']*row['Concentration (C)']\n",
    "    def gini_A(row):\n",
    "        return row['Gini']*row['Asymmetry (A)']\n",
    "    def gini_n(row):\n",
    "        return row['Gini']*row['Sersic N']\n",
    "    def gini_A_S(row):\n",
    "        return row['Gini']*row['Shape Asymmetry']\n",
    "    \n",
    "    def M20_C(row):\n",
    "        return row['M20']*row['Concentration (C)']\n",
    "    def M20_A(row):\n",
    "        return row['M20']*row['Asymmetry (A)']\n",
    "    def M20_n(row):\n",
    "        return row['M20']*row['Sersic N']\n",
    "    def M20_A_S(row):\n",
    "        return row['M20']*row['Shape Asymmetry']\n",
    "    \n",
    "    def C_A(row):\n",
    "        return row['Concentration (C)']*row['Asymmetry (A)']\n",
    "    def C_n(row):\n",
    "        return row['Concentration (C)']*row['Sersic N']\n",
    "    def C_A_S(row):\n",
    "        return row['Concentration (C)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def A_n(row):\n",
    "        return row['Asymmetry (A)']*row['Sersic N']\n",
    "    def A_A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def n_A_S(row):\n",
    "        return row['Sersic N']*row['Shape Asymmetry']\n",
    "    \n",
    "    df['Gini*M20'] = df.apply(gini_m20,axis=1)\n",
    "    df['Gini*C'] = df.apply(gini_C,axis=1)\n",
    "    df['Gini*A'] = df.apply(gini_A,axis=1)\n",
    "    df['Gini*n'] = df.apply(gini_n,axis=1)\n",
    "    df['Gini*A_S'] = df.apply(gini_A_S,axis=1)\n",
    "    \n",
    "    df['M20*C'] = df.apply(M20_C,axis=1)\n",
    "    df['M20*A'] = df.apply(M20_A,axis=1)\n",
    "    df['M20*n'] = df.apply(M20_n,axis=1)\n",
    "    df['M20*A_S'] = df.apply(M20_A_S,axis=1)\n",
    "    \n",
    "    df['C*A'] = df.apply(C_A,axis=1)\n",
    "    df['C*n'] = df.apply(C_n,axis=1)\n",
    "    df['C*A_S'] = df.apply(C_A_S,axis=1)\n",
    "    \n",
    "    df['A*n'] = df.apply(A_n,axis=1)\n",
    "    df['A*A_S'] = df.apply(A_A_S,axis=1)\n",
    "    \n",
    "    df['n*A_S'] = df.apply(n_A_S,axis=1)\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    #'Clumpiness (S)',\n",
    "    \n",
    "    \n",
    "    y = df['class label'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_nonmerg=[]\n",
    "    X_merg=[]\n",
    "    \n",
    "    for l in range(len(y)):\n",
    "        if y[l]==0:\n",
    "            X_nonmerg.append(X[l])\n",
    "        else:\n",
    "            X_merg.append(X[l])\n",
    "            \n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    print('std_scale mean', std_scale.mean_)\n",
    "    print('std_scale var', np.sqrt(std_scale.var_))\n",
    "    \n",
    "    \n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    \n",
    "    n_params=6\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    print('input priors', priors_list[i])\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    \n",
    "    \n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    \n",
    "    print('coef', coef)\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    kf.get_n_splits(X, y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    coef_list=[]\n",
    "    inter_list=[]\n",
    "    confusion_master=[]\n",
    "    y_test_master=[]\n",
    "    pred_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        \n",
    "        sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "        #priors=[0.1,0.9],\n",
    "    \n",
    "    \n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        #print('coef kfold', coef)\n",
    "        coef_list.append(coef)\n",
    "        inter_list.append(inter)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred =sklearn_lda.predict(X_test)\n",
    "        \n",
    "        '''def predict_with_cutoff(colname, y_prob, df):\n",
    "            n_events = df[colname].values\n",
    "            event_rate = sum(n_events) / float(df.shape[0]) * 100\n",
    "            threshold = np.percentile(y_prob[:, 1], 100 - event_rate)\n",
    "            print \"Cutoff/threshold at: \" + str(threshold)\n",
    "            y_pred = [1 if x >= threshold else 0 for x in y_prob[:, 1]]\n",
    "            return y_pred'''\n",
    "        \n",
    "        '''plt.clf()\n",
    "        fig=plt.figure()#figsize=(6,6)\n",
    "        plot_confusion_matrix(confusion_matrix(pred,y_test)/np.sum(confusion_matrix(pred,y_test)), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'_'+str(count)+'.pdf')\n",
    "        #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "        plt.clf()'''\n",
    "        \n",
    "        confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        pred_master.append(pred)\n",
    "        y_test_master.append(y_test)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    print('~~~~~Stratified K-fold validation means  ~~~~~~')\n",
    "    print(np.mean(coef_list, axis=0))\n",
    "    print(np.mean(inter_list, axis=0))\n",
    "    print('~~~~~Stratified K-fold validation STD ~~~~~~')\n",
    "    print(np.std(coef_list, axis=0))\n",
    "    print(np.std(inter_list, axis=0))\n",
    "    \n",
    "    print(run+str(' & '))\n",
    "    for j in range(len(np.mean(coef_list,axis=0)[0])):\n",
    "        print(str(round(np.mean(coef_list,axis=0)[0][j],2))+r' $\\pm$ '+str(round(np.std(coef_list,axis=0)[0][j],2))+' & ')\n",
    "    print(str(round(np.mean(inter_list,axis=0)[0],2))+r' $\\pm$ '+str(round(np.std(inter_list,axis=0)[0],2))+ '//')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs=['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry',\n",
    "            'Gini*M20','Gini*C','Gini*A','Gini*n','Gini*A_S',\n",
    "            'M20*C','M20*A', 'M20*n', 'M20*A_S', \n",
    "            'C*A','C*n','C*A_S',\n",
    "           'A*n','A*A_S',\n",
    "           'n*A_S']\n",
    "    coef_mean=[]\n",
    "    coef_std=[]\n",
    "    coef_mean_std=[]\n",
    "    accuracy=[]\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "        # LDA\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        '''print(master)\n",
    "        print(master[1][0])#row, then column\n",
    "        print('~~~Accuracy~~~')\n",
    "        print((master[1][1]+master[0][0])/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "        print('~~~Precision~~~')\n",
    "        print(master[1][1]/(master[0][1]+master[1][1]))#TP/(TP+FP)\n",
    "        print('~~~Recall~~~')\n",
    "        print(master[1][1]/(master[1][0]+master[1][1]))#TP/(TP+FN)\n",
    "        print('~~~F1~~~')\n",
    "        print((2*master[1][1])/(master[0][1]+master[1][0]+2*master[1][1]))#2TP/(2TP+FP+FN)'''\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        coef_mean.append(np.mean(coef_list, axis=0))\n",
    "        coef_std.append(np.std(coef_list, axis=0))\n",
    "        coef_mean_std.append(abs(np.mean(coef_list, axis=0))-np.std(coef_list, axis=0))\n",
    "    \n",
    "    print('accuracy', accuracy)\n",
    "    print(min(accuracy))\n",
    "    print(accuracy.index(min(accuracy)))\n",
    "    print(inputs[accuracy.index(min(accuracy))])\n",
    "    first_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    first_A=min(accuracy)\n",
    "    '''Now we select the second one that IMPROVES THE ACCURACY'''\n",
    "    inputs.remove(str(inputs[accuracy.index(min(accuracy))]))\n",
    "    \n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master,axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "    '''if min(accuracy) > first_A:\n",
    "        print(first_thing)\n",
    "        STOP'''\n",
    "    second_A=min(accuracy)\n",
    "    second_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(second_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "    third_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    third_A=min(accuracy)\n",
    "    inputs.remove(third_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    fourth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    fourth_A=min(accuracy)\n",
    "    \n",
    "    inputs.remove(fourth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    fifth_A=min(accuracy)\n",
    "    fifth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(fifth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,fifth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    sixth_A=min(accuracy)\n",
    "    sixth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(sixth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    seventh_A=min(accuracy)\n",
    "    seventh_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(seventh_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    eighth_A=min(accuracy)\n",
    "    eighth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    \n",
    "    inputs.remove(eighth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    ninth_A=min(accuracy)\n",
    "    ninth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    \n",
    "    inputs.remove(ninth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    tenth_A=min(accuracy)\n",
    "    tenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(tenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    eleventh_A=min(accuracy)\n",
    "    eleventh_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(eleventh_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    twelth_A=min(accuracy)\n",
    "    twelth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    print(first_thing, second_thing, third_thing, fourth_thing, fifth_thing, sixth_thing,\n",
    "         seventh_thing,eighth_thing, ninth_thing,tenth_thing, eleventh_thing, twelth_thing)\n",
    "    print(first_A, second_A, third_A, fourth_A, fifth_A, sixth_A,\n",
    "         seventh_A,eighth_A, ninth_A, tenth_A, eleventh_A, twelth_A)\n",
    "    \n",
    "    missclass=[first_A,second_A,third_A,fourth_A,fifth_A,sixth_A,seventh_A,eighth_A,\n",
    "              ninth_A,tenth_A, eleventh_A, twelth_A]\n",
    "    num_comps=[1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    \n",
    "    min_A=min(missclass)\n",
    "    min_comps=num_comps[missclass.index(min(missclass))]\n",
    "    plt.plot(num_comps,missclass, color=colors[i], label=names[i])\n",
    "    plt.scatter(min_comps,min_A, marker='x',color='black')\n",
    "    #plt.scatter(num_comps,missclass, color=colors[i], edgecolor='black', alpha=100)\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel('Cross-Validation Error')\n",
    "plt.legend()\n",
    "plt.savefig('../MaNGA_Papers/Paper_I/CV_variable_selection.pdf')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run fg3_m12_no_200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:351: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_scale mean [ 0.54507963 -1.77059676  3.28756292  0.20924545  0.11664004  1.40959046\n",
      "  0.22127319]\n",
      "std_scale var [0.05807988 0.39261558 0.82014827 0.18345029 0.06558203 0.73823792\n",
      " 0.19004855]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 5.76387129 -1.85249314  1.2500407   5.01586697 -2.31987016  5.0070893\n",
      "   2.03218167]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 5.80101547 -1.86075949  1.24912998  5.02633785 -2.33012569  5.03342566\n",
      "   2.04894713]]\n",
      "[-1.04983594]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.263677   0.39592677 0.25929772 0.51689588 0.21292841 0.30599017\n",
      "  0.16318193]]\n",
      "[0.03488838]\n",
      "fg3_m12_no_200 & \n",
      "5.8 $\\pm$ 0.26 & \n",
      "-1.86 $\\pm$ 0.4 & \n",
      "1.25 $\\pm$ 0.26 & \n",
      "5.03 $\\pm$ 0.52 & \n",
      "-2.33 $\\pm$ 0.21 & \n",
      "5.03 $\\pm$ 0.31 & \n",
      "2.05 $\\pm$ 0.16 & \n",
      "-1.05 $\\pm$ 0.03//\n",
      "accuracy [3.2, 13.1, 9.6, 9.9, 10.4, 4.0, 9.1, 12.6, 6.6, 9.4, 9.6, 3.4, 8.9, 11.8, 6.0, 9.9, 6.2, 8.5, 8.9, 9.5, 5.8, 7.4, 11.1, 10.2, 11.3, 7.9, 10.1, 8.1]\n",
      "3.2\n",
      "0\n",
      "Gini\n",
      "Gini Sersic N Gini*n Asymmetry (A) A*n M20 Concentration (C) Shape Asymmetry Gini*M20 Gini*C Gini*A Gini*A_S M20*A M20*n Clumpiness (S) Gini*S M20*C M20*S M20*A_S C*A C*S C*n C*A_S A*S A*A_S S*n\n",
      "3.2 1.4 0.7 0.4 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n",
      "run fg1_m13_no_200\n",
      "std_scale mean [ 0.56390047 -1.85092417  3.58690291  0.16161305  0.1237425   1.42850467\n",
      "  0.2435008 ]\n",
      "std_scale var [0.05303224 0.45469322 0.80050729 0.14421751 0.07112324 0.64603526\n",
      " 0.21938039]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 4.58957469 -2.80264898  4.22380127  4.83498346 -2.2207304   0.77669391\n",
      "   1.4499716 ]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 4.63307461 -2.81936431  4.22640221  4.84652339 -2.21698644  0.77251192\n",
      "   1.46811935]]\n",
      "[0.24045895]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.36770477 0.25806828 0.38215819 0.25180084 0.30350119 0.26617685\n",
      "  0.27539408]]\n",
      "[0.16393569]\n",
      "fg1_m13_no_200 & \n",
      "4.63 $\\pm$ 0.37 & \n",
      "-2.82 $\\pm$ 0.26 & \n",
      "4.23 $\\pm$ 0.38 & \n",
      "4.85 $\\pm$ 0.25 & \n",
      "-2.22 $\\pm$ 0.3 & \n",
      "0.77 $\\pm$ 0.27 & \n",
      "1.47 $\\pm$ 0.28 & \n",
      "0.24 $\\pm$ 0.16//\n",
      "accuracy [2.4, 15.9, 6.3, 13.6, 9.3, 5.8, 13.2, 15.4, 4.8, 12.7, 9.0, 5.4, 13.3, 11.5, 12.2, 9.9, 9.1, 12.7, 12.0, 9.6, 5.9, 12.2, 12.9, 12.5, 14.6, 7.8, 13.7, 12.0]\n",
      "2.4\n",
      "0\n",
      "Gini\n",
      "Gini Shape Asymmetry Gini*A_S Concentration (C) C*A_S M20*S Sersic N M20 C*A Asymmetry (A) M20*n Clumpiness (S) Gini*A M20*C M20*A M20*A_S Gini*C Gini*S Gini*M20 Gini*n C*S C*n A*A_S A*S S*n A*n\n",
      "2.4 1.7 1.2 1.0 0.8 0.6 0.6 0.6 0.6 0.6 0.4 0.4 0.5 0.5 0.5 0.5 0.6 0.6 0.6 0.6 0.6 0.7 0.7 0.5 0.5 0.6\n",
      "run fg3_m15_no_200\n",
      "std_scale mean [ 0.53139306 -1.80844536  3.11583766  0.15295292  0.09055393  1.18849788\n",
      "  0.19503245]\n",
      "std_scale var [0.03889787 0.22719494 0.25878813 0.11648682 0.04013812 0.32409258\n",
      " 0.17800784]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[-0.06747364 -1.06116648  2.47439652  0.67022231 -0.35310297  0.19630515\n",
      "   2.28668247]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[-0.10259892 -1.09157893  2.54219891  0.67864038 -0.35265235  0.19019669\n",
      "   2.35056806]]\n",
      "[0.06123547]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.24073584 0.16304058 0.35303841 0.28545995 0.13721496 0.18346481\n",
      "  0.283076  ]]\n",
      "[0.09814325]\n",
      "fg3_m15_no_200 & \n",
      "-0.1 $\\pm$ 0.24 & \n",
      "-1.09 $\\pm$ 0.16 & \n",
      "2.54 $\\pm$ 0.35 & \n",
      "0.68 $\\pm$ 0.29 & \n",
      "-0.35 $\\pm$ 0.14 & \n",
      "0.19 $\\pm$ 0.18 & \n",
      "2.35 $\\pm$ 0.28 & \n",
      "0.06 $\\pm$ 0.1//\n",
      "accuracy [5.5, 12.6, 5.5, 10.0, 11.0, 9.5, 9.4, 10.7, 4.9, 9.7, 10.9, 8.4, 9.4, 10.5, 9.0, 10.9, 9.9, 8.9, 9.5, 10.7, 7.7, 9.1, 11.1, 9.5, 11.7, 7.6, 11.3, 8.2]\n",
      "4.9\n",
      "8\n",
      "Gini*C\n",
      "Gini*C M20*A_S C*n Concentration (C) Gini M20*A M20 Shape Asymmetry A*A_S Gini*A_S Asymmetry (A) C*S Gini*M20 Gini*S n*A_S M20*n Gini*n C*A Gini*A Sersic N M20*C S*A_S C*A_S S*n Clumpiness (S) M20*S\n",
      "4.9 3.9 3.3 2.9 2.0 1.8 1.8 1.8 1.6 1.5 1.2 1.1 1.1 1.1 1.1 1.1 1.0 1.0 1.0 1.0 1.0 1.0 1.2 1.3 1.3 1.4\n",
      "run fg3_m1_10_no_200\n",
      "std_scale mean [ 0.52146969 -1.89102164  3.14274471  0.11656778  0.09645624  1.31950651\n",
      "  0.1542379 ]\n",
      "std_scale var [0.03249144 0.15344897 0.28938236 0.06002134 0.04471882 0.51508337\n",
      " 0.13140449]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[-1.16829432  0.66700867  1.82877314 -0.06047931  1.84638706  2.31385572\n",
      "   1.58053198]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[-1.1726121   0.67742713  1.84672034 -0.06665635  1.86395074  2.33771755\n",
      "   1.61769733]]\n",
      "[-0.13774081]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.23175938 0.18543129 0.29842806 0.11356517 0.27632097 0.16818958\n",
      "  0.23984935]]\n",
      "[0.0977329]\n",
      "fg3_m1_10_no_200 & \n",
      "-1.17 $\\pm$ 0.23 & \n",
      "0.68 $\\pm$ 0.19 & \n",
      "1.85 $\\pm$ 0.3 & \n",
      "-0.07 $\\pm$ 0.11 & \n",
      "1.86 $\\pm$ 0.28 & \n",
      "2.34 $\\pm$ 0.17 & \n",
      "1.62 $\\pm$ 0.24 & \n",
      "-0.14 $\\pm$ 0.1//\n",
      "accuracy [6.0, 7.1, 4.1, 8.3, 8.1, 6.4, 8.3, 5.5, 4.4, 8.1, 8.3, 6.3, 8.4, 5.5, 7.9, 7.4, 6.4, 8.1, 7.8, 8.2, 6.0, 7.9, 9.2, 7.2, 8.7, 4.6, 8.6, 7.0]\n",
      "4.1\n",
      "2\n",
      "Concentration (C)\n",
      "Concentration (C) Shape Asymmetry Gini*A_S M20*A_S M20*n C*n Sersic N Asymmetry (A) C*A Gini*M20 Gini*S Gini*A Gini*n C*A_S A*n C*S Gini M20 Gini*C n*A_S S*n M20*C A*A_S M20*A S*A_S A*S\n",
      "4.1 3.3 3.0 2.9 2.7 2.2 2.0 1.9 1.4 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.3 1.4 1.4 1.3 1.5 1.6 1.7 1.6 1.7 1.8\n",
      "run all\n",
      "106\n",
      "126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:241: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n",
      "159\n",
      "lengths [106, 126, 133, 159] 106\n",
      "LENGTH NOW 106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:282: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH NOW 106\n",
      "LENGTH NOW 36\n",
      "LENGTH NOW 36\n",
      "['q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_010.fits'] 10 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_020.fits'] 20 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_030.fits'] 30 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_020.fits'] 20 [0]\n",
      "std_scale mean [ 0.5251703  -1.82185801  3.1128426   0.12416896  0.08947257  1.20059307\n",
      "  0.15966539]\n",
      "std_scale var [0.04281955 0.24545313 0.48293184 0.10842828 0.04865795 0.4926465\n",
      " 0.15788453]\n",
      "input priors [0.75, 0.25]\n",
      "coef [[ 0.04202849 -1.01188035  0.74356348  1.27836914  0.88829522  1.00275883\n",
      "   1.17218123]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 0.03959468 -1.01996526  0.74367661  1.28447174  0.89142004  1.00292504\n",
      "   1.18430317]]\n",
      "[-1.39589672]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.11365759 0.06444428 0.07544351 0.08026412 0.08045932 0.05993407\n",
      "  0.09750588]]\n",
      "[0.05713569]\n",
      "all & \n",
      "0.04 $\\pm$ 0.11 & \n",
      "-1.02 $\\pm$ 0.06 & \n",
      "0.74 $\\pm$ 0.08 & \n",
      "1.28 $\\pm$ 0.08 & \n",
      "0.89 $\\pm$ 0.08 & \n",
      "1.0 $\\pm$ 0.06 & \n",
      "1.18 $\\pm$ 0.1 & \n",
      "-1.4 $\\pm$ 0.06//\n",
      "accuracy [13.9, 25.9, 17.0, 20.0, 17.4, 15.1, 18.4, 18.7, 15.0, 19.5, 17.5, 15.1, 18.5, 19.4, 17.2, 18.4, 17.7, 17.8, 18.1, 19.1, 16.1, 17.8, 21.1, 19.9, 23.0, 17.6, 20.4, 17.2]\n",
      "13.9\n",
      "0\n",
      "Gini\n",
      "Gini Sersic N Gini*n C*A Concentration (C) Shape Asymmetry Gini*A_S C*n n*A_S A*A_S S*n M20 A*S Gini*C M20*A_S Gini*M20 C*S M20*S Gini*S M20*A A*n Clumpiness (S) C*A_S Asymmetry (A) M20*C M20*n\n",
      "13.9 11.1 9.9 8.3 8.0 7.2 6.6 5.7 5.4 5.3 5.2 5.2 5.2 5.1 4.7 4.7 4.7 4.8 4.9 5.0 5.0 5.1 5.1 5.1 4.9 4.8\n"
     ]
    }
   ],
   "source": [
    "'''Forward selection, adding in S'''\n",
    "'''Selection of which predictors including interaction terms'''\n",
    "\n",
    "'''\n",
    "~~~\n",
    "Introducing Interaction terms\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "   # from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#example-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, target_names, title, cmap=plt.cm.Blues):\n",
    "    sns.set_style(\"dark\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    target_names=['Nonmerger','Merger']\n",
    "    plt.xticks(tick_marks, target_names)#, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('True label', size=20)\n",
    "    plt.xlabel('Predicted label', size=20)\n",
    "    \n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def lda_classify(v, levels, cutoffpoints):\n",
    "    for level, cutoff in zip(reversed(levels), reversed(cutoffpoints)):\n",
    "        if v > cutoff: return level\n",
    "    return levels[0]\n",
    "\n",
    "'''def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len((X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "        \n",
    "        print(( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ))\n",
    "\n",
    "        Xp = ( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det((X0)))) - (n_2-1)*(np.log(np.linalg.det((X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) '''\n",
    "\n",
    "def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len(np.cov(X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "\n",
    "        Xp = ( ((n_1-1)*np.cov(X0)) + ((n_2-1)*np.cov(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det(np.cov(X0)))) - (n_2-1)*(np.log(np.linalg.det(np.cov(X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) \n",
    "\n",
    "def plot_mean_and_CI(mean, lb, ub, color_mean=None, color_shading=None):\n",
    "        # plot the shaded range of the confidence intervals\n",
    "        plt.fill_between(range(mean.shape[0]), ub, lb,\n",
    "                         color=color_shading, alpha=.5)\n",
    "        # plot the mean on top\n",
    "        plt.plot(mean, color_mean)\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12_no_200', 'fg1_m13_no_200', 'fg3_m15_no_200', 'fg3_m1_10_no_200','all']\n",
    "colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"],sns.xkcd_rgb[\"black\"]]\n",
    "#colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"]]\n",
    "names=['q0.5_fg0.3','q0.333_fg0.1','q0.2_fg0.3_BT0.2','q0.1_fg0.3_BT0.2','All Combined']\n",
    "\n",
    "#list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "#'fg3_m12_comp_real','fg1_m13_comp_real','fg3_m15_comp_real','fg3_m1_10_comp_real']#,'fg3_m15_alliso','fg3_m1_10_alliso']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "add_noise='no'\n",
    "priors_list=[[0.9,0.1],[0.9,0.1],[0.7,0.3],[0.7,0.3],[0.75,0.25]]\n",
    "plt.clf()\n",
    "#list_runs=[ 'fg3_m12', 'fg1_m13', 'fg3_m15', 'fg3_m1_10']\n",
    "#priors_list=[[0.7,0.3],[0.9,0.1]]\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    print('run', add_on)\n",
    "    \n",
    "    if add_on=='all':\n",
    "        lists=['fg3_m1_10_alone', 'fg3_m15_alone', 'fg3_m12_alone', 'fg1_m13_alone']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "        #add_noise='yes'\n",
    "        '''\n",
    "        So the time covered differs for different simulations.\n",
    "        We want to retain this in the data.\n",
    "        Minor mergers are 3x as frequent.\n",
    "        Since galaxies merge on average w/i 1-2 Gyr a lot of this will be washed out.\n",
    "        Because of the frequency of most mergers a lot of this will be washed out meaning that\n",
    "        it is probably unrealistic to combine the simulations together.\n",
    "        But we do so anyway making sure we have 3x the number of minor mergers as major mergers.\n",
    "        So we are limited by the smallest sample size.\n",
    "        '''\n",
    "\n",
    "        lens=[]\n",
    "\n",
    "        for p in range(len(lists)):\n",
    "\n",
    "            add_on=lists[p]\n",
    "            run=lists[p]\n",
    "\n",
    "            df = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "            df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "            df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            '''index_list=[]\n",
    "            for j in range(len(df)):\n",
    "                if df[['class label']].values[j][0]==0:\n",
    "                    index_list.append(j)\n",
    "\n",
    "            df.drop(df.index[index_list], inplace=True)'''\n",
    "\n",
    "            counter=0\n",
    "\n",
    "            for j in range(len(df)):\n",
    "                \n",
    "                if df[['Myr']].values[counter][0]<40 and df[['Sep']].values[counter][0]==0.0 and df[['# Bulges']].values[counter][0]==1:#df[['Myr']].values[i][0]\n",
    "                    df.set_value(counter,'class label',0.0)\n",
    "                    df.drop(df.index[counter], inplace=True)\n",
    "                else:\n",
    "                    counter+=1\n",
    "\n",
    "            print(len(df))\n",
    "            lens.append(len(df))\n",
    "\n",
    "\n",
    "        print('lengths', lens, min(lens[0],lens[1])) \n",
    "        length=min(lens[0],lens[1])\n",
    "\n",
    "        names_df=['df1', 'df2', 'df3', 'df4']\n",
    "        dfs=[]\n",
    "\n",
    "        for p in range(len(lists)):\n",
    "\n",
    "            add_on=lists[p]\n",
    "            run=lists[p]\n",
    "\n",
    "            names_df[p] = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "            names_df[p].columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "            names_df[p].dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "            '''for j in range(len(names_df)):\n",
    "                if names_df[['class label']].values[j]<1:\n",
    "                    print(names_df[['Image']].values[j],names_df[['Myr']].values[j][0],names_df[['class label']].values[j])\n",
    "\n",
    "            '''\n",
    "\n",
    "            counter=0\n",
    "            OG_length=len(names_df[p])\n",
    "            for j in range(len(names_df[p])):\n",
    "                if names_df[p][['Myr']].values[j][0]<40 and names_df[p][['Sep']].values[j][0]==0.0 and names_df[p][['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "                    names_df[p].set_value(j,'class label',0)\n",
    "                        #names_df[p].drop(names_df[p].index[counter], inplace=True)\n",
    "                    \n",
    "            '''Now you need to drop the number off from the longest one'''\n",
    "            if add_on=='fg3_m12_alone' or add_on=='fg1_m13_alone':\n",
    "                length_limit=length/3\n",
    "            else:\n",
    "                length_limit=length\n",
    "\n",
    "            names_df[p].dropna(how=\"all\",inplace=True)\n",
    "\n",
    "            n_drop=int(len(names_df[p])-length_limit)\n",
    "            drop_indices = np.random.choice(names_df[p].index, n_drop, replace=False)\n",
    "            df_subset = names_df[p].drop(drop_indices)\n",
    "            print('LENGTH NOW', len(df_subset))\n",
    "            dfs.append(df_subset)\n",
    "\n",
    "        new_df=dfs[0].append(dfs[1]).append(dfs[2]).append(dfs[3]) \n",
    "\n",
    "        for j in range(len(new_df)):\n",
    "            if new_df[['class label']].values[j]<1:\n",
    "                print(new_df[['Image']].values[j],new_df[['Myr']].values[j][0],new_df[['class label']].values[j])\n",
    "\n",
    "\n",
    "        #These are the isolated galaxies:'LDA_img_ratio_statmorph_isolated.txt'\n",
    "        df = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_isolated_no_200.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "        df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "        df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "        new_df=new_df.append(df)\n",
    "\n",
    "        myr=[]\n",
    "        myr_non=[]\n",
    "        for j in range(len(new_df)):\n",
    "            if new_df[['class label']].values[j][0]==0.0:\n",
    "                myr_non.append(new_df[['Myr']].values[j][0])\n",
    "            else:\n",
    "                myr.append(new_df[['Myr']].values[j][0])\n",
    "\n",
    "        myr_non=sorted(list(set(myr_non)))\n",
    "        myr=sorted(list(set(myr)))\n",
    "        df=new_df\n",
    "        run='all'\n",
    "    else:\n",
    "        run=list_runs[i]\n",
    "\n",
    "        df = pd.io.parsers.read_table(\n",
    "            filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "            header=[0],\n",
    "            sep='\\t'\n",
    "            )#,skiprows=10,nrows=10\n",
    "            ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "        df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "        df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(len(df)):\n",
    "            if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "                df.set_value(j,'class label',0)\n",
    "        myr=[]\n",
    "        myr_non=[]\n",
    "        for j in range(len(df)):\n",
    "            if df[['class label']].values[j][0]==0.0:\n",
    "                myr_non.append(df[['Myr']].values[j][0])\n",
    "            else:\n",
    "                myr.append(df[['Myr']].values[j][0])\n",
    "\n",
    "        myr_non=sorted(list(set(myr_non)))\n",
    "        myr=sorted(list(set(myr)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.dropna(inplace=True) # to drop the empty line at file-end\n",
    "    #print(df)\n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    def gini_m20(row):\n",
    "        return row['Gini']*row['M20']\n",
    "    def gini_C(row):\n",
    "        return row['Gini']*row['Concentration (C)']\n",
    "    def gini_A(row):\n",
    "        return row['Gini']*row['Asymmetry (A)']\n",
    "    def gini_S(row):\n",
    "        return row['Gini']*row['Clumpiness (S)']\n",
    "    def gini_n(row):\n",
    "        return row['Gini']*row['Sersic N']\n",
    "    def gini_A_S(row):\n",
    "        return row['Gini']*row['Shape Asymmetry']\n",
    "    \n",
    "    def M20_C(row):\n",
    "        return row['M20']*row['Concentration (C)']\n",
    "    def M20_A(row):\n",
    "        return row['M20']*row['Asymmetry (A)']\n",
    "    def M20_S(row):\n",
    "        return row['M20']*row['Clumpiness (S)']\n",
    "    def M20_n(row):\n",
    "        return row['M20']*row['Sersic N']\n",
    "    def M20_A_S(row):\n",
    "        return row['M20']*row['Shape Asymmetry']\n",
    "    \n",
    "    def C_A(row):\n",
    "        return row['Concentration (C)']*row['Asymmetry (A)']\n",
    "    def C_S(row):\n",
    "        return row['Concentration (C)']*row['Clumpiness (S)']\n",
    "    def C_n(row):\n",
    "        return row['Concentration (C)']*row['Sersic N']\n",
    "    def C_A_S(row):\n",
    "        return row['Concentration (C)']*row['Shape Asymmetry']\n",
    "    \n",
    "    \n",
    "    def A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Clumpiness (S)']\n",
    "    def A_n(row):\n",
    "        return row['Asymmetry (A)']*row['Sersic N']\n",
    "    def A_A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def S_n(row):\n",
    "        return row['Clumpiness (S)']*row['Sersic N']\n",
    "    def S_A_S(row):\n",
    "        return row['Clumpiness (S)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def n_A_S(row):\n",
    "        return row['Sersic N']*row['Shape Asymmetry']\n",
    "    \n",
    "    df['Gini*M20'] = df.apply(gini_m20,axis=1)\n",
    "    df['Gini*C'] = df.apply(gini_C,axis=1)\n",
    "    df['Gini*A'] = df.apply(gini_A,axis=1)\n",
    "    df['Gini*S'] = df.apply(gini_S,axis=1)\n",
    "    df['Gini*n'] = df.apply(gini_n,axis=1)\n",
    "    df['Gini*A_S'] = df.apply(gini_A_S,axis=1)\n",
    "    \n",
    "    df['M20*C'] = df.apply(M20_C,axis=1)\n",
    "    df['M20*A'] = df.apply(M20_A,axis=1)\n",
    "    df['M20*S'] = df.apply(M20_S,axis=1)\n",
    "    df['M20*n'] = df.apply(M20_n,axis=1)\n",
    "    df['M20*A_S'] = df.apply(M20_A_S,axis=1)\n",
    "    \n",
    "    df['C*A'] = df.apply(C_A,axis=1)\n",
    "    df['C*S'] = df.apply(C_S,axis=1)\n",
    "    df['C*n'] = df.apply(C_n,axis=1)\n",
    "    df['C*A_S'] = df.apply(C_A_S,axis=1)\n",
    "    \n",
    "    df['A*S'] = df.apply(A_S,axis=1)\n",
    "    df['A*n'] = df.apply(A_n,axis=1)\n",
    "    df['A*A_S'] = df.apply(A_A_S,axis=1)\n",
    "    \n",
    "    df['S*n'] = df.apply(S_n,axis=1)\n",
    "    df['S*A_S'] = df.apply(S_A_S,axis=1)\n",
    "    \n",
    "    df['n*A_S'] = df.apply(n_A_S,axis=1)\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)','Clumpiness (S)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    #'Clumpiness (S)',\n",
    "    \n",
    "    \n",
    "    y = df['class label'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_nonmerg=[]\n",
    "    X_merg=[]\n",
    "    \n",
    "    for l in range(len(y)):\n",
    "        if y[l]==0:\n",
    "            X_nonmerg.append(X[l])\n",
    "        else:\n",
    "            X_merg.append(X[l])\n",
    "            \n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    print('std_scale mean', std_scale.mean_)\n",
    "    print('std_scale var', np.sqrt(std_scale.var_))\n",
    "    \n",
    "    \n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    \n",
    "    n_params=6\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    print('input priors', priors_list[i])\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    \n",
    "    \n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    \n",
    "    print('coef', coef)\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    kf.get_n_splits(X, y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    coef_list=[]\n",
    "    inter_list=[]\n",
    "    confusion_master=[]\n",
    "    y_test_master=[]\n",
    "    pred_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        \n",
    "        sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "        #priors=[0.1,0.9],\n",
    "    \n",
    "    \n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        #print('coef kfold', coef)\n",
    "        coef_list.append(coef)\n",
    "        inter_list.append(inter)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred =sklearn_lda.predict(X_test)\n",
    "        \n",
    "        '''def predict_with_cutoff(colname, y_prob, df):\n",
    "            n_events = df[colname].values\n",
    "            event_rate = sum(n_events) / float(df.shape[0]) * 100\n",
    "            threshold = np.percentile(y_prob[:, 1], 100 - event_rate)\n",
    "            print \"Cutoff/threshold at: \" + str(threshold)\n",
    "            y_pred = [1 if x >= threshold else 0 for x in y_prob[:, 1]]\n",
    "            return y_pred'''\n",
    "        \n",
    "        '''plt.clf()\n",
    "        fig=plt.figure()#figsize=(6,6)\n",
    "        plot_confusion_matrix(confusion_matrix(pred,y_test)/np.sum(confusion_matrix(pred,y_test)), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'_'+str(count)+'.pdf')\n",
    "        #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "        plt.clf()'''\n",
    "        \n",
    "        confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        pred_master.append(pred)\n",
    "        y_test_master.append(y_test)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    print('~~~~~Stratified K-fold validation means  ~~~~~~')\n",
    "    print(np.mean(coef_list, axis=0))\n",
    "    print(np.mean(inter_list, axis=0))\n",
    "    print('~~~~~Stratified K-fold validation STD ~~~~~~')\n",
    "    print(np.std(coef_list, axis=0))\n",
    "    print(np.std(inter_list, axis=0))\n",
    "    \n",
    "    print(run+str(' & '))\n",
    "    for j in range(len(np.mean(coef_list,axis=0)[0])):\n",
    "        print(str(round(np.mean(coef_list,axis=0)[0][j],2))+r' $\\pm$ '+str(round(np.std(coef_list,axis=0)[0][j],2))+' & ')\n",
    "    print(str(round(np.mean(inter_list,axis=0)[0],2))+r' $\\pm$ '+str(round(np.std(inter_list,axis=0)[0],2))+ '//')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs=['Gini','M20','Concentration (C)','Asymmetry (A)','Clumpiness (S)','Sersic N','Shape Asymmetry',\n",
    "            'Gini*M20','Gini*C','Gini*A','Gini*S','Gini*n','Gini*A_S',\n",
    "            'M20*C','M20*A','M20*S', 'M20*n', 'M20*A_S', \n",
    "            'C*A','C*S','C*n','C*A_S',\n",
    "           'A*S','A*n','A*A_S',\n",
    "            'S*n','S*A_S',\n",
    "           'n*A_S']\n",
    "    coef_mean=[]\n",
    "    coef_std=[]\n",
    "    coef_mean_std=[]\n",
    "    accuracy=[]\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "        '''c'''\n",
    "        \n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "        # LDA\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        '''print(master)\n",
    "        print(master[1][0])#row, then column\n",
    "        print('~~~Accuracy~~~')\n",
    "        print((master[1][1]+master[0][0])/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "        print('~~~Precision~~~')\n",
    "        print(master[1][1]/(master[0][1]+master[1][1]))#TP/(TP+FP)\n",
    "        print('~~~Recall~~~')\n",
    "        print(master[1][1]/(master[1][0]+master[1][1]))#TP/(TP+FN)\n",
    "        print('~~~F1~~~')\n",
    "        print((2*master[1][1])/(master[0][1]+master[1][0]+2*master[1][1]))#2TP/(2TP+FP+FN)'''\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        coef_mean.append(np.mean(coef_list, axis=0))\n",
    "        coef_std.append(np.std(coef_list, axis=0))\n",
    "        coef_mean_std.append(abs(np.mean(coef_list, axis=0))-np.std(coef_list, axis=0))\n",
    "    \n",
    "    print('accuracy', accuracy)\n",
    "    print(min(accuracy))\n",
    "    print(accuracy.index(min(accuracy)))\n",
    "    print(inputs[accuracy.index(min(accuracy))])\n",
    "    first_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    first_A=min(accuracy)\n",
    "    '''Now we select the second one that IMPROVES THE ACCURACY'''\n",
    "    inputs.remove(str(inputs[accuracy.index(min(accuracy))]))\n",
    "    \n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master,axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "    '''if min(accuracy) > first_A:\n",
    "        print(first_thing)\n",
    "        STOP'''\n",
    "    second_A=min(accuracy)\n",
    "    second_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(second_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "    third_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    third_A=min(accuracy)\n",
    "    inputs.remove(third_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    fourth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    fourth_A=min(accuracy)\n",
    "    \n",
    "    inputs.remove(fourth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    fifth_A=min(accuracy)\n",
    "    fifth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(fifth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,fifth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    sixth_A=min(accuracy)\n",
    "    sixth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(sixth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    seventh_A=min(accuracy)\n",
    "    seventh_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(seventh_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    eighth_A=min(accuracy)\n",
    "    eighth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    \n",
    "    inputs.remove(eighth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    ninth_A=min(accuracy)\n",
    "    ninth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    \n",
    "    inputs.remove(ninth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    tenth_A=min(accuracy)\n",
    "    tenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(tenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    eleventh_A=min(accuracy)\n",
    "    eleventh_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(eleventh_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    twelth_A=min(accuracy)\n",
    "    twelth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(twelth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,twelth_thing,\n",
    "                inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    thirteenth_A=min(accuracy)\n",
    "    thirteenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(thirteenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing, thirteenth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    fourteenth_A=min(accuracy)\n",
    "    fourteenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(fourteenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing, fourteenth_thing,\n",
    "                inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    fifteenth_A=min(accuracy)\n",
    "    fifteenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(fifteenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    sixteenth_A=min(accuracy)\n",
    "    sixteenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(sixteenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    seventeenth_A=min(accuracy)\n",
    "    seventeenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(seventeenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    eighteenth_A=min(accuracy)\n",
    "    eighteenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(eighteenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "                eighteenth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    ninteenth_A=min(accuracy)\n",
    "    ninteenth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(ninteenth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "                eighteenth_thing,ninteenth_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    twentieth_A=min(accuracy)\n",
    "    twentieth_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(twentieth_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "                eighteenth_thing,ninteenth_thing,twentieth_thing,\n",
    "                inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    A_21=min(accuracy)\n",
    "    thing_21=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(thing_21)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "                eighteenth_thing,ninteenth_thing,twentieth_thing,\n",
    "                thing_21,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    A_22=min(accuracy)\n",
    "    thing_22=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(thing_22)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "                eighteenth_thing,ninteenth_thing,twentieth_thing,\n",
    "                thing_21,thing_22,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    A_23=min(accuracy)\n",
    "    thing_23=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(thing_23)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "                eighteenth_thing,ninteenth_thing,twentieth_thing,\n",
    "                thing_21,thing_22,thing_23,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    A_24=min(accuracy)\n",
    "    thing_24=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(thing_24)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "                eighteenth_thing,ninteenth_thing,twentieth_thing,\n",
    "                thing_21,thing_22,thing_23,thing_24,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    A_25=min(accuracy)\n",
    "    thing_25=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(thing_25)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,second_thing,third_thing,fourth_thing,\n",
    "                fifth_thing,sixth_thing,seventh_thing,eighth_thing,\n",
    "                ninth_thing,tenth_thing,eleventh_thing,\n",
    "                twelth_thing,thirteenth_thing,fourteenth_thing,\n",
    "                fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "                eighteenth_thing,ninteenth_thing,twentieth_thing,\n",
    "                thing_21,thing_22,thing_23,thing_24,thing_25,\n",
    "                inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.sum(confusion_master, axis=0)#.transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1])/10)#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    A_26=min(accuracy)\n",
    "    thing_26=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    print(first_thing, second_thing, third_thing, fourth_thing, fifth_thing, sixth_thing,\n",
    "         seventh_thing,eighth_thing, ninth_thing,tenth_thing, eleventh_thing, twelth_thing,\n",
    "         thirteenth_thing,fourteenth_thing,fifteenth_thing,sixteenth_thing,seventeenth_thing,\n",
    "         eighteenth_thing,ninteenth_thing,twentieth_thing,thing_21,thing_22,\n",
    "         thing_23,thing_24,thing_25,thing_26)\n",
    "    print(first_A, second_A, third_A, fourth_A, fifth_A, sixth_A,\n",
    "         seventh_A,eighth_A, ninth_A, tenth_A, eleventh_A, twelth_A,\n",
    "         thirteenth_A,fourteenth_A,fifteenth_A,sixteenth_A,seventeenth_A,\n",
    "         eighteenth_A,ninteenth_A,twentieth_A,A_21,A_22,A_23,A_24,A_25,A_26)\n",
    "    \n",
    "    missclass=[first_A,second_A,third_A,fourth_A,fifth_A,sixth_A,seventh_A,eighth_A,\n",
    "              ninth_A,tenth_A, eleventh_A, twelth_A, thirteenth_A, fourteenth_A,\n",
    "              fifteenth_A,sixteenth_A,seventeenth_A,eighteenth_A,ninteenth_A,twentieth_A,\n",
    "              A_21,A_22,A_23,A_24,A_25,A_26]\n",
    "    num_comps=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26]\n",
    "    \n",
    "\n",
    "    \n",
    "    min_A=min(missclass)\n",
    "    min_comps=num_comps[missclass.index(min(missclass))]\n",
    "    plt.plot(num_comps,missclass, color=colors[i], label=names[i])\n",
    "    if i==0:\n",
    "        plt.scatter(num_comps[4],missclass[4], marker='x',color='black', zorder=100)\n",
    "    if i==1:\n",
    "        plt.scatter(num_comps[10],missclass[10], marker='x',color='black', zorder=100)\n",
    "    if i==2:\n",
    "        plt.scatter(num_comps[9],missclass[9], marker='x',color='black', zorder=100)\n",
    "    if i==3:\n",
    "        plt.scatter(num_comps[13],missclass[13], marker='x',color='black', zorder=100)\n",
    "    if i==4:\n",
    "        plt.scatter(num_comps[16],missclass[16], marker='x', color='black',zorder=100)\n",
    "plt.xlabel('Number of Predictors')\n",
    "plt.ylabel('Cross-Validation Error')\n",
    "plt.ylim([0,8])\n",
    "plt.legend()\n",
    "plt.savefig('../MaNGA_Papers/Paper_I/CV_variable_selection_S_all_noise.pdf')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run fg3_m12_no_200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:372: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std_scale mean [0.54507963 1.40959046 0.20924545 0.79755579 0.35313146]\n",
      "std_scale var [0.05807988 0.73823792 0.18345029 0.46789234 0.41674025]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 16.12918473  68.1249295   19.83012405 -51.392041   -20.82843167]]\n",
      "['Gini', 'Sersic N', 'Asymmetry (A)', 'Gini*n', 'A*n']\n",
      "fg3_m12_no_200 & \n",
      "16.21 $\\pm$ 1.2 & \n",
      "68.45 $\\pm$ 4.36 & \n",
      "19.92 $\\pm$ 1.14 & \n",
      "-51.65 $\\pm$ 4.2 & \n",
      "-20.94 $\\pm$ 1.3 & \n",
      "-0.01 $\\pm$ 0.17//\n",
      "before transposing [[0.45643154 0.00414938]\n",
      " [0.         0.53941909]]\n",
      "after transposing [[0.45643154 0.        ]\n",
      " [0.00414938 0.53941909]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~Accuracy~~~\n",
      "0.9958506224066389\n",
      "~~~Precision~~~\n",
      "1.0\n",
      "~~~Recall~~~\n",
      "0.9923664122137404\n",
      "~~~F1~~~\n",
      "0.9961685823754789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION BOUNDARY 2.82523905672032 fg3_m12_no_200\n",
      "[4.781237991160214, 1.69387787327359, 4.650315434099918, 5.983694214925752]\n",
      "[5.448585711043356, 5.97085270916552, 5.9776173288067795, 5.455032804370081, 5.608548836386315, 5.7907453618361595, 7.152626551518965]\n",
      "[6.85049872190573, 4.876349804985194, 6.634447590497344, 7.502878871020989, 6.925382569876803, 6.858896177917838, 6.035980742677809]\n",
      "[7.659480581551197, 5.692675106744543, 6.112951515200155, 8.116800164758923, 7.735442722599224, 7.04964544025229, 4.636244765738791]\n",
      "[6.582949493269009, 6.531986425405373, 7.652822033558842, 7.828285005254932, 4.822225991119583, 7.130865150708361, 5.776349353032582]\n",
      "[7.024029265406901, 6.6537518837417355, 7.350375124680593, 7.671360455845986, 6.0641556675297705, 6.963464965137589, 5.272754973906532]\n",
      "[7.179498232631419, 7.129932633301947, 8.132770512571778, 7.746007749497432, 6.644711860824119, 6.496776491757528, 4.887969977868489]\n",
      "[7.084488442366403, 6.264753270101121, 6.496162764743135, 7.129712799985574, 6.118265988104527, 7.141114271559312]\n",
      "[6.546311182586505, 7.098662633565922, 5.894796065815871, 4.861584757300276, 5.890489535707614, 5.9326557794627295, 7.780882770301896]\n",
      "[7.318570263493735, 7.864116234402951, 7.15023567366945, 5.169853073974469, 3.959006074571644, 9.163038888302088, 6.663182845968686]\n",
      "[6.086487949165498, 6.701415306518783, 6.301510702920954, 7.448991050253428, 6.934198590953483, 8.081130190821893, 8.553678987174285]\n",
      "[6.92124527790329, 6.063537297253749, 6.897605153156032, 6.858315734484469, 6.6996930538782635, 7.528780710814023, 8.461341442944892]\n",
      "[5.355425637632184, 6.146800009965677, 4.93320383677383, 5.915924526679794, 6.415533029430676, 3.769980118541538, 3.793131753914963]\n",
      "[5.663040001028028, 6.426109342460983, 5.808947923784139, 6.331770605196947, 5.924999494250672, 5.645279238150996, 6.79954236231324]\n",
      "[5.433356854707999, 6.665329286829495, 6.234361623894449, 4.319846976706103, 6.6108822033432215, 5.516919899961432, 6.90869732025212]\n",
      "[6.5926850227562035, 6.8271985722063855, 6.728748477530003, 5.598517989346518, 6.597726549687321, 5.694721874621216, 7.239004875533378]\n",
      "[6.6821838529027335, 6.728394097728533, 6.542816137359657, 6.001557053637926, 5.450799718395459, 5.286985230448095, 6.386488062642297]\n",
      "[6.651209688977752, 6.682142492117952, 7.066530683239615, 6.305562923459726, 5.192734186541701, 4.843297627937588, 7.578391135729193]\n",
      "[6.3932190665886, 6.4915197777620115, 6.296550832765901, 6.8831839461144035, 6.072592850729866, 6.8790865366179865, 4.510705553017573]\n",
      "means [4.277281378364869, 5.914858471875311, 6.526347782697387, 6.714748613835018, 6.617926207478383, 6.714270333749872, 6.888238208350387, 6.705749589476678, 6.286483246391545, 6.755429007769003, 7.15820182540119, 7.061502667204961, 5.189999844705524, 6.085669852455001, 5.955627737956403, 6.468371908811575, 6.154174879016385, 6.33140981971479, 6.218122651942336]\n",
      "[30, 40, 60, 80, 100, 120, 140, 160, 170, 180, 185, 190, 195, 205, 210, 220, 225, 230, 240, 250, 260] [1.57947342 0.54474416 0.78405017 1.17954057 0.98128808 0.75431875\n",
      " 0.97405619 0.42744818 0.88043295 1.5964834  0.84726732 0.69616889\n",
      " 1.00038358 0.40726062 0.8502167  0.55777547 0.54557693 0.91279622\n",
      " 0.74901722]\n",
      "myr [30, 40, 60, 80, 100, 120, 140, 160, 170, 180, 185, 190, 195, 205, 210, 220, 225, 230, 240, 250, 260]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 100]\n",
      "means [4.27728138 5.91485847 6.52634778 6.71474861 6.61792621 6.71427033\n",
      " 6.88823821 6.70574959 6.28648325 6.75542901 7.15820183 7.06150267\n",
      " 5.18999984 6.08566985 5.95562774 6.46837191 6.15417488 6.33140982\n",
      " 6.21812265]\n",
      "run fg1_m13_no_200\n",
      "std_scale mean [ 0.56390047 -1.85092417  3.58690291  0.16161305  0.1237425   1.42850467\n",
      "  0.2435008   0.1437033   0.9289168  -0.22780087  0.59687133 -2.73145919]\n",
      "std_scale var [0.05303224 0.45469322 0.80050729 0.14421751 0.07112324 0.64603526\n",
      " 0.21938039 0.13711827 0.87495641 0.14422476 0.54796105 1.63520479]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[  9.61915168   0.76802406  15.58707562   9.06345293  -1.04874512\n",
      "   -3.17315953  58.88144648 -42.20448612 -16.36406774   3.61167371\n",
      "   -6.81047164  -3.68009639]]\n",
      "['Gini', 'M20', 'Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)', 'Sersic N', 'Shape Asymmetry', 'Gini*A_S', 'C*A_S', 'M20*S', 'C*A', 'M20*n']\n",
      "fg1_m13_no_200 & \n",
      "9.74 $\\pm$ 1.24 & \n",
      "0.52 $\\pm$ 1.32 & \n",
      "15.91 $\\pm$ 0.96 & \n",
      "9.56 $\\pm$ 2.93 & \n",
      "-0.87 $\\pm$ 1.34 & \n",
      "-2.99 $\\pm$ 1.41 & \n",
      "59.97 $\\pm$ 6.81 & \n",
      "-42.96 $\\pm$ 7.49 & \n",
      "-16.74 $\\pm$ 1.54 & \n",
      "3.85 $\\pm$ 1.37 & \n",
      "-7.3 $\\pm$ 2.84 & \n",
      "-3.4 $\\pm$ 1.82 & \n",
      "1.85 $\\pm$ 0.42//\n",
      "before transposing [[0.38132296 0.0155642 ]\n",
      " [0.         0.60311284]]\n",
      "after transposing [[0.38132296 0.        ]\n",
      " [0.0155642  0.60311284]]\n",
      "~~~Accuracy~~~\n",
      "0.9844357976653696\n",
      "~~~Precision~~~\n",
      "1.0\n",
      "~~~Recall~~~\n",
      "0.9748427672955975\n",
      "~~~F1~~~\n",
      "0.9872611464968153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION BOUNDARY 2.313977057489847 fg1_m13_no_200\n",
      "[0.7100789115541091, 2.93908309716606, 6.969257581967838, 1.4260905091387142, 1.0057115165934012, 3.3322872142822044, 5.7702889890022995]\n",
      "[3.795536199893084, 2.542072691494767, 5.2030403211419864, 6.83618312892974, 4.6612287287584016, 5.010637756796879, 3.963456760302867]\n",
      "[4.35529880187646, 3.6912873654774545, 5.716691199251017, 5.615192405293617, 5.115903051972478, 4.99139918208164]\n",
      "[4.612485480431078, 3.380766313399837, 5.3301402482088855, 3.4668780261721777, 5.108026966159899, 4.159441411602764]\n",
      "[6.169696710905141, 4.617950418333166, 6.144617675077948, 5.432608406118471, 6.509187048327325, 5.209269838121431, 4.189578490971472]\n",
      "[5.613090168756725, 5.399725977187817, 5.175296789464089, 5.525988120041706, 5.704814651316169, 5.249761439547061, 4.972241044618363]\n",
      "[5.677383204262625, 5.6821369430791115, 5.2428824735981605, 5.895083118343859, 5.803901807481505, 4.371377948482362, 4.354543249841519]\n",
      "[7.024444645977045, 4.887858942031084, 6.188789266200785, 6.51728220437099, 5.833563740964231, 5.33896413743048, 5.9699451515529685]\n",
      "[5.989589758989844, 5.242024978616815, 6.551739949216086, 5.208599135325898, 6.2598241055421004, 5.564082828897011, 8.310816081755453]\n",
      "[5.723208335412494, 4.9685443025858875, 5.7138043608785996, 4.12712007906227, 5.62587914312812, 4.605354894576821, 7.46528683455608]\n",
      "[6.024865896354926, 4.909371110872759, 8.433544567023185, 5.9411494804496225]\n",
      "[5.190162158170855, 6.534741721810762]\n",
      "[3.9353082071047147, 6.034724518859383]\n",
      "[5.866104251420468, 5.065722808231117]\n",
      "[6.1162155209868665, 6.653046472574835]\n",
      "[6.193696079013581, 6.112526648656303, 5.847735891085463, 5.432393520667523, 6.166085955696186, 6.061421127058249, 4.335411267654618]\n",
      "[4.152119660201219, 4.725193306314545, 5.037961777170453, 4.865851476556433, 5.339552656381426, 5.062400443505342, 3.2843612516912515]\n",
      "[5.2101142381128485, 5.282019122474074, 5.652737952440932, 4.83211757686031, 5.267382296364311, 4.373281789541447, 3.8361017883066633]\n",
      "[6.164456108582019, 5.445091114669762, 6.2505165061313015, 6.189737934866343, 6.237964290956155, 5.274900955867922, 4.2714517502086355]\n",
      "[5.876948653466413, 4.807311080764227, 5.562040177348678, 5.887241096876091, 5.745370881827368, 3.5886081624395483, 4.899723952733196]\n",
      "[5.982694236393353, 5.416492469686448, 5.818644066406814, 5.293026638714072, 5.653903566903637, 2.8555774438992856, 4.716278825174408]\n",
      "[6.059644183022243, 5.224781004926394, 5.742800331714109, 5.818418735296835, 5.737481413592793, 4.421281075835663, 4.6165979144894225]\n",
      "[5.752924618516703, 5.286175331319026, 5.890007065446472, 5.626343646416362, 5.867406867136348, 3.693906547455292, 5.020926523024254]\n",
      "[5.903378556124969, 5.393592387879476, 6.01412784502362, 5.625854597282079, 5.934502804570023, 3.9454797353574222, 4.035212524115127]\n",
      "[5.774314280744224, 5.743152647061174, 5.32059251601048, 5.154559036673269, 5.714974449384227, 4.300845683303585, 3.898017049177532]\n",
      "[5.057268188154439, 5.173824595879509, 5.089092786359079, 4.966191627955619, 5.977230435533116, 3.948872811170923, 3.7395920514082324]\n",
      "means [3.1646854028149463, 4.5731650839025315, 4.914295334325444, 4.342956407662441, 5.467558369693564, 5.37727402727599, 5.289615535012735, 5.965835441218227, 6.16095383404903, 5.461313992885754, 6.3272327636751236, 5.862451939990809, 4.985016362982049, 5.465913529825793, 6.384630996780851, 5.73561006997599, 4.638205795974381, 4.9219649663000835, 5.690588380183162, 5.195320572207932, 5.105231035311145, 5.374429236982494, 5.305384371330637, 5.264592635764673, 5.129493666050642, 4.850296070922988]\n",
      "[40, 50, 60, 70, 90, 120, 130, 140, 195, 200, 210, 215, 220, 225, 230, 235, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350] [2.23772524 1.24320543 0.70591691 0.7482771  0.79815847 0.24101513\n",
      " 0.61588758 0.65975851 0.99437182 0.99505134 1.29299721 0.67228978\n",
      " 1.04970816 0.40019072 0.26841548 0.62202898 0.65029636 0.57993053\n",
      " 0.6901195  0.77458403 0.9945794  0.59032009 0.72102171 0.82956233\n",
      " 0.69441629 0.71055031]\n",
      "myr [40, 50, 60, 70, 90, 120, 130, 140, 195, 200, 210, 215, 220, 225, 230, 235, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 100]\n",
      "means [3.1646854  4.57316508 4.91429533 4.34295641 5.46755837 5.37727403\n",
      " 5.28961554 5.96583544 6.16095383 5.46131399 6.32723276 5.86245194\n",
      " 4.98501636 5.46591353 6.384631   5.73561007 4.6382058  4.92196497\n",
      " 5.69058838 5.19532057 5.10523104 5.37442924 5.30538437 5.26459264\n",
      " 5.12949367 4.85029607]\n",
      "run fg3_m15_no_200\n",
      "std_scale mean [ 0.53139306 -1.80844536  3.11583766  0.15295292  0.09055393  1.18849788\n",
      "  0.19503245  1.66195408 -0.33481165  3.73408054 -0.25999498  0.04350753\n",
      "  0.10634585  0.28716384]\n",
      "std_scale var [0.03889787 0.22719494 0.25878813 0.11648682 0.04013812 0.32409258\n",
      " 0.17800784 0.23492871 0.27259602 1.17369259 0.15575022 0.09290233\n",
      " 0.10360653 0.14834008]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[ 40.66357171  -8.64869076  51.35463055  13.87943863   6.88937463\n",
      "   -3.51570074  54.27918213 -77.9639034   15.08722995   3.89218492\n",
      "    6.11748816  -9.14251087 -30.4305718   -7.68189978]]\n",
      "['Gini', 'M20', 'Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)', 'Sersic N', 'Shape Asymmetry', 'Gini*C', 'M20*A_S', 'C*n', 'M20*A', 'A*A_S', 'Gini*A_S', 'C*S']\n",
      "fg3_m15_no_200 & \n",
      "41.35 $\\pm$ 3.8 & \n",
      "-8.66 $\\pm$ 0.67 & \n",
      "52.35 $\\pm$ 4.81 & \n",
      "13.86 $\\pm$ 0.76 & \n",
      "7.77 $\\pm$ 2.9 & \n",
      "-3.56 $\\pm$ 2.49 & \n",
      "55.17 $\\pm$ 5.57 & \n",
      "-79.3 $\\pm$ 7.35 & \n",
      "15.27 $\\pm$ 2.83 & \n",
      "3.97 $\\pm$ 2.81 & \n",
      "6.03 $\\pm$ 0.65 & \n",
      "-9.32 $\\pm$ 0.81 & \n",
      "-31.0 $\\pm$ 3.09 & \n",
      "-8.69 $\\pm$ 3.26 & \n",
      "1.72 $\\pm$ 0.21//\n",
      "before transposing [[0.32275132 0.06878307]\n",
      " [0.01058201 0.5978836 ]]\n",
      "after transposing [[0.32275132 0.01058201]\n",
      " [0.06878307 0.5978836 ]]\n",
      "~~~Accuracy~~~\n",
      "0.9206349206349206\n",
      "~~~Precision~~~\n",
      "0.982608695652174\n",
      "~~~Recall~~~\n",
      "0.8968253968253967\n",
      "~~~F1~~~\n",
      "0.9377593360995851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION BOUNDARY 0.7799034481872475 fg3_m15_no_200\n",
      "[2.995511499831709, 1.9682365950171068, 3.5025111000008153, 4.515307092193309, 3.4597750208714397, 0.6646945472513308, 2.8931064295052917]\n",
      "[4.244564998228941, 3.944614875533097, 3.2111879353183075, 1.3237032997724953, 1.1660481973311931, 2.190186458686718, 1.2593499902112697]\n",
      "[2.481300884957335, 1.2456595388424723, 1.2249731681806504, 2.4876701810078106, 2.359396791460017, 0.022621048221400458, 3.3718862702118826]\n",
      "[2.370617090618242, 2.735742602231166, 0.517052743297846, 0.7726454171215896, 1.6582404671576931, 0.7277826847082025, 3.364676032765118]\n",
      "[2.9440273772266123, 1.7195919703038085, 1.8333268018466937, 0.10711251110762365, 3.0083376363820444, 0.9696154847683292, 0.08263045742091624]\n",
      "[3.191119800334674, 1.4896505361638601, 1.6465536069258904, 1.96741736348315, 3.3640696715196183, 3.3476085660146326, 1.122277242539298]\n",
      "[1.6209271687637679, 1.6554267171477335, 2.735138674395158, 1.9664118093014915, 1.8730819653790527, 1.5509962316468844, 1.7290702162969636]\n",
      "[2.909822535487816, 3.595513359762543, 2.5961376091857766, 3.319524101076902, 2.9287716781976845, 4.3307328596695, 2.741893111234001]\n",
      "[3.829873788242854, 2.472156535620041, 3.4038682434393173, 3.7244236920784344, 3.2319772636901076, 3.6245168310842684, 3.553152460770694]\n",
      "[2.408592174991176, 2.905239482129856, 2.5542711171426267, 3.21754725930559, 2.577541876550174, 3.6173533347027917, 6.277955706014055]\n",
      "[1.5422154239221748, 2.9132680824895614, 3.0046648195528096, 2.387333445125386, 2.379722475708143, 2.820933954407585, 2.0821328980230973]\n",
      "[3.4222734832845454, 2.7897270227824893, 2.8114310721723674, 3.715662651953504, 3.1983317066477728, 2.058591440335724, 3.5532880360115584]\n",
      "[4.066409701162955, 4.655552478708222, 3.3949350375259684, 3.254792308653787, 3.9442241399714266, 3.863665086117158, 2.365106323643647]\n",
      "[3.718390116287882, 3.8949889452928446, 3.3970405820626115, 4.113638029733218, 3.80084343840541, 2.5753079241260597, 3.373218914626655]\n",
      "[3.0250779534926804, 1.9345362742789156, 4.079278464608626, 4.400919816215354, 3.321871873300311, 3.0241376058462413, 3.070527553181513]\n",
      "[3.2290701216445603, 2.5516842614461392, 2.5075315549336654, 2.7976776796241833, 3.269180049200232, 3.5605318805994304, 2.169904223499274]\n",
      "[3.1150306082934476, 2.1659099707802385, 2.391522557790526, 3.359470618570069, 3.2226423664613244, 3.2468462878558983, 2.947474156190108]\n",
      "[3.2574191634344176, 2.7940760222385483, 2.637208857841914, 2.215856824237197, 3.332894625199454, 3.115309675382178, 1.6718202758186689]\n",
      "means [2.8570203263815714, 2.4770936792974316, 1.8847868404116528, 1.7352510054142651, 1.523520319865147, 2.3040995409973033, 1.8758646832758643, 3.203199322087746, 3.4057098307036737, 3.3655001358337526, 2.4471815856041084, 3.0784722018839945, 3.649240725111881, 3.5533468500763825, 3.26519279156052, 2.8693685387067833, 2.9212709379916584, 2.717797920593197]\n",
      "[60, 90, 120, 150, 180, 210, 240, 270, 300, 320, 340, 360, 380, 400, 420, 440, 480, 500] [1.14309089 1.22070429 1.03285429 1.03449359 1.11778685 0.89482683\n",
      " 0.37554389 0.55824744 0.42305312 1.25209544 0.48226724 0.52899755\n",
      " 0.67495486 0.46790983 0.74451594 0.46185657 0.42732991 0.55880966]\n",
      "myr [60, 90, 120, 150, 180, 210, 240, 270, 300, 320, 340, 360, 380, 400, 420, 440, 480, 500]\n",
      "myr_non [5, 30, 60, 90, 100, 120, 150, 180]\n",
      "means [2.85702033 2.47709368 1.88478684 1.73525101 1.52352032 2.30409954\n",
      " 1.87586468 3.20319932 3.40570983 3.36550014 2.44718159 3.0784722\n",
      " 3.64924073 3.55334685 3.26519279 2.86936854 2.92127094 2.71779792]\n",
      "run fg3_m1_10_no_200\n",
      "std_scale mean [ 0.52146969 -1.89102164  3.14274471  0.11656778  1.31950651  0.1542379\n",
      "  0.08234952 -0.29314102 -2.56255436  4.21193238  0.36958333 -0.98748795]\n",
      "std_scale var [0.03249144 0.15344897 0.28938236 0.06002134 0.51508337 0.13140449\n",
      " 0.07859546 0.24396103 1.19236906 1.89541052 0.20952307 0.11441499]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[  1.89232556  -3.39553878  14.3045845   18.99760918  19.77483842\n",
      "   38.83095969 -15.51960661  22.17795855 -19.0491024  -39.7399072\n",
      "  -18.58754014   4.71105009]]\n",
      "['Gini', 'M20', 'Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry', 'Gini*A_S', 'M20*A_S', 'M20*n', 'C*n', 'C*A', 'Gini*M20']\n",
      "fg3_m1_10_no_200 & \n",
      "1.97 $\\pm$ 1.36 & \n",
      "-3.48 $\\pm$ 1.73 & \n",
      "14.5 $\\pm$ 1.36 & \n",
      "19.41 $\\pm$ 2.78 & \n",
      "20.1 $\\pm$ 2.17 & \n",
      "39.27 $\\pm$ 2.16 & \n",
      "-15.8 $\\pm$ 1.35 & \n",
      "22.32 $\\pm$ 1.22 & \n",
      "-19.08 $\\pm$ 2.07 & \n",
      "-40.1 $\\pm$ 3.45 & \n",
      "-19.01 $\\pm$ 2.74 & \n",
      "4.85 $\\pm$ 2.61 & \n",
      "0.46 $\\pm$ 0.13//\n",
      "before transposing [[0.35502959 0.06508876]\n",
      " [0.01775148 0.56213018]]\n",
      "after transposing [[0.35502959 0.01775148]\n",
      " [0.06508876 0.56213018]]\n",
      "~~~Accuracy~~~\n",
      "0.9171597633136096\n",
      "~~~Precision~~~\n",
      "0.9693877551020408\n",
      "~~~Recall~~~\n",
      "0.8962264150943396\n",
      "~~~F1~~~\n",
      "0.9313725490196079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION BOUNDARY 0.6378668220945753 fg3_m1_10_no_200\n",
      "[0.1356311577001923, 1.0414891533468187, 0.20326130201238124, 1.378184303520462, 0.09780098752235977, -1.167635415754073, 1.3062641604468332]\n",
      "[2.393565553153086, 3.355891277859756, 2.812443245338019, 4.665497706430604, 2.3127444918536537, -1.323280037772514, 2.708985437005936]\n",
      "[3.123291640727443, 2.7489289159457146, 0.7515398067027923, -0.09283430498980616, -0.2580889287703418, -0.46448804366138474, 1.3399746107616404]\n",
      "[2.128032671578392, 1.2368643851929848, 1.4614828513593134, 1.3444991612645905, 1.7596230916793978, 1.1299876991298643, 1.9742870033393296]\n",
      "[2.231844749554059, 1.859172719024183, 2.531545711525835, 1.8631381008437928, 1.6749762804968507, 2.198475518240859, 2.130725095099004]\n",
      "[2.5488650694688904, 1.6580964771256197, 1.1258830841351257, 1.4115602908106362, 2.345033047755575, 0.30608165124998105, 2.7432104143384155]\n",
      "[1.7757007312271238, 3.6553936002473972, 1.5103742342398474, 1.6495648785335495, 2.6842021878222067, 1.0839677214686974, 2.365905127189164]\n",
      "[3.6240028172605396, 2.8041670650400707, 4.8704052419305315, 1.6731965449321924, 2.7188971117657417, 3.789549978056586, 2.6765440874985518]\n",
      "[2.133909679719262, 2.7877967781294344, 2.32923288381064, 2.3763666708805222, 1.6973215191066866, 2.3227446539640377, 2.4084466823987087]\n",
      "[3.112992831494592, 2.1075285463537234, 3.4419542573899937, 3.197877213340192, 2.593295399793075, 3.184001440004434, 2.929726279640967]\n",
      "[2.7535270062822836, 2.040807998368673, 1.8242366880025536, 3.3236125724870993, 2.947803446984895, 2.699687936112438, 2.61141224568268]\n",
      "[2.0222615152468713, 2.5766589461168543, 2.8843018448957114, 2.827636018471208, 2.2937752504367857, 2.967900719966457, 2.6997255705527774]\n",
      "[2.6025670982435583, 2.1915723671761502, 2.8192812079215837, 2.741135465850627, 2.9211034088222814, 2.871601402012951, 2.7449884970733938]\n",
      "[3.0981362211821084, 2.264754486218123, 3.06470788962469, 2.7267565484710126, 2.846270251811756, 2.5426248072803346, 2.435930185074533]\n",
      "[2.828690827505451, 2.224089168183772, 3.1964857508852034, 3.134631580839413, 3.273743957162637, 3.0453113145133326, 3.160392353099812]\n",
      "means [0.4278565212564249, 2.4179782391240776, 1.0211890995308655, 1.5763966947919816, 2.069982596397798, 1.7341042906977489, 2.1035869258182838, 3.165251835212031, 2.293688409715613, 2.9381965668595678, 2.6001554134172324, 2.6103228379552377, 2.6988927781572207, 2.711311484237508, 2.980477850312803]\n",
      "[40, 60, 100, 200, 300, 400, 410, 420, 700, 800, 840, 900, 1000, 1040, 1100, 1140] [0.83166251 1.69789769 1.34499559 0.35410565 0.26798065 0.8083809\n",
      " 0.80349228 0.94886607 0.30412371 0.41768367 0.47700331 0.31742177\n",
      " 0.22811686 0.29195842 0.33555147]\n",
      "myr [40, 60, 100, 200, 300, 400, 410, 420, 700, 800, 840, 900, 1000, 1040, 1100, 1140]\n",
      "myr_non [5, 30, 60, 90, 100, 120, 150, 180]\n",
      "means [0.42785652 2.41797824 1.0211891  1.57639669 2.0699826  1.73410429\n",
      " 2.10358693 3.16525184 2.29368841 2.93819657 2.60015541 2.61032284\n",
      " 2.69889278 2.71131148 2.98047785]\n",
      "run all\n",
      "entering the loop\n",
      "133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:259: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "106\n",
      "126\n",
      "lengths [133, 159, 106, 126] 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:302: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LENGTH NOW 45\n",
      "LENGTH NOW 45\n",
      "LENGTH NOW 20\n",
      "LENGTH NOW 133\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_010.fits'] 10 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_030.fits'] 30 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_010.fits'] 10 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_020.fits'] 20 [0]\n",
      "['q0.5_fg0.3_allrx10_sunruns/hires_kin_early_cen1/broadband_030.fits'] 30 [0]\n",
      "['q0.333_fg0.1_allrx10_sunruns/hires_kin_early_cen1/broadband_010.fits'] 10 [0]\n",
      "['q0.1_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "['q0.2_fg0.3_BT0.2_allrx10_sunruns/hires_kin_early_cen1/broadband_005.fits'] 5 [0]\n",
      "std_scale mean [ 0.52609394 -1.79649948  3.09432279  0.13210948  1.16985917  0.16621696\n",
      "  3.75549307 -0.22084589  1.6420806   0.09179118  0.62709691  0.2844525\n",
      "  0.1770365   0.42000946 -0.28837455 -2.13897735  0.53786639  0.22479023]\n",
      "std_scale var [0.04413404 0.26869971 0.4867248  0.12384834 0.48002052 0.17178893\n",
      " 2.12321399 0.16612117 0.38393936 0.10409219 0.29858509 0.20880218\n",
      " 0.25003389 0.41703837 0.27637338 1.07443309 0.60350806 0.29271331]\n",
      "input priors [0.75, 0.25]\n",
      "coef [[  8.18519273  -0.2579427   23.3866605    1.66843497  -3.74252901\n",
      "   30.12336977  -7.68985706  -2.02337501 -23.30631687 -25.1211922\n",
      "   16.51140725  -0.193666    -2.00038857  -1.3432108   -0.37614816\n",
      "    3.21320485  -2.18484535  -3.37616113]]\n",
      "['Gini', 'M20', 'Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry', 'C*n', 'M20*A', 'Gini*C', 'Gini*A_S', 'Gini*n', 'C*S', 'A*n', 'C*A', 'M20*A_S', 'M20*n', 'C*A_S', 'n*A_S']\n",
      "all & \n",
      "8.26 $\\pm$ 0.83 & \n",
      "-0.32 $\\pm$ 0.58 & \n",
      "23.84 $\\pm$ 2.23 & \n",
      "1.75 $\\pm$ 0.61 & \n",
      "-4.02 $\\pm$ 1.62 & \n",
      "30.26 $\\pm$ 1.55 & \n",
      "-7.76 $\\pm$ 0.81 & \n",
      "-2.03 $\\pm$ 0.2 & \n",
      "-23.84 $\\pm$ 3.39 & \n",
      "-25.12 $\\pm$ 1.41 & \n",
      "17.05 $\\pm$ 2.59 & \n",
      "-0.19 $\\pm$ 0.25 & \n",
      "-2.04 $\\pm$ 0.64 & \n",
      "-1.41 $\\pm$ 0.42 & \n",
      "-0.36 $\\pm$ 0.45 & \n",
      "3.36 $\\pm$ 1.04 & \n",
      "-2.23 $\\pm$ 0.61 & \n",
      "-3.45 $\\pm$ 0.43 & \n",
      "-2.17 $\\pm$ 0.06//\n",
      "before transposing [[0.5753176  0.06170599]\n",
      " [0.01088929 0.35208711]]\n",
      "after transposing [[0.5753176  0.01088929]\n",
      " [0.06170599 0.35208711]]\n",
      "~~~Accuracy~~~\n",
      "0.9274047186932848\n",
      "~~~Precision~~~\n",
      "0.97\n",
      "~~~Recall~~~\n",
      "0.8508771929824562\n",
      "~~~F1~~~\n",
      "0.9065420560747663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION BOUNDARY 0.8799704270693414 all\n",
      "[2.7484347005023326, 0.11374132893847921, 3.7516577344619257, 0.34684395046870375, 3.6667822511339683, 0.9005385921602002, -0.8049701252472308]\n",
      "[2.6193960939552032, 2.8594104407251457, 3.331106245070155, 3.3969143764831133, 2.683030547185009, 3.525864668529011, 3.0525787343074233, 0.7615115489894946, 3.319811637703559, 2.9261672484191394, 2.253006518965612, 5.857231518519584, 2.3858213585441335, 0.4749840587751394, 4.281536818414201]\n",
      "[1.9511778593361555, 4.16088260355461]\n",
      "[4.383009259980249, 3.524382511090482]\n",
      "[3.9894595200540097, 4.523186525768887, 3.3113225550531795, 4.093564086486847, 2.9787099783152513, 3.2300632340814945, 2.754855759891515, 1.2558679892162694, 1.0512177595337409, 2.731030610184244, 1.2590029490601655]\n",
      "[3.7611163763935087, 3.6033086497549185]\n",
      "[3.388830587044876, 3.4180511404988345, 3.9952696799920067, 1.3359300368074756, 1.6433504752249897, 0.9749892810162009, 2.207887001465597, 1.290932542275297, -0.02641449598937118, 2.894444366375174]\n",
      "[4.059377305092954, 3.487234336622677, 3.7557223286359314]\n",
      "[1.8355368272743633, 2.6969326448227933, 2.669514984856212]\n",
      "[1.4077428912366459, 2.04114001945302, -0.11121715147513073, 0.23312645947522803, 0.7022616072435935, 0.04399058114385409, 2.4110927027301465]\n",
      "[3.8310329698719094, 3.5465276996022186]\n",
      "[1.4053663787666029, 1.8267562102371926, 1.6906175532463974, 0.7835496245120979, 1.4602559039379208, 0.14473148810537198, 1.7409081011004914, 0.5057209097020503, 0.508285621977679]\n",
      "[3.1891294769890526, 3.494983135009911]\n",
      "[2.3710876952210977, 3.0576615258694457, 3.0908458315698946]\n",
      "[4.685929313972428, 3.4606835221625527, 2.8847142699860298]\n",
      "[5.0958464770150105, 1.5134257434068648, 3.6863200926951833]\n",
      "[2.9270298049520753, 2.298931378800668, 1.9946470340216633, 0.7685514260889229, 0.883140644475985, 1.2793225733436109, 2.132202040288711, 2.0509687067664113, 1.0208664880887304]\n",
      "[4.037724190686694, 3.0503523348783657, 1.9009400265860426]\n",
      "[3.794619300102216, 4.578702855498649, 3.8170992940341946]\n",
      "[4.124077489182575, 1.7893700528837524]\n",
      "[3.4076621710502346, 3.5052677627616653]\n",
      "[3.4954736917807003, 3.9962723485366647, 0.15037300839962564, 0.7449765491742902, 1.5223255999803156, 1.0536399321914152, 0.08581166559366707, 0.3421176219209458, 1.1554598070458741]\n",
      "[3.4948553788778245, 4.6615005426065945, 3.4150369049561062]\n",
      "[3.4777348197402387, 3.108236995130155, 3.162008448967404]\n",
      "[4.004209392079476, 3.6036304264650623, 4.288231558905371, 7.433219095827683, 3.1193998011278676, 6.5092796470341545, 5.060468426232549, 3.443106992719756]\n",
      "[4.053391152131107, 4.036932029743477]\n",
      "[3.637020728843024, 3.196265952725028, 2.9302419106012456]\n",
      "[3.911084002868452, 3.1361017865769845, 2.3801126734492324, 2.7840704208601292, 2.6686701318062225, 3.3022517978151917, 3.347546744145735, 3.4392819696798473]\n",
      "[3.5851962303844793, 3.784494973915937, 3.972565533468101, 2.9780218785152477, 3.4879461059258583, 3.784609791676516, 3.4283268314168427, 4.629013850889533]\n",
      "[3.280156480085973, 3.0900797990248385]\n",
      "[3.4784261128453773, 3.0909323004753086, 3.7526600443457756, 3.11042779828198, 3.333278739040874, 3.460574692781826, 3.758155583843394, 3.272071542422669, 2.6368338290361732]\n",
      "[3.354845463813693, 3.4987429004120556, 2.942267563387138]\n",
      "[3.2392762687383003, 2.07591829452581, 2.373324282642786, 2.782215935650496, 3.4459052020738947, 1.6250763424538235, 2.922388361388274]\n",
      "[3.1213641919492803, 2.740291235317187, 2.330327574462628, 2.4548932220257824, 3.2149387135545204, 2.008072931228636, 2.314760694237065]\n",
      "[1.4944188412537396, 2.670483424508157, 2.3469302197192867, 2.402647700500768, 2.8682152209858094, 3.0986228670698575, 1.6344828755310317, 2.5781301976807]\n",
      "[0.278259758105481, 1.1914290142832544]\n",
      "[2.832841026798187, 1.2222822354429999, 2.6491877201613367, 2.599862945386913, 1.5074724285218926, 2.252961406937722, 2.980812320270805, 2.638995135120502, 1.979256896042158, 2.3987767372067927]\n",
      "[2.822109608422081, 1.9791970729577824, 1.5916327102341359, 1.9480261378149255, 2.8726837571202566, 2.553327198786674, 2.1918678047420688]\n",
      "[2.3351155449307526, 1.582300614658879, 1.447410395299696, 1.9432695889969513, 2.4364245409208904, 2.2772993783139173, 2.243796081980382]\n",
      "[2.4835168542091024, 1.4149092420593232, 2.027437823034143, 1.6242156343760006, 2.6899504175617874, 2.0337279956346874, 1.575378913677181]\n",
      "[3.1836585164423044, 2.168934514311771]\n",
      "[3.186463274322743, 1.9335179611440438]\n",
      "[2.9508735179933447, 2.92758537915314]\n",
      "means [1.531861204631197, 2.9152247876390622, 3.0560302314453827, 3.9536958855353657, 2.834389178876873, 3.6822125130742136, 2.1123270614711083, 3.7674446567838538, 2.400661485651123, 0.961162444258194, 3.6887803347370642, 1.118465754620645, 3.342056305999482, 2.8398650175534796, 3.6771090353736704, 3.431864104372353, 1.7061844552029752, 2.996338850717034, 4.063473816545019, 2.9567237710331638, 3.45646496690595, 1.3940500249581662, 3.857130942146842, 3.2493267546125995, 4.68269316754899, 4.045161590937292, 3.2545095307230993, 3.1211399409002243, 3.706271899524064, 3.1851181395554056, 3.3214845158970423, 3.265285309204296, 2.637729241067627, 2.5978069375393, 2.3867414184061686, 0.7348443861943676, 2.306244885188931, 2.2798348985825605, 2.037945163585924, 1.9784481257931752, 2.6762965153770377, 2.5599906177333933, 2.9392294485732426]\n",
      "[40, 60, 70, 80, 90, 100, 120, 130, 140, 150, 160, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 380, 400, 410, 420, 440, 480, 500, 800, 840, 900, 1000, 1040, 1140] [1.70042492 1.23664472 1.10485237 0.42931337 1.14204271 0.07890386\n",
      " 1.2192564  0.23372342 0.39976021 0.93015757 0.14225264 0.59848914\n",
      " 0.15292683 0.33175235 0.75109871 1.47354345 0.70188783 0.87317418\n",
      " 0.36443752 1.16735372 0.0488028  1.3401028  0.56970787 0.16299392\n",
      " 1.44936632 0.00822956 0.29146562 0.45784517 0.44784871 0.09503834\n",
      " 0.33159501 0.23584171 0.60094234 0.41319945 0.52674731 0.45658463\n",
      " 0.54573104 0.4475601  0.36096455 0.44276845 0.507362   0.62647266\n",
      " 0.01164407]\n",
      "myr [40, 60, 70, 80, 90, 100, 120, 130, 140, 150, 160, 180, 185, 190, 195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 380, 400, 410, 420, 440, 480, 500, 800, 840, 900, 1000, 1040, 1140]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "means [1.5318612  2.91522479 3.05603023 3.95369589 2.83438918 3.68221251\n",
      " 2.11232706 3.76744466 2.40066149 0.96116244 3.68878033 1.11846575\n",
      " 3.34205631 2.83986502 3.67710904 3.4318641  1.70618446 2.99633885\n",
      " 4.06347382 2.95672377 3.45646497 1.39405002 3.85713094 3.24932675\n",
      " 4.68269317 4.04516159 3.25450953 3.12113994 3.7062719  3.18511814\n",
      " 3.32148452 3.26528531 2.63772924 2.59780694 2.38674142 0.73484439\n",
      " 2.30624489 2.2798349  2.03794516 1.97844813 2.67629652 2.55999062\n",
      " 2.93922945]\n",
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "~~~\n",
    "Introducing Interaction terms\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "   # from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#example-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, target_names, title, cmap=plt.cm.Blues):\n",
    "    sns.set_style(\"dark\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    target_names=['Nonmerger','Merger']\n",
    "    plt.xticks(tick_marks, target_names)#, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('True label', size=20)\n",
    "    plt.xlabel('Predicted label', size=20)\n",
    "    \n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def lda_classify(v, levels, cutoffpoints):\n",
    "    for level, cutoff in zip(reversed(levels), reversed(cutoffpoints)):\n",
    "        if v > cutoff: return level\n",
    "    return levels[0]\n",
    "\n",
    "'''def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len((X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "        \n",
    "        print(( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ))\n",
    "\n",
    "        Xp = ( ((n_1-1)*(X0)) + ((n_2-1)*(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det((X0)))) - (n_2-1)*(np.log(np.linalg.det((X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) '''\n",
    "\n",
    "def box_m(X0,X1):\n",
    "\n",
    "        global Xp\n",
    "\n",
    "        m = 2\n",
    "        k = len(np.cov(X0))\n",
    "        n_1 = len(X0[0])\n",
    "        n_2 = len(X1[0])\n",
    "        n = len(X0[0])+len(X1[0])\n",
    "\n",
    "        Xp = ( ((n_1-1)*np.cov(X0)) + ((n_2-1)*np.cov(X1)) ) / (n-m)\n",
    "\n",
    "        M = ((n-m)*np.log(np.linalg.det(Xp))) \\\n",
    "         - (n_1-1)*(np.log(np.linalg.det(np.cov(X0)))) - (n_2-1)*(np.log(np.linalg.det(np.cov(X1))))\n",
    "\n",
    "        c = ( ( 2*(k**2) + (3*k) - 1 ) / ( (6*(k+1)*(m-1)) ) ) \\\n",
    "            * ( (1/(n_1-1)) + (1/(n_2-1)) - (1/(n-m)) )\n",
    "\n",
    "        df = (k*(k+1)*(m-1))/2\n",
    "\n",
    "        c2 = ( ((k-1)*(k+2)) / (6*(m-1)) ) \\\n",
    "            * ( (1/((n_1-1)**2)) + (1/((n_2-1)**2)) - (1/((n-m)**2)) )\n",
    "\n",
    "        df2 = (df+2) / (np.abs(c2-c**2))\n",
    "\n",
    "        if (c2>c**2):\n",
    "\n",
    "            a_plus = df / (1-c-(df/df2))\n",
    "\n",
    "            F = M / a_plus\n",
    "\n",
    "        else:\n",
    "\n",
    "            a_minus = df2 / (1-c+(2/df2))\n",
    "\n",
    "            F = (df2*M) / (df*(a_minus-M))\n",
    "\n",
    "        print('M = {}'.format(M))\n",
    "        print('c = {}'.format(c))\n",
    "        print('c2 = {}'.format(c2))\n",
    "        print('-------------------')\n",
    "        print('df = {}'.format(df))\n",
    "        print('df2 = {}'.format(df2))\n",
    "        print('-------------------')\n",
    "        print('F = {}'.format(F)) \n",
    "\n",
    "def plot_mean_and_CI(mean, lb, ub, color_mean=None, color_shading=None):\n",
    "        # plot the shaded range of the confidence intervals\n",
    "        plt.fill_between(range(mean.shape[0]), ub, lb,\n",
    "                         color=color_shading, alpha=.5)\n",
    "        # plot the mean on top\n",
    "        plt.plot(mean, color_mean)\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12_no_200', 'fg1_m13_no_200', 'fg3_m15_no_200', 'fg3_m1_10_no_200']\n",
    "colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"]]\n",
    "#colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"]]\n",
    "names=['q0.5_fg0.3','q0.333_fg0.1','q0.2_fg0.3_BT0.2','q0.1_fg0.3_BT0.2']\n",
    "\n",
    "inputs=[['Gini','Sersic N','Asymmetry (A)', 'Gini*n','A*n'],\n",
    "        ['Gini', 'M20','Concentration (C)','Asymmetry (A)','Clumpiness (S)','Sersic N','Shape Asymmetry','Gini*A_S', 'C*A_S', 'M20*S', 'C*A', 'M20*n'],\n",
    "       ['Gini','M20','Concentration (C)','Asymmetry (A)','Clumpiness (S)','Sersic N','Shape Asymmetry','Gini*C', 'M20*A_S', 'C*n', 'M20*A', 'A*A_S', 'Gini*A_S', 'C*S'],\n",
    "       ['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry','Gini*A_S', 'M20*A_S', 'M20*n', 'C*n', 'C*A', 'Gini*M20'],\n",
    "       ['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry','C*n', 'M20*A', 'Gini*C', 'Gini*A_S', 'Gini*n', 'C*S', 'A*n', 'C*A', 'M20*A_S', 'M20*n', 'C*A_S', 'n*A_S']]\n",
    "\n",
    "\n",
    "#Gini M20*A_S Sersic N Gini*n Asymmetry (A) C*n Concentration (C) n*A_S\n",
    "'''['Gini','M20','Concentration (C)','Asymmetry (A)','Clumpiness (S)','Sersic N','Shape Asymmetry',\n",
    "        'Gini*M20','Gini*C', 'Gini*n', 'Gini*S', 'Gini*A_S',\n",
    "        'M20*C','M20*A','M20*S','M20*A_S',\n",
    "        'C*A','C*n','C*A_S',\n",
    "        'A*A_S', 'A*n', \n",
    "        'n*A_S' ]'''\n",
    "\n",
    "list_runs=['fg3_m12_no_200', 'fg1_m13_no_200', 'fg3_m15_no_200', 'fg3_m1_10_no_200','all']\n",
    "colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"],sns.xkcd_rgb[\"black\"]]\n",
    "#colors=[sns.xkcd_rgb[\"red\"],sns.xkcd_rgb[\"amber\"],sns.xkcd_rgb[\"green\"],sns.xkcd_rgb[\"purple\"]]\n",
    "names=['q0.5_fg0.3','q0.333_fg0.1','q0.2_fg0.3_BT0.2','q0.1_fg0.3_BT0.2','All Combined']\n",
    "\n",
    "#list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "#'fg3_m12_comp_real','fg1_m13_comp_real','fg3_m15_comp_real','fg3_m1_10_comp_real']#,'fg3_m15_alliso','fg3_m1_10_alliso']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "add_noise='no'\n",
    "priors_list=[[0.9,0.1],[0.9,0.1],[0.7,0.3],[0.7,0.3],[0.75,0.25]]\n",
    "plt.clf()\n",
    "#list_runs=[ 'fg3_m12', 'fg1_m13', 'fg3_m15', 'fg3_m1_10']\n",
    "#priors_list=[[0.7,0.3],[0.9,0.1]]\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    print('run', add_on)\n",
    "    \n",
    "    if add_on=='all':\n",
    "        print('entering the loop')\n",
    "        lists=['fg3_m12_alone', 'fg1_m13_alone','fg3_m1_10_alone', 'fg3_m15_alone']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "        #add_noise='yes'\n",
    "        '''\n",
    "        So the time covered differs for different simulations.\n",
    "        We want to retain this in the data.\n",
    "        Minor mergers are 3x as frequent.\n",
    "        Since galaxies merge on average w/i 1-2 Gyr a lot of this will be washed out.\n",
    "        Because of the frequency of most mergers a lot of this will be washed out meaning that\n",
    "        it is probably unrealistic to combine the simulations together.\n",
    "        But we do so anyway making sure we have 3x the number of minor mergers as major mergers.\n",
    "        So we are limited by the smallest sample size.\n",
    "        '''\n",
    "\n",
    "        lens=[]\n",
    "\n",
    "        for p in range(len(lists)):\n",
    "\n",
    "            add_on=lists[p]\n",
    "            run=lists[p]\n",
    "\n",
    "            df = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "            df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "            df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            '''index_list=[]\n",
    "            for j in range(len(df)):\n",
    "                if df[['class label']].values[j][0]==0:\n",
    "                    index_list.append(j)\n",
    "\n",
    "            df.drop(df.index[index_list], inplace=True)'''\n",
    "\n",
    "            counter=0\n",
    "\n",
    "            for j in range(len(df)):\n",
    "                \n",
    "                if df[['Myr']].values[counter][0]<40 and df[['Sep']].values[counter][0]==0.0 and df[['# Bulges']].values[counter][0]==1:#df[['Myr']].values[i][0]\n",
    "                    df.set_value(counter,'class label',0)\n",
    "                    df.drop(df.index[counter], inplace=True)\n",
    "                else:\n",
    "                    counter+=1\n",
    "\n",
    "            print(len(df))\n",
    "            lens.append(len(df))\n",
    "\n",
    "\n",
    "        print('lengths', lens, min(lens[0],lens[1])) \n",
    "        length=min(lens[0],lens[1])\n",
    "\n",
    "        names_df=['df1', 'df2', 'df3', 'df4']\n",
    "        dfs=[]\n",
    "\n",
    "        for p in range(len(lists)):\n",
    "\n",
    "            add_on=lists[p]\n",
    "            run=lists[p]\n",
    "\n",
    "            names_df[p] = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "            names_df[p].columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "            names_df[p].dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "            '''for j in range(len(names_df)):\n",
    "                if names_df[['class label']].values[j]<1:\n",
    "                    print(names_df[['Image']].values[j],names_df[['Myr']].values[j][0],names_df[['class label']].values[j])\n",
    "\n",
    "            '''\n",
    "\n",
    "            counter=0\n",
    "            OG_length=len(names_df[p])\n",
    "            for j in range(len(names_df[p])):\n",
    "                if counter > OG_length:\n",
    "                    break\n",
    "                if names_df[p][['Myr']].values[j][0]<40 and names_df[p][['Sep']].values[j][0]==0.0 and names_df[p][['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "                    names_df[p].set_value(j,'class label',0)\n",
    "                    #names_df[p].drop(names_df[p].index[counter], inplace=True)\n",
    "                else:\n",
    "                    counter+=1\n",
    "            '''Now you need to drop the number off from the longest one'''\n",
    "            if add_on=='fg3_m12_alone' or add_on=='fg1_m13_alone':\n",
    "                length_limit=length/3\n",
    "            else:\n",
    "                length_limit=length\n",
    "\n",
    "            names_df[p].dropna(how=\"all\",inplace=True)\n",
    "\n",
    "            n_drop=int(len(names_df[p])-length_limit)\n",
    "            drop_indices = np.random.choice(names_df[p].index, n_drop, replace=False)\n",
    "            df_subset = names_df[p].drop(drop_indices)\n",
    "            print('LENGTH NOW', len(df_subset))\n",
    "            dfs.append(df_subset)\n",
    "\n",
    "        new_df=dfs[0].append(dfs[1]).append(dfs[2]).append(dfs[3]) \n",
    "\n",
    "        for j in range(len(new_df)):\n",
    "            if new_df[['class label']].values[j]<1:\n",
    "                print(new_df[['Image']].values[j],new_df[['Myr']].values[j][0],new_df[['class label']].values[j])\n",
    "\n",
    "\n",
    "        #These are the isolated galaxies:'LDA_img_ratio_statmorph_isolated.txt'\n",
    "        df = pd.io.parsers.read_table(\n",
    "                filepath_or_buffer='LDA_img_ratio_statmorph_isolated_no_200.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "                header=[0],\n",
    "                sep='\\t'\n",
    "                )#,skiprows=10,nrows=10\n",
    "                ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "        df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "        df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "        new_df=new_df.append(df)\n",
    "\n",
    "        myr=[]\n",
    "        myr_non=[]\n",
    "        for j in range(len(new_df)):\n",
    "            if new_df[['class label']].values[j][0]==0:\n",
    "                myr_non.append(new_df[['Myr']].values[j][0])\n",
    "            else:\n",
    "                myr.append(new_df[['Myr']].values[j][0])\n",
    "\n",
    "        myr_non=sorted(list(set(myr_non)))\n",
    "        myr=sorted(list(set(myr)))\n",
    "        df=new_df\n",
    "        run='all'\n",
    "    else:\n",
    "        run=list_runs[i]\n",
    "\n",
    "        df = pd.io.parsers.read_table(\n",
    "            filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "            header=[0],\n",
    "            sep='\\t'\n",
    "            )#,skiprows=10,nrows=10\n",
    "            ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "        df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "\n",
    "        df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(len(df)):\n",
    "            if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "                df.set_value(j,'class label',0)\n",
    "        myr=[]\n",
    "        myr_non=[]\n",
    "        for j in range(len(df)):\n",
    "            if df[['class label']].values[j][0]==0:\n",
    "                myr_non.append(df[['Myr']].values[j][0])\n",
    "            else:\n",
    "                myr.append(df[['Myr']].values[j][0])\n",
    "\n",
    "        myr_non=sorted(list(set(myr_non)))\n",
    "        myr=sorted(list(set(myr)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.dropna(inplace=True) # to drop the empty line at file-end\n",
    "    #print(df)\n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    def gini_m20(row):\n",
    "        return row['Gini']*row['M20']\n",
    "    def gini_C(row):\n",
    "        return row['Gini']*row['Concentration (C)']\n",
    "    def gini_A(row):\n",
    "        return row['Gini']*row['Asymmetry (A)']\n",
    "    def gini_S(row):\n",
    "        return row['Gini']*row['Clumpiness (S)']\n",
    "    def gini_n(row):\n",
    "        return row['Gini']*row['Sersic N']\n",
    "    def gini_A_S(row):\n",
    "        return row['Gini']*row['Shape Asymmetry']\n",
    "    \n",
    "    def M20_C(row):\n",
    "        return row['M20']*row['Concentration (C)']\n",
    "    def M20_A(row):\n",
    "        return row['M20']*row['Asymmetry (A)']\n",
    "    def M20_S(row):\n",
    "        return row['M20']*row['Clumpiness (S)']\n",
    "    def M20_n(row):\n",
    "        return row['M20']*row['Sersic N']\n",
    "    def M20_A_S(row):\n",
    "        return row['M20']*row['Shape Asymmetry']\n",
    "    \n",
    "    def C_A(row):\n",
    "        return row['Concentration (C)']*row['Asymmetry (A)']\n",
    "    def C_S(row):\n",
    "        return row['Concentration (C)']*row['Clumpiness (S)']\n",
    "    def C_n(row):\n",
    "        return row['Concentration (C)']*row['Sersic N']\n",
    "    def C_A_S(row):\n",
    "        return row['Concentration (C)']*row['Shape Asymmetry']\n",
    "    \n",
    "    \n",
    "    def A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Clumpiness (S)']\n",
    "    def A_n(row):\n",
    "        return row['Asymmetry (A)']*row['Sersic N']\n",
    "    def A_A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def S_n(row):\n",
    "        return row['Clumpiness (S)']*row['Sersic N']\n",
    "    def S_A_S(row):\n",
    "        return row['Clumpiness (S)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def n_A_S(row):\n",
    "        return row['Sersic N']*row['Shape Asymmetry']\n",
    "    \n",
    "    df['Gini*M20'] = df.apply(gini_m20,axis=1)\n",
    "    df['Gini*C'] = df.apply(gini_C,axis=1)\n",
    "    df['Gini*A'] = df.apply(gini_A,axis=1)\n",
    "    df['Gini*S'] = df.apply(gini_S,axis=1)\n",
    "    df['Gini*n'] = df.apply(gini_n,axis=1)\n",
    "    df['Gini*A_S'] = df.apply(gini_A_S,axis=1)\n",
    "    \n",
    "    df['M20*C'] = df.apply(M20_C,axis=1)\n",
    "    df['M20*A'] = df.apply(M20_A,axis=1)\n",
    "    df['M20*S'] = df.apply(M20_S,axis=1)\n",
    "    df['M20*n'] = df.apply(M20_n,axis=1)\n",
    "    df['M20*A_S'] = df.apply(M20_A_S,axis=1)\n",
    "    \n",
    "    df['C*A'] = df.apply(C_A,axis=1)\n",
    "    df['C*S'] = df.apply(C_S,axis=1)\n",
    "    df['C*n'] = df.apply(C_n,axis=1)\n",
    "    df['C*A_S'] = df.apply(C_A_S,axis=1)\n",
    "    \n",
    "    df['A*S'] = df.apply(A_S,axis=1)\n",
    "    df['A*n'] = df.apply(A_n,axis=1)\n",
    "    df['A*A_S'] = df.apply(A_A_S,axis=1)\n",
    "    \n",
    "    df['S*n'] = df.apply(S_n,axis=1)\n",
    "    df['S*A_S'] = df.apply(S_A_S,axis=1)\n",
    "    \n",
    "    df['n*A_S'] = df.apply(n_A_S,axis=1)\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    X = df[inputs[i]].values\n",
    "    #'Clumpiness (S)',\n",
    "    \n",
    "    \n",
    "    y = df['class label'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_nonmerg=[]\n",
    "    X_merg=[]\n",
    "    \n",
    "    for l in range(len(y)):\n",
    "        if y[l]==0:\n",
    "            X_nonmerg.append(X[l])\n",
    "        else:\n",
    "            X_merg.append(X[l])\n",
    "            \n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    print('std_scale mean', std_scale.mean_)\n",
    "    print('std_scale var', np.sqrt(std_scale.var_))\n",
    "    \n",
    "    \n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    \n",
    "    n_params=6\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    print('input priors', priors_list[i])\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    \n",
    "    \n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    \n",
    "    print('coef', coef)\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    kf.get_n_splits(X, y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    coef_list=[]\n",
    "    inter_list=[]\n",
    "    confusion_master=[]\n",
    "    y_test_master=[]\n",
    "    pred_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        \n",
    "        sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "        #priors=[0.1,0.9],\n",
    "    \n",
    "    \n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        #print('coef kfold', coef)\n",
    "        coef_list.append(coef)\n",
    "        inter_list.append(inter)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred =sklearn_lda.predict(X_test)\n",
    "        \n",
    "        '''def predict_with_cutoff(colname, y_prob, df):\n",
    "            n_events = df[colname].values\n",
    "            event_rate = sum(n_events) / float(df.shape[0]) * 100\n",
    "            threshold = np.percentile(y_prob[:, 1], 100 - event_rate)\n",
    "            print \"Cutoff/threshold at: \" + str(threshold)\n",
    "            y_pred = [1 if x >= threshold else 0 for x in y_prob[:, 1]]\n",
    "            return y_pred'''\n",
    "        \n",
    "        '''plt.clf()\n",
    "        fig=plt.figure()#figsize=(6,6)\n",
    "        plot_confusion_matrix(confusion_matrix(pred,y_test)/np.sum(confusion_matrix(pred,y_test)), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'_'+str(count)+'.pdf')\n",
    "        #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "        plt.clf()'''\n",
    "        \n",
    "        confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        pred_master.append(pred)\n",
    "        y_test_master.append(y_test)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    '''print('~~~~~Stratified K-fold validation means  ~~~~~~')\n",
    "    print(np.mean(coef_list, axis=0))\n",
    "    print(np.mean(inter_list, axis=0))\n",
    "    print('~~~~~Stratified K-fold validation STD ~~~~~~')\n",
    "    print(np.std(coef_list, axis=0))\n",
    "    print(np.std(inter_list, axis=0))'''\n",
    "    print(inputs[i])\n",
    "    print(run+str(' & '))\n",
    "    for j in range(len(np.mean(coef_list,axis=0)[0])):\n",
    "        print(str(round(np.mean(coef_list,axis=0)[0][j],2))+r' $\\pm$ '+str(round(np.std(coef_list,axis=0)[0][j],2))+' & ')\n",
    "    print(str(round(np.mean(inter_list,axis=0)[0],2))+r' $\\pm$ '+str(round(np.std(inter_list,axis=0)[0],2))+ '//')\n",
    "    \n",
    "    print('before transposing', (np.mean(confusion_master,axis=0)/np.sum(np.mean(confusion_master,axis=0))))\n",
    "    \n",
    "    print('after transposing', (np.mean(confusion_master,axis=0)/np.sum(np.mean(confusion_master,axis=0))).transpose())\n",
    "    plt.clf()\n",
    "    fig=plt.figure()#figsize=(6,6)\n",
    "    plot_confusion_matrix((np.mean(confusion_master,axis=0)/np.sum(np.mean(confusion_master,axis=0))).transpose(), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'.pdf')\n",
    "    #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "    plt.clf()\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    master=np.mean(confusion_master, axis=0).transpose()\n",
    "    \n",
    "    print('~~~Accuracy~~~')\n",
    "    print((master[1][1]+master[0][0])/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "    print('~~~Precision~~~')\n",
    "    print(master[1][1]/(master[0][1]+master[1][1]))#TP/(TP+FP)\n",
    "    print('~~~Recall~~~')\n",
    "    print(master[1][1]/(master[1][0]+master[1][1]))#TP/(TP+FN)\n",
    "    print('~~~F1~~~')\n",
    "    print((2*master[1][1])/(master[0][1]+master[1][0]+2*master[1][1]))#2TP/(2TP+FP+FN)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Redo X_lda to make plots'''\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    #coef = sklearn_qda.coef_\n",
    "    #inter = sklearn_qda.intercept_\n",
    "    #print(dec_qda)#mean accuracy on the given test data and labels.\n",
    "\n",
    "    '''Make a histogram'''\n",
    "    from scipy import stats\n",
    "    import seaborn as sns\n",
    "    \n",
    "    X_lda_1=[]\n",
    "    X_lda_2=[]\n",
    "    for j in range(len(X_lda_sklearn)):\n",
    "        if y[j] ==1:\n",
    "            X_lda_1.append(X_lda_sklearn[j][0])\n",
    "        else:\n",
    "            X_lda_2.append(X_lda_sklearn[j][0])\n",
    "    input_hist=X_lda_sklearn\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(20,4))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.hist(X_lda_1, label='Nonmerger',  color=sns.xkcd_rgb[\"sky blue\"], normed=1)\n",
    "    ax.hist(X_lda_2, label='Merger',  color=sns.xkcd_rgb[\"salmon\"],alpha = 0.85,normed=1)\n",
    "\n",
    "    \n",
    "\n",
    "    ax.set_xlabel('LD1', size=25)\n",
    "    #ax.set_title('Histogram #%s' %str(cnt+1), size=20)\n",
    "\n",
    "    # hide axis ticks\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\", labelsize=20)\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    ax.set_ylabel('Relative Count', size=25)\n",
    "    \n",
    "    \n",
    "    plt.legend(loc=\"upper right\", fontsize=20)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Now measure LD1 for every row and then plot that'''\n",
    "    import seaborn as sns\n",
    "    \n",
    "\n",
    "    n_params=7\n",
    "\n",
    "\n",
    "\n",
    "    #coef is how you get the eigvecs (doesn't matter what slope offset is)\n",
    "    #print('real eigvecs',(eigvec_sc.real))\n",
    "    #print(len(X_lda[:,0].real[y==2]))#[y == label]\n",
    "    xs=[]\n",
    "    LDA1=[]\n",
    "    \n",
    "    my_lists = {key:[] for key in myr}\n",
    "    my_lists_non = {key:[] for key in myr_non}\n",
    "    my_lists_none = []\n",
    "    my_lists_merg = []\n",
    "    separations = {key:[] for key in myr}\n",
    "\n",
    "    \n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['class label']].values[j]==0:\n",
    "            my_lists_none.append(X_lda_sklearn[j][0])\n",
    "            my_lists_non[df[['Myr']].values[j][0]].append(X_lda_sklearn[j][0])\n",
    "            continue\n",
    "        else:\n",
    "            my_lists_merg.append(X_lda_sklearn[j][0])\n",
    "        \n",
    "            my_lists[df[['Myr']].values[j][0]].append(X_lda_sklearn[j][0])\n",
    "        \n",
    "            separations[df[['Myr']].values[j][0]].append(df[['Sep']].values[j][0])\n",
    "            L=X_lda_sklearn[j][0]\n",
    "            #df[['Gini']].values[i][0]*coef[0][0]+df[['M20']].values[i][0]*coef[0][1]+df[['Concentration (C)']].values[i][0]*coef[0][2]+df[['Asymmetry (A)']].values[i][0]*coef[0][3]+df[['Clumpiness (S)']].values[i][0]*coef[0][4]+df[['Sersic N']].values[i][0]*coef[0][5]+df[['Shape Asymmetry']].values[i][0]*coef[0][6]\n",
    "            LDA1.append(L)\n",
    "            xs.append(df[['Myr']].values[j][0])\n",
    "\n",
    "    #print(mean(my_lists[180]))\n",
    "    mean_non=(np.mean(my_lists_merg)+np.mean(my_lists_none))/2\n",
    "    print('DECISION BOUNDARY', mean_non, run)\n",
    "    \n",
    "    if run=='fg1_m13' or run=='fg1_m13_comp_real' or run=='fg1_m13_no_200':\n",
    "        plt.annotate('q0.333_fg0.1', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    if run=='fg3_m12' or run=='fg3_m12_comp_real' or run=='fg3_m12_no_200':\n",
    "        plt.annotate('q0.5_fg0.3', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    if run=='fg3_m15' or run=='fg3_m15_comp_real' or run=='fg3_m15_no_200':\n",
    "        plt.annotate('q0.2_fg0.3_BT0.2', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    if run=='all':\n",
    "        plt.annotate('All', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    if run=='fg3_m1_10' or run=='fg3_m1_10_comp_real' or run=='fg3_m1_10_no_200':\n",
    "        plt.annotate('q0.1_fg0.3_BT0.2', xy=(0.01,0.92), xycoords='axes fraction', size=20)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    means=[]\n",
    "    std=[]\n",
    "    separation_value=[]\n",
    "    myr_here=[]\n",
    "    for j in range(len(myr)):\n",
    "        '''if math.isnan(np.mean(my_lists[myr[j]])):\n",
    "            separation_value.append(999)\n",
    "            continue\n",
    "        else:'''\n",
    "        if np.std(my_lists[myr[j]])==0:# or np.std(my_lists[myr[j]])< 0.01*np.mean(my_lists[myr[j]]):\n",
    "            continue\n",
    "        means.append(np.mean(my_lists[myr[j]]))\n",
    "        std.append(np.std(my_lists[myr[j]]))\n",
    "        separation_value.append(np.mean(separations[myr[j]]))\n",
    "        myr_here.append(myr[j])\n",
    "        print(my_lists[myr[j]])\n",
    "        \n",
    "    print('means',means)\n",
    "    \n",
    "    means=np.array(means)\n",
    "    std=np.array(std)\n",
    "    myr_here=np.array(myr_here)\n",
    "    \n",
    "    means_non=[]\n",
    "    std_non=[]\n",
    "    myr_here_non=[]\n",
    "    for j in range(len(myr_non)):\n",
    "        '''if math.isnan(np.mean(my_lists_non[myr_non[i]])):\n",
    "            \n",
    "            continue\n",
    "        else:'''\n",
    "        if np.std(my_lists_non[myr_non[j]])==0 or np.std(my_lists_non[myr_non[j]])< 0.01*np.mean(my_lists_non[myr_non[j]]):\n",
    "            continue\n",
    "        means_non.append(np.mean(my_lists_non[myr_non[j]]))\n",
    "        std_non.append(np.std(my_lists_non[myr_non[j]]))\n",
    "        myr_here_non.append(myr_non[j])\n",
    "        \n",
    "    \n",
    "    means_non=np.array(means_non)\n",
    "    std_non=np.array(std_non)\n",
    "    myr_here_non=np.array(myr_here_non)\n",
    "    \n",
    "    print(myr, std)\n",
    "    print('myr', myr)\n",
    "    print('myr_non', myr_non)\n",
    "    \n",
    "    '''delete places where there is only one point'''\n",
    "    \n",
    "    \n",
    "    plt.axvline(x=mean_non, color='black')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/Hist_statmorph_nonoise_'+str(run)+'.pdf')\n",
    "    plt.clf()\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(18,6))\n",
    "    \n",
    "    print('means',means)\n",
    "    \n",
    "    if run=='fg1_m13' or run=='fg1_m13_comp_real' or run=='fg1_m13_alliso' or run=='fg1_m13_no_200':\n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#-1.7583e-01\n",
    "        rescale_y_pm=7.13475416061/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color=sns.xkcd_rgb[\"amber\"])\n",
    "        \n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        #plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=215/100, color='black', ls='--')\n",
    "        plt.axvline(x=280/100, color='black', ls='--')\n",
    "\n",
    "        \n",
    "        plt.annotate('q0.333_fg0.1', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(1.7,max(new_means+std)-0.2),  size=20)\n",
    "        plt.annotate('Late', xy=(2.4,max(new_means+std)-0.2), size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(2.9,max(new_means+std)-0.2), size=20)\n",
    "\n",
    "    \n",
    "    if run=='fg3_m12' or run=='fg3_m12_alliso' or run=='fg3_m12_comp_real' or run=='fg3_m12_no_200':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        rescale_y_pm=5.5684302120/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color='red')\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color='red')\n",
    "        \n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "\n",
    "        plt.annotate('q0.5_fg0.3', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(1.68,max(new_means+std)-0.2),  size=20)\n",
    "        plt.annotate('Late', xy=(2.1,max(new_means+std)-0.2),size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(2.22,max(new_means+std)-0.2),  size=20)\n",
    "    if run=='fg3_m15' or run=='fg3_m15_alliso' or run=='fg3_m15_comp_real' or run=='fg3_m15_no_200':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        rescale_y_pm=5.5684302120/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "        \n",
    "        \n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color='green')\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color='green')\n",
    "        \n",
    "        \n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        plt.axvline(x=360/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "        plt.annotate('q0.2_fg0.3_BT0.2', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(1.55,max(new_means+std)-0.2),  size=20)\n",
    "        plt.annotate('Late', xy=(1.9,max(new_means+std)-0.2), size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(3.62,max(new_means+std)-0.2),  size=20)\n",
    "    if run=='all':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        \n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color='green')\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color='green')\n",
    "        \n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        \n",
    "        plt.axvline(x=270/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "\n",
    "        plt.annotate('All', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(1.5,0.97), size=20)\n",
    "        \n",
    "        plt.annotate('Late', xy=(1.9,0.97), size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(2.75,0.97), size=20)\n",
    "    if run=='fg3_m1_10' or run=='fg3_m1_10_alliso' or run=='fg3_m1_10_comp_real' or run=='fg3_m1_10_no_200':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        \n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        plt.clf()\n",
    "\n",
    "        plt.plot(myr_here/100, new_means, color='purple')\n",
    "        plt.fill_between(myr_here/100, (new_means-std), (new_means+std),alpha=.5, color='purple')\n",
    "        \n",
    "        new_means_non=np.array([(x-rescale_y_mean) for x in means_non])\n",
    "        plt.plot(myr_here_non/100, new_means_non, color='blue')\n",
    "        plt.fill_between(myr_here_non/100, (new_means_non-std_non), (new_means_non+std_non),alpha=.5, color='blue')\n",
    "        \n",
    "        plt.axvline(x=900/100, color='black', ls='--')\n",
    "        plt.axvline(x=410/100, color='black', ls='--')\n",
    "        plt.annotate('q0.1_fg0.3_BT0.2', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(3,max(new_means+std)-0.2), size=20)\n",
    "        \n",
    "        plt.annotate('Late', xy=(5,max(new_means+std)-0.2), size=20)\n",
    "        plt.annotate('Post Coalescence', xy=(9.1,max(new_means+std)-0.2), size=20)\n",
    "    #plt.ylim([-1,1])\n",
    "    plt.xlim([min(myr)/100,max(myr)/100])\n",
    "    frame1 = plt.gca()\n",
    "    plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "    \n",
    "    #frame1.axes.yaxis.set_ticklabels([])\n",
    "    plt.axhline(y=mean_non, color='black')\n",
    "    plt.xlabel(r'Merger Timeline [Gyr]', size=20)\n",
    "    plt.ylabel(r'Detection Sensitivity (LD1)', size=20)\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/Mountain_plot_'+str(run)+'.pdf')\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#    savefig('../MaNGA_Papers/Paper_I/Bayesian_Hist_'+str(run)+'.pdf')\n",
    "\n",
    "print('finished')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run fg3_m12_alliso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:70: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myr [30, 40, 60, 80, 100, 120, 140, 160, 170, 180, 185, 190, 195, 205, 210, 220, 225, 230, 240, 250, 260]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "std_scale mean [ 0.5257748  -1.78554059  3.099091    0.14246161  1.21511054  0.15368987]\n",
      "std_scale var [0.04782654 0.28856416 0.62700362 0.15084112 0.59729942 0.15540656]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 4.1609288  -1.36543768  2.62179352  4.95185848  3.15791192  3.12215882]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 4.17470792 -1.36036639  2.65349867  4.9659255   3.15719159  3.15365088]]\n",
      "[-8.82642992]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.27982845 0.29195162 0.31190489 0.41448807 0.24252398 0.35931986]]\n",
      "[0.26368272]\n",
      "fg3_m12_alliso & \n",
      "4.17 $\\pm$ 0.28 & \n",
      "-1.36 $\\pm$ 0.29 & \n",
      "2.65 $\\pm$ 0.31 & \n",
      "4.97 $\\pm$ 0.41 & \n",
      "3.16 $\\pm$ 0.24 & \n",
      "3.15 $\\pm$ 0.36 & \n",
      "-8.83 $\\pm$ 0.26//\n",
      "starting misclassified numbers 0.30000000000000004\n",
      "Gini\n",
      "M20\n",
      "Concentration (C)\n",
      "Asymmetry (A)\n",
      "Sersic N\n",
      "Shape Asymmetry\n",
      "Gini*M20\n",
      "Gini*C\n",
      "Gini*A\n",
      "Gini*n\n",
      "Gini*A_S\n",
      "M20*C\n",
      "M20*A\n",
      "M20*n\n",
      "M20*A_S\n",
      "C*A\n",
      "C*n\n",
      "C*A_S\n",
      "A*n\n",
      "A*A_S\n",
      "n*A_S\n",
      "accuracy [0.30000000000000004, 0.30000000000000004, 0.4, 0.30000000000000004, 0.30000000000000004, 0.4, 0.30000000000000004, 0.4, 0.30000000000000004, 0.4, 0.4, 0.30000000000000004, 0.4, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.4, 0.4]\n",
      "0.30000000000000004\n",
      "0\n",
      "Gini\n",
      "inputs_OG ['M20', 'Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry', 'Gini*M20', 'Gini*C', 'Gini*A', 'Gini*n', 'Gini*A_S', 'M20*C', 'M20*A', 'M20*n', 'M20*A_S', 'C*A', 'C*n', 'C*A_S', 'A*n', 'A*A_S', 'n*A_S']\n",
      "M20\n",
      "Concentration (C)\n",
      "Asymmetry (A)\n",
      "Sersic N\n",
      "Shape Asymmetry\n",
      "Gini*M20\n",
      "Gini*C\n",
      "Gini*A\n",
      "Gini*n\n",
      "Gini*A_S\n",
      "M20*C\n",
      "M20*A\n",
      "M20*n\n",
      "M20*A_S\n",
      "C*A\n",
      "C*n\n",
      "C*A_S\n",
      "A*n\n",
      "A*A_S\n",
      "n*A_S\n",
      "accuracy [0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.30000000000000004, 0.4, 0.30000000000000004]\n",
      "0.30000000000000004\n",
      "0\n",
      "M20\n",
      "[2.6, 2.1, 2.0, 1.5, 3.3000000000000003, 2.7, 2.4, 2.1, 2.0, 2.6, 1.6, 2.3000000000000003, 1.7, 2.3, 2.6, 1.9, 2.4, 2.8]\n",
      "1.5 0.30000000000000004 0.30000000000000004\n",
      "Gini M20\n",
      "run fg1_m13_alliso\n",
      "myr [40, 50, 60, 70, 90, 120, 130, 140, 195, 200, 210, 215, 220, 225, 230, 235, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "std_scale mean [ 0.53363518 -1.82254835  3.26111063  0.12195174  1.22868713  0.1678297 ]\n",
      "std_scale var [0.05286595 0.34245219 0.69366965 0.11605439 0.55653594 0.1822133 ]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 5.35439029 -3.11516512  5.03083188  5.13697363 -0.07564073  1.95949274]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 5.37212044 -3.1336563   5.06492987  5.1648362  -0.08225323  1.97009566]]\n",
      "[-7.02952831]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.31584729 0.23738732 0.33663775 0.27308469 0.20825999 0.33283881]]\n",
      "[0.32955927]\n",
      "fg1_m13_alliso & \n",
      "5.37 $\\pm$ 0.32 & \n",
      "-3.13 $\\pm$ 0.24 & \n",
      "5.06 $\\pm$ 0.34 & \n",
      "5.16 $\\pm$ 0.27 & \n",
      "-0.08 $\\pm$ 0.21 & \n",
      "1.97 $\\pm$ 0.33 & \n",
      "-7.03 $\\pm$ 0.33//\n",
      "starting misclassified numbers 0.5\n",
      "Gini\n",
      "M20\n",
      "Concentration (C)\n",
      "Asymmetry (A)\n",
      "Sersic N\n",
      "Shape Asymmetry\n",
      "Gini*M20\n",
      "Gini*C\n",
      "Gini*A\n",
      "Gini*n\n",
      "Gini*A_S\n",
      "M20*C\n",
      "M20*A\n",
      "M20*n\n",
      "M20*A_S\n",
      "C*A\n",
      "C*n\n",
      "C*A_S\n",
      "A*n\n",
      "A*A_S\n",
      "n*A_S\n",
      "accuracy [0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5]\n",
      "0.4\n",
      "5\n",
      "Shape Asymmetry\n",
      "inputs_OG ['Gini', 'M20', 'Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Gini*M20', 'Gini*C', 'Gini*A', 'Gini*n', 'Gini*A_S', 'M20*C', 'M20*A', 'M20*n', 'M20*A_S', 'C*A', 'C*n', 'C*A_S', 'A*n', 'A*A_S', 'n*A_S']\n",
      "M20\n",
      "Concentration (C)\n",
      "Asymmetry (A)\n",
      "Sersic N\n",
      "Shape Asymmetry\n",
      "Gini*M20\n",
      "Gini*C\n",
      "Gini*A\n",
      "Gini*n\n",
      "Gini*A_S\n",
      "M20*C\n",
      "M20*A\n",
      "M20*n\n",
      "M20*A_S\n",
      "C*A\n",
      "C*n\n",
      "C*A_S\n",
      "A*n\n",
      "A*A_S\n",
      "n*A_S\n",
      "accuracy [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5, 0.5, 0.5, 0.5, 0.4, 0.5]\n",
      "0.4\n",
      "13\n",
      "M20*A_S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.1, 2.4, 10.2, 3.5, 10.8, 5.4, 2.1, 9.7, 2.9, 10.2, 4.6, 8.8, 4.3999999999999995, 9.3, 3.1, 9.1, 9.1, 10.5]\n",
      "2.1 0.4 0.4\n",
      "Shape Asymmetry M20*A_S\n",
      "run fg3_m15_alliso\n",
      "myr [60, 120, 150, 180, 210, 240, 270, 300, 320, 340, 360, 400, 420]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "std_scale mean [ 0.5097741  -1.76897196  2.93548409  0.10541085  1.00981552  0.12086474]\n",
      "std_scale var [0.03123415 0.16180426 0.22013719 0.0937227  0.30274627 0.1262214 ]\n",
      "input priors [0.7, 0.3]\n",
      "coef [[-0.22792703 -1.41400938  3.08578835  1.95205955 -0.20283869  2.5501287 ]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[-0.23859387 -1.44197796  3.11751884  2.01489341 -0.21913467  2.59945767]]\n",
      "[-3.7556185]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.22085931 0.15975014 0.23376086 0.36367523 0.19983012 0.34019277]]\n",
      "[0.16662209]\n",
      "fg3_m15_alliso & \n",
      "-0.24 $\\pm$ 0.22 & \n",
      "-1.44 $\\pm$ 0.16 & \n",
      "3.12 $\\pm$ 0.23 & \n",
      "2.01 $\\pm$ 0.36 & \n",
      "-0.22 $\\pm$ 0.2 & \n",
      "2.6 $\\pm$ 0.34 & \n",
      "-3.76 $\\pm$ 0.17//\n",
      "starting misclassified numbers 2.1999999999999997\n",
      "Gini\n",
      "M20\n",
      "Concentration (C)\n",
      "Asymmetry (A)\n",
      "Sersic N\n",
      "Shape Asymmetry\n",
      "Gini*M20\n",
      "Gini*C\n",
      "Gini*A\n",
      "Gini*n\n",
      "Gini*A_S\n",
      "M20*C\n",
      "M20*A\n",
      "M20*n\n",
      "M20*A_S\n",
      "C*A\n",
      "C*n\n",
      "C*A_S\n",
      "A*n\n",
      "A*A_S\n",
      "n*A_S\n",
      "accuracy [2.6, 2.3, 2.1, 2.5, 2.4, 2.1999999999999997, 2.4, 2.3, 2.3, 2.1, 2.1999999999999997, 2.2, 2.4, 2.3, 2.3, 2.1, 2.3, 2.4, 2.7, 2.0, 2.3]\n",
      "2.0\n",
      "19\n",
      "A*A_S\n",
      "inputs_OG ['Gini', 'M20', 'Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry', 'Gini*M20', 'Gini*C', 'Gini*A', 'Gini*n', 'Gini*A_S', 'M20*C', 'M20*A', 'M20*n', 'M20*A_S', 'C*A', 'C*n', 'C*A_S', 'A*n', 'n*A_S']\n",
      "M20\n",
      "Concentration (C)\n",
      "Asymmetry (A)\n",
      "Sersic N\n",
      "Shape Asymmetry\n",
      "Gini*M20\n",
      "Gini*C\n",
      "Gini*A\n",
      "Gini*n\n",
      "Gini*A_S\n",
      "M20*C\n",
      "M20*A\n",
      "M20*n\n",
      "M20*A_S\n",
      "C*A\n",
      "C*n\n",
      "C*A_S\n",
      "A*n\n",
      "A*A_S\n",
      "n*A_S\n",
      "accuracy [2.4, 2.4, 2.6, 2.5, 2.5, 2.6, 2.5, 2.6, 2.7, 2.3, 2.4, 2.6, 2.5, 2.6, 2.5, 2.7, 2.5, 2.8000000000000003, 2.3000000000000003, 2.7]\n",
      "A*A_S\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-062def7d1865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mfirst_A\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_thing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mSTOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msecond_A\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "'''Backwards Selection of which predictors including interaction terms'''\n",
    "\n",
    "'''\n",
    "~~~\n",
    "Introducing Interaction terms\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "\n",
    "#list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "#'fg3_m12_comp_real','fg1_m13_comp_real','fg3_m15_comp_real','fg3_m1_10_comp_real']#,'fg3_m15_alliso','fg3_m1_10_alliso']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "add_noise='no'\n",
    "priors_list=[[0.9,0.1],[0.9,0.1],[0.7,0.3],[0.7,0.3]]\n",
    "\n",
    "#list_runs=[ 'fg3_m12', 'fg1_m13', 'fg3_m15', 'fg3_m1_10']\n",
    "#priors_list=[[0.7,0.3],[0.9,0.1]]\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    print('run', add_on)\n",
    "    \n",
    "\n",
    "    run=list_runs[i]\n",
    "    \n",
    "    df = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "        ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "          \n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "    \n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "            df.set_value(j,'class label',0)\n",
    "    myr=[]\n",
    "    myr_non=[]\n",
    "    for j in range(len(df)):\n",
    "        if df[['class label']].values[j][0]==0.0:\n",
    "            myr_non.append(df[['Myr']].values[j][0])\n",
    "        else:\n",
    "            myr.append(df[['Myr']].values[j][0])\n",
    "    \n",
    "    myr_non=sorted(list(set(myr_non)))\n",
    "    myr=sorted(list(set(myr)))\n",
    "    \n",
    "    print('myr', myr)\n",
    "    print('myr_non', myr_non)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.dropna(inplace=True) # to drop the empty line at file-end\n",
    "    #print(df)\n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    def gini_m20(row):\n",
    "        return row['Gini']*row['M20']\n",
    "    def gini_C(row):\n",
    "        return row['Gini']*row['Concentration (C)']\n",
    "    def gini_A(row):\n",
    "        return row['Gini']*row['Asymmetry (A)']\n",
    "    def gini_n(row):\n",
    "        return row['Gini']*row['Sersic N']\n",
    "    def gini_A_S(row):\n",
    "        return row['Gini']*row['Shape Asymmetry']\n",
    "    \n",
    "    def M20_C(row):\n",
    "        return row['M20']*row['Concentration (C)']\n",
    "    def M20_A(row):\n",
    "        return row['M20']*row['Asymmetry (A)']\n",
    "    def M20_n(row):\n",
    "        return row['M20']*row['Sersic N']\n",
    "    def M20_A_S(row):\n",
    "        return row['M20']*row['Shape Asymmetry']\n",
    "    \n",
    "    def C_A(row):\n",
    "        return row['Concentration (C)']*row['Asymmetry (A)']\n",
    "    def C_n(row):\n",
    "        return row['Concentration (C)']*row['Sersic N']\n",
    "    def C_A_S(row):\n",
    "        return row['Concentration (C)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def A_n(row):\n",
    "        return row['Asymmetry (A)']*row['Sersic N']\n",
    "    def A_A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def n_A_S(row):\n",
    "        return row['Sersic N']*row['Shape Asymmetry']\n",
    "    \n",
    "    df['Gini*M20'] = df.apply(gini_m20,axis=1)\n",
    "    df['Gini*C'] = df.apply(gini_C,axis=1)\n",
    "    df['Gini*A'] = df.apply(gini_A,axis=1)\n",
    "    df['Gini*n'] = df.apply(gini_n,axis=1)\n",
    "    df['Gini*A_S'] = df.apply(gini_A_S,axis=1)\n",
    "    \n",
    "    df['M20*C'] = df.apply(M20_C,axis=1)\n",
    "    df['M20*A'] = df.apply(M20_A,axis=1)\n",
    "    df['M20*n'] = df.apply(M20_n,axis=1)\n",
    "    df['M20*A_S'] = df.apply(M20_A_S,axis=1)\n",
    "    \n",
    "    df['C*A'] = df.apply(C_A,axis=1)\n",
    "    df['C*n'] = df.apply(C_n,axis=1)\n",
    "    df['C*A_S'] = df.apply(C_A_S,axis=1)\n",
    "    \n",
    "    df['A*n'] = df.apply(A_n,axis=1)\n",
    "    df['A*A_S'] = df.apply(A_A_S,axis=1)\n",
    "    \n",
    "    df['n*A_S'] = df.apply(n_A_S,axis=1)\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    #'Clumpiness (S)',\n",
    "    \n",
    "    \n",
    "    y = df['class label'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_nonmerg=[]\n",
    "    X_merg=[]\n",
    "    \n",
    "    for l in range(len(y)):\n",
    "        if y[l]==0:\n",
    "            X_nonmerg.append(X[l])\n",
    "        else:\n",
    "            X_merg.append(X[l])\n",
    "            \n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    print('std_scale mean', std_scale.mean_)\n",
    "    print('std_scale var', np.sqrt(std_scale.var_))\n",
    "    \n",
    "    \n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    \n",
    "    n_params=6\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    print('input priors', priors_list[i])\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    \n",
    "    \n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    \n",
    "    print('coef', coef)\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    kf.get_n_splits(X, y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    coef_list=[]\n",
    "    inter_list=[]\n",
    "    confusion_master=[]\n",
    "    y_test_master=[]\n",
    "    pred_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        \n",
    "        sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "        #priors=[0.1,0.9],\n",
    "    \n",
    "    \n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        #print('coef kfold', coef)\n",
    "        coef_list.append(coef)\n",
    "        inter_list.append(inter)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred =sklearn_lda.predict(X_test)\n",
    "        \n",
    "        '''def predict_with_cutoff(colname, y_prob, df):\n",
    "            n_events = df[colname].values\n",
    "            event_rate = sum(n_events) / float(df.shape[0]) * 100\n",
    "            threshold = np.percentile(y_prob[:, 1], 100 - event_rate)\n",
    "            print \"Cutoff/threshold at: \" + str(threshold)\n",
    "            y_pred = [1 if x >= threshold else 0 for x in y_prob[:, 1]]\n",
    "            return y_pred'''\n",
    "        \n",
    "        '''plt.clf()\n",
    "        fig=plt.figure()#figsize=(6,6)\n",
    "        plot_confusion_matrix(confusion_matrix(pred,y_test)/np.sum(confusion_matrix(pred,y_test)), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'_'+str(count)+'.pdf')\n",
    "        #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "        plt.clf()'''\n",
    "        \n",
    "        confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        pred_master.append(pred)\n",
    "        y_test_master.append(y_test)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    print('~~~~~Stratified K-fold validation means  ~~~~~~')\n",
    "    print(np.mean(coef_list, axis=0))\n",
    "    print(np.mean(inter_list, axis=0))\n",
    "    print('~~~~~Stratified K-fold validation STD ~~~~~~')\n",
    "    print(np.std(coef_list, axis=0))\n",
    "    print(np.std(inter_list, axis=0))\n",
    "    \n",
    "    print(run+str(' & '))\n",
    "    for j in range(len(np.mean(coef_list,axis=0)[0])):\n",
    "        print(str(round(np.mean(coef_list,axis=0)[0][j],2))+r' $\\pm$ '+str(round(np.std(coef_list,axis=0)[0][j],2))+' & ')\n",
    "    print(str(round(np.mean(inter_list,axis=0)[0],2))+r' $\\pm$ '+str(round(np.std(inter_list,axis=0)[0],2))+ '//')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs=['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry',\n",
    "            'Gini*M20','Gini*C','Gini*A','Gini*n','Gini*A_S',\n",
    "            'M20*C','M20*A', 'M20*n', 'M20*A_S', \n",
    "            'C*A','C*n','C*A_S',\n",
    "           'A*n','A*A_S',\n",
    "           'n*A_S']\n",
    "    inputs_OG=inputs\n",
    "    coef_mean=[]\n",
    "    coef_std=[]\n",
    "    coef_mean_std=[]\n",
    "    accuracy=[]\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = df[inputs].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "    y = df['class label'].values\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "    coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "    coef_list=[]\n",
    "    inter_list=[]\n",
    "    confusion_master=[]\n",
    "    y_test_master=[]\n",
    "    pred_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "        #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        #print('coef kfold', coef)\n",
    "        coef_list.append(coef)\n",
    "        inter_list.append(inter)\n",
    "        pred =sklearn_lda.predict(X_test)\n",
    "\n",
    "        confusion_master.append(confusion_matrix(pred,y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    master=np.mean(confusion_master, axis=0).transpose()\n",
    "    \n",
    "    \n",
    "    accuracy_all=(master[1][0]+master[0][1])\n",
    "    \n",
    "    print('starting misclassified numbers', accuracy_all)\n",
    "    \n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        inputs=['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry',\n",
    "            'Gini*M20','Gini*C','Gini*A','Gini*n','Gini*A_S',\n",
    "            'M20*C','M20*A', 'M20*n', 'M20*A_S', \n",
    "            'C*A','C*n','C*A_S',\n",
    "           'A*n','A*A_S',\n",
    "           'n*A_S']\n",
    "        print(inputs[k])\n",
    "        inputs.remove(inputs[k])\n",
    "    \n",
    "        X = df[inputs].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "        # LDA\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.mean(confusion_master, axis=0).transpose()\n",
    "        '''print(master)\n",
    "        print(master[1][0])#row, then column\n",
    "        print('~~~Accuracy~~~')\n",
    "        print((master[1][1]+master[0][0])/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "        print('~~~Precision~~~')\n",
    "        print(master[1][1]/(master[0][1]+master[1][1]))#TP/(TP+FP)\n",
    "        print('~~~Recall~~~')\n",
    "        print(master[1][1]/(master[1][0]+master[1][1]))#TP/(TP+FN)\n",
    "        print('~~~F1~~~')\n",
    "        print((2*master[1][1])/(master[0][1]+master[1][0]+2*master[1][1]))#2TP/(2TP+FP+FN)'''\n",
    "        accuracy.append((master[1][0]+master[0][1]))#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "         \n",
    "    print('accuracy', accuracy)\n",
    "    print(min(accuracy))\n",
    "    print(accuracy.index(min(accuracy)))\n",
    "    print(inputs[accuracy.index(min(accuracy))])\n",
    "    first_thing=str(inputs_OG[accuracy.index(min(accuracy))])\n",
    "    first_A=min(accuracy)\n",
    "    '''Now we select the second one that IMPROVES THE ACCURACY'''\n",
    "    inputs_OG.remove(str(inputs_OG[accuracy.index(min(accuracy))]))\n",
    "    \n",
    "    accuracy=[]\n",
    "    print('inputs_OG', inputs_OG)\n",
    "    \n",
    "    for k in range(len(inputs_OG)):\n",
    "        \n",
    "        inputs=['M20', 'Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry', 'Gini*M20', 'Gini*C', 'Gini*A', 'Gini*n', 'Gini*A_S', 'M20*C', 'M20*A', 'M20*n', 'M20*A_S', 'C*A', 'C*n', 'C*A_S', 'A*n', 'A*A_S', 'n*A_S']\n",
    "        print(inputs[k])\n",
    "        inputs.remove(inputs[k])\n",
    "        X = df[inputs].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.mean(confusion_master, axis=0).transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1]))#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "    print('accuracy', accuracy)\n",
    "    if min(accuracy) > first_A:\n",
    "        print(first_thing)\n",
    "        STOP\n",
    "    print(min(accuracy))\n",
    "    second_A=min(accuracy)\n",
    "    print(accuracy.index(min(accuracy)))\n",
    "    print(inputs[accuracy.index(min(accuracy))])\n",
    "    second_thing=str(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    inputs.remove(second_thing)\n",
    "    accuracy=[]\n",
    "    \n",
    "    for k in range(len(inputs)):\n",
    "        \n",
    "    \n",
    "        X = df[[first_thing,inputs[k]]].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "        #priors=[],\n",
    "\n",
    "\n",
    "\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "        #print('predictsions', X_lda_sklearn)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        kf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "\n",
    "        coef_list=[]\n",
    "        inter_list=[]\n",
    "        confusion_master=[]\n",
    "        y_test_master=[]\n",
    "        pred_master=[]\n",
    "        count=0\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "            sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "            #priors=[0.1,0.9],\n",
    "\n",
    "\n",
    "            X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "            coef = sklearn_lda.coef_\n",
    "            inter = sklearn_lda.intercept_\n",
    "            #print('coef kfold', coef)\n",
    "            coef_list.append(coef)\n",
    "            inter_list.append(inter)\n",
    "            pred =sklearn_lda.predict(X_test)\n",
    "            \n",
    "            confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        master=np.mean(confusion_master, axis=0).transpose()\n",
    "        accuracy.append((master[1][0]+master[0][1]))#/(master[0][0]+master[1][0]+master[0][1]+master[1][1]))\n",
    "\n",
    "    if min(accuracy) > second_A:\n",
    "        print(accuracy)\n",
    "        print(min(accuracy), second_A, first_A)\n",
    "        print(first_thing, second_thing)\n",
    "        continue\n",
    "    print(min(accuracy))\n",
    "    print(accuracy.index(min(accuracy)))\n",
    "    print(inputs[accuracy.index(min(accuracy))])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run fg3_m12_alliso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:72: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myr [30, 40, 60, 80, 100, 120, 140, 160, 170, 180, 185, 190, 195, 205, 210, 220, 225, 230, 240, 250, 260]\n",
      "myr_non [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 120, 150, 180]\n",
      "std_scale mean [ 0.5257748  -1.78554059  3.099091    0.14246161  1.21511054  0.15368987]\n",
      "std_scale var [0.04782654 0.28856416 0.62700362 0.15084112 0.59729942 0.15540656]\n",
      "input priors [0.9, 0.1]\n",
      "coef [[ 4.1609288  -1.36543768  2.62179352  4.95185848  3.15791192  3.12215882]]\n",
      "~~~~~Stratified K-fold validation means  ~~~~~~\n",
      "[[ 4.17470792 -1.36036639  2.65349867  4.9659255   3.15719159  3.15365088]]\n",
      "[-8.82642992]\n",
      "~~~~~Stratified K-fold validation STD ~~~~~~\n",
      "[[0.27982845 0.29195162 0.31190489 0.41448807 0.24252398 0.35931986]]\n",
      "[0.26368272]\n",
      "fg3_m12_alliso & \n",
      "4.17 $\\pm$ 0.28 & \n",
      "-1.36 $\\pm$ 0.29 & \n",
      "2.65 $\\pm$ 0.31 & \n",
      "4.97 $\\pm$ 0.41 & \n",
      "3.16 $\\pm$ 0.24 & \n",
      "3.15 $\\pm$ 0.36 & \n",
      "-8.83 $\\pm$ 0.26//\n",
      "[6.08244154e-01 2.48502839e-01 5.45418231e-02 4.03806021e-02\n",
      " 1.91734400e-02 1.49725231e-02 5.47615094e-03 3.80861704e-03\n",
      " 1.74944693e-03 9.30193444e-04 6.96726557e-04 4.53104590e-04\n",
      " 3.40163343e-04 2.14114116e-04 1.52182447e-04 1.18234582e-04\n",
      " 1.00699579e-04 9.16798772e-05 2.79161559e-05 1.61262013e-05\n",
      " 9.26353061e-06]\n",
      "[[ 2.38842936e-01 -4.11796166e-02  1.87002156e-01  2.06567205e-01\n",
      "   2.39793457e-01  2.37041846e-01 -1.34268152e-01  2.17329325e-01\n",
      "   2.13371646e-01  2.50872963e-01  2.40524548e-01 -1.51864796e-01\n",
      "  -2.46832264e-01 -2.11836591e-01 -2.40293764e-01  2.39267632e-01\n",
      "   2.38470912e-01  2.56023811e-01  2.26296979e-01  1.92511009e-01\n",
      "   2.52607812e-01]\n",
      " [-3.66781601e-02  4.04850300e-01 -2.71554109e-01  2.69414850e-01\n",
      "  -9.82431840e-02  1.60589914e-01  3.56806513e-01 -2.20359743e-01\n",
      "   2.57997132e-01 -9.34881142e-02  1.52891373e-01  3.56378321e-01\n",
      "  -1.04031395e-01  2.47843616e-01  7.56503110e-03  1.39018555e-01\n",
      "  -1.85084549e-01  3.12925477e-02  1.81849575e-01  2.89373884e-01\n",
      "   8.80714112e-02]\n",
      " [-7.28285159e-02 -2.06933178e-01 -1.25092258e-01 -1.60554870e-01\n",
      "  -2.25319474e-01  3.43717831e-01 -1.49036985e-01 -1.26126322e-01\n",
      "  -1.59266629e-01 -2.21645641e-01  3.32580958e-01 -4.21858723e-02\n",
      "   5.67622678e-02  7.88278717e-02 -4.59666780e-01 -2.10280556e-01\n",
      "  -2.04004242e-01  3.01024074e-01 -2.93860970e-01  1.27720058e-01\n",
      "   1.29183964e-01]\n",
      " [-2.82445258e-01 -1.47704667e-02 -2.95190382e-01 -1.34732510e-01\n",
      "   4.20236904e-01  7.03310129e-02  1.15690331e-01 -3.17967941e-01\n",
      "  -1.55220153e-01  3.12626727e-01  2.99908523e-02  1.23260741e-01\n",
      "   2.27968235e-01 -2.90803913e-01 -3.23493651e-02 -2.96221507e-01\n",
      "   1.52182556e-01 -5.20453041e-02  1.83920048e-01 -8.67895344e-03\n",
      "   3.09291534e-01]\n",
      " [-1.59447187e-01  3.54123355e-01  4.07476694e-01 -2.15825999e-01\n",
      "  -1.52940560e-02  5.37210478e-02  3.79104251e-01  2.83072165e-01\n",
      "  -1.93375222e-01 -8.14974640e-03  5.29173092e-02  5.41226223e-02\n",
      "   3.76394228e-01  1.53243453e-01 -1.54572408e-02  1.16739034e-01\n",
      "   1.93777106e-01  3.13406551e-01 -7.11588831e-02 -1.16213999e-01\n",
      "   1.81741233e-01]\n",
      " [-7.48407918e-01 -2.11184103e-01  1.31012905e-01  9.25207619e-02\n",
      "  -4.96448573e-02 -6.59516525e-02  1.43859452e-01 -1.35230662e-01\n",
      "   9.62896861e-03 -1.66105805e-01 -1.44097982e-01 -1.58296204e-01\n",
      "  -3.63154927e-01 -8.06180836e-02 -1.10745177e-01  2.71799416e-01\n",
      "   6.20138372e-02  1.11160947e-01  9.19572819e-02 -2.89962458e-02\n",
      "  -1.54894244e-02]\n",
      " [-1.66630230e-01 -1.25422905e-02  1.01602408e-01  1.36993705e-01\n",
      "   3.71758850e-02  1.15690208e-01  9.35419808e-02  1.23254313e-02\n",
      "   1.39633035e-01 -1.40780280e-02  9.43223072e-02 -1.81948127e-01\n",
      "   2.63050644e-01 -2.32294502e-01  2.42719384e-01 -8.70767827e-02\n",
      "   1.90156798e-01 -1.03271420e-01 -3.66417737e-01  6.33191869e-01\n",
      "  -2.93174201e-01]\n",
      " [-4.21454262e-02 -1.98049486e-01  1.21837492e-01 -1.43483194e-01\n",
      "  -1.80385135e-01 -1.20054268e-01 -1.30155096e-01  7.42107880e-02\n",
      "  -7.35393654e-02 -9.46353135e-02 -5.85920330e-02 -2.26272060e-01\n",
      "   1.54655821e-01  2.74170571e-01  2.23669943e-01 -1.20558190e-01\n",
      "  -1.41045240e-01 -6.64644350e-02  5.12058420e-01  4.40372318e-01\n",
      "   3.75605732e-01]\n",
      " [ 2.90976536e-02 -3.51635104e-01 -1.34077597e-01 -2.56195726e-01\n",
      "   1.04104406e-01 -1.19653304e-01 -1.64390590e-01 -4.49506237e-02\n",
      "  -8.74678515e-02  7.15450461e-02  5.64365264e-04  4.77747824e-01\n",
      "   1.94505073e-01  4.65475330e-02  9.02336476e-02  5.10479405e-01\n",
      "   4.13620408e-02  2.95351897e-01  5.10846829e-02  2.06445278e-01\n",
      "  -2.31900523e-01]\n",
      " [ 1.05886370e-01  8.81098979e-02 -8.88194251e-03 -2.62157179e-01\n",
      "  -9.65264927e-02 -1.27001727e-02  7.69919096e-03  8.33414667e-03\n",
      "  -2.93948746e-01 -6.54296572e-02 -3.48201637e-02  2.16370949e-01\n",
      "  -5.30164396e-01 -1.20285504e-01  2.82042588e-01  5.04039711e-02\n",
      "   1.96223305e-01 -1.19345672e-01 -3.52650977e-01  2.06563387e-01\n",
      "   4.08027851e-01]\n",
      " [-4.47105952e-02  1.19923582e-01  7.58625293e-02 -3.15230188e-01\n",
      "   1.25157789e-01  1.06730385e-01  7.62943986e-02  1.00614355e-01\n",
      "  -2.46058929e-01  1.40215487e-01  1.82999030e-01  2.93876814e-02\n",
      "  -3.68597327e-01  2.43730294e-01 -1.27656443e-01 -2.77374258e-01\n",
      "   1.38686309e-01 -7.69699805e-02  2.93055659e-01  1.62344065e-01\n",
      "  -5.43175785e-01]\n",
      " [-1.22406540e-01 -1.26790236e-01  7.98138207e-02  2.79303952e-02\n",
      "   4.48795474e-01  2.49435206e-01  1.11323624e-02  4.36530685e-02\n",
      "  -3.59681040e-02  2.38522739e-01  1.56110348e-01 -1.54867221e-01\n",
      "  -1.08368734e-01  3.50266083e-01  3.77160805e-01  1.07615724e-01\n",
      "  -4.75127216e-01  6.84378930e-03 -2.45003520e-01 -1.08290240e-01\n",
      "   6.14562205e-02]\n",
      " [-1.10169676e-01 -2.30932494e-01 -8.35414203e-02 -3.96617272e-02\n",
      "  -2.58153241e-01  2.89910522e-01 -3.65515023e-02 -1.19882978e-02\n",
      "   1.63753230e-01  3.28076447e-02  3.96445203e-01  2.88333176e-02\n",
      "   1.10631481e-01  2.46079358e-01  1.53015427e-01  1.55753834e-01\n",
      "   4.63542778e-01 -4.12318625e-01  3.85644689e-02 -2.77597372e-01\n",
      "   6.34398701e-02]\n",
      " [-7.35035634e-02 -1.90890425e-02 -3.30397351e-01  1.52589231e-01\n",
      "  -1.56734614e-01 -1.81857156e-01 -6.65322701e-02  7.49504487e-02\n",
      "   1.24730235e-01  1.86508543e-01 -4.76497262e-03 -1.06489579e-01\n",
      "  -1.18211984e-01  2.31430216e-01  3.21879109e-01 -3.19860879e-01\n",
      "   3.00983851e-01  5.96613178e-01 -7.56521692e-02 -8.00702556e-02\n",
      "  -1.65846736e-02]\n",
      " [-1.72953497e-02  3.98020519e-01 -4.34844632e-01 -1.21870404e-01\n",
      "  -1.23740405e-01  2.03165834e-01 -1.78126964e-01 -1.43287714e-02\n",
      "  -3.07418303e-01  4.01765672e-02 -5.13763999e-02 -4.85200880e-01\n",
      "   7.47530200e-02 -1.19804127e-01  8.97865332e-02  4.07498435e-01\n",
      "  -1.73245050e-02  2.64718945e-02  9.72698882e-02 -1.01302305e-03\n",
      "  -1.00573956e-01]\n",
      " [ 2.21917777e-01 -7.38396816e-02 -1.27701346e-02 -4.46865425e-01\n",
      "  -2.06063352e-03 -3.53315274e-01  3.96670617e-01 -3.01351576e-01\n",
      "   3.03810417e-01 -1.35123534e-02  3.43355982e-01 -3.41345128e-01\n",
      "  -6.92581475e-02 -1.17294746e-01  3.89606091e-02  1.02127500e-01\n",
      "  -7.59190750e-02  8.42760199e-02 -1.68033729e-02 -4.22963890e-02\n",
      "  -1.08978368e-02]\n",
      " [-3.29684160e-01  2.14895894e-01 -7.46989497e-02 -1.13936233e-01\n",
      "  -1.92725363e-01 -3.94064888e-01 -2.46175202e-01  3.10364901e-01\n",
      "   1.80377506e-01  4.57713984e-01  2.27709008e-01  9.71692208e-02\n",
      "   4.56753160e-03 -1.75156177e-02 -2.21644104e-01  4.42491594e-02\n",
      "  -2.10352580e-01 -1.92637253e-01 -1.57916866e-01  9.46085243e-02\n",
      "   8.49643246e-02]\n",
      " [-1.10281290e-01  3.95854740e-02  1.33664092e-01 -2.22152398e-02\n",
      "  -2.23369997e-01  1.62322827e-01 -8.47691192e-02  1.37509903e-01\n",
      "  -3.54683658e-04 -1.07948673e-01  3.36473948e-01  2.11867782e-01\n",
      "  -3.65465789e-02 -5.33069315e-01  4.12078938e-01 -1.36820631e-01\n",
      "  -2.83143810e-01  1.58033089e-01  2.64836598e-01 -1.86427139e-01\n",
      "  -1.08407622e-01]\n",
      " [-1.16861120e-02  1.12913702e-01  1.81532669e-02  3.66108330e-01\n",
      "   2.68492552e-01 -4.49809964e-01 -1.73097290e-01 -8.57254316e-02\n",
      "  -3.75316918e-01 -3.33872463e-01  5.14477341e-01 -2.65835121e-02\n",
      "   4.20287611e-02  7.37086858e-02  1.58266848e-02  4.70134721e-02\n",
      "   1.09511181e-01 -3.35120571e-02  9.09317222e-03 -1.43423453e-02\n",
      "   1.51259327e-02]\n",
      " [ 1.08692462e-01 -6.61721937e-03  3.71262383e-01  2.41395893e-01\n",
      "  -3.75155016e-01 -1.50527560e-02 -2.24428280e-03 -5.32593720e-01\n",
      "  -3.03485037e-01  5.13975289e-01  2.69418743e-02 -7.87302284e-03\n",
      "   1.23178086e-02  2.10097042e-02  2.01416288e-02  5.14018343e-02\n",
      "  -3.30577996e-02  4.90145470e-02 -8.92312077e-03  1.38297620e-02\n",
      "  -5.41916568e-02]\n",
      " [-1.11882884e-01  3.76832278e-01  2.88005511e-01 -2.58121181e-01\n",
      "   1.58844650e-01  6.62851129e-02 -5.50758998e-01 -4.07410422e-01\n",
      "   3.54234239e-01 -1.55694317e-01 -6.39789474e-02  3.94268889e-02\n",
      "   2.14613870e-03  1.11842618e-01  7.73947631e-02 -4.00904798e-02\n",
      "   1.11463367e-01  8.75894264e-02 -2.19230820e-02 -2.95550481e-02\n",
      "   5.54830232e-03]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-1494e687ba27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0mSTOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "'''Now, running PCA to do variable deletion'''\n",
    "\n",
    "'''Backwards Selection of which predictors including interaction terms'''\n",
    "\n",
    "'''\n",
    "~~~\n",
    "Introducing Interaction terms\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "\n",
    "#list_runs=['fg3_m12_alliso', 'fg1_m13_alliso', 'fg3_m15_alliso', 'fg3_m1_10_alliso']\n",
    "#'fg3_m12_comp_real','fg1_m13_comp_real','fg3_m15_comp_real','fg3_m1_10_comp_real']#,'fg3_m15_alliso','fg3_m1_10_alliso']#,'fg1_m13']#['fg3_m1_10', 'all','fg1_m13','fg3_m15','fg3_m12']#,'fg3_m12','fg1_m13']#'fg3_m1_10', 'fg3_m15']\n",
    "add_noise='no'\n",
    "priors_list=[[0.9,0.1],[0.9,0.1],[0.7,0.3],[0.7,0.3]]\n",
    "\n",
    "#list_runs=[ 'fg3_m12', 'fg1_m13', 'fg3_m15', 'fg3_m1_10']\n",
    "#priors_list=[[0.7,0.3],[0.9,0.1]]\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    print('run', add_on)\n",
    "    \n",
    "\n",
    "    run=list_runs[i]\n",
    "    \n",
    "    df = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "        ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "          \n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "    \n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "            df.set_value(j,'class label',0)\n",
    "    myr=[]\n",
    "    myr_non=[]\n",
    "    for j in range(len(df)):\n",
    "        if df[['class label']].values[j][0]==0.0:\n",
    "            myr_non.append(df[['Myr']].values[j][0])\n",
    "        else:\n",
    "            myr.append(df[['Myr']].values[j][0])\n",
    "    \n",
    "    myr_non=sorted(list(set(myr_non)))\n",
    "    myr=sorted(list(set(myr)))\n",
    "    \n",
    "    print('myr', myr)\n",
    "    print('myr_non', myr_non)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df.dropna(inplace=True) # to drop the empty line at file-end\n",
    "    #print(df)\n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    def gini_m20(row):\n",
    "        return row['Gini']*row['M20']\n",
    "    def gini_C(row):\n",
    "        return row['Gini']*row['Concentration (C)']\n",
    "    def gini_A(row):\n",
    "        return row['Gini']*row['Asymmetry (A)']\n",
    "    def gini_n(row):\n",
    "        return row['Gini']*row['Sersic N']\n",
    "    def gini_A_S(row):\n",
    "        return row['Gini']*row['Shape Asymmetry']\n",
    "    \n",
    "    def M20_C(row):\n",
    "        return row['M20']*row['Concentration (C)']\n",
    "    def M20_A(row):\n",
    "        return row['M20']*row['Asymmetry (A)']\n",
    "    def M20_n(row):\n",
    "        return row['M20']*row['Sersic N']\n",
    "    def M20_A_S(row):\n",
    "        return row['M20']*row['Shape Asymmetry']\n",
    "    \n",
    "    def C_A(row):\n",
    "        return row['Concentration (C)']*row['Asymmetry (A)']\n",
    "    def C_n(row):\n",
    "        return row['Concentration (C)']*row['Sersic N']\n",
    "    def C_A_S(row):\n",
    "        return row['Concentration (C)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def A_n(row):\n",
    "        return row['Asymmetry (A)']*row['Sersic N']\n",
    "    def A_A_S(row):\n",
    "        return row['Asymmetry (A)']*row['Shape Asymmetry']\n",
    "    \n",
    "    def n_A_S(row):\n",
    "        return row['Sersic N']*row['Shape Asymmetry']\n",
    "    \n",
    "    df['Gini*M20'] = df.apply(gini_m20,axis=1)\n",
    "    df['Gini*C'] = df.apply(gini_C,axis=1)\n",
    "    df['Gini*A'] = df.apply(gini_A,axis=1)\n",
    "    df['Gini*n'] = df.apply(gini_n,axis=1)\n",
    "    df['Gini*A_S'] = df.apply(gini_A_S,axis=1)\n",
    "    \n",
    "    df['M20*C'] = df.apply(M20_C,axis=1)\n",
    "    df['M20*A'] = df.apply(M20_A,axis=1)\n",
    "    df['M20*n'] = df.apply(M20_n,axis=1)\n",
    "    df['M20*A_S'] = df.apply(M20_A_S,axis=1)\n",
    "    \n",
    "    df['C*A'] = df.apply(C_A,axis=1)\n",
    "    df['C*n'] = df.apply(C_n,axis=1)\n",
    "    df['C*A_S'] = df.apply(C_A_S,axis=1)\n",
    "    \n",
    "    df['A*n'] = df.apply(A_n,axis=1)\n",
    "    df['A*A_S'] = df.apply(A_A_S,axis=1)\n",
    "    \n",
    "    df['n*A_S'] = df.apply(n_A_S,axis=1)\n",
    "    #print(df)\n",
    "    \n",
    "    \n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    #'Clumpiness (S)',\n",
    "    \n",
    "    \n",
    "    y = df['class label'].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_nonmerg=[]\n",
    "    X_merg=[]\n",
    "    \n",
    "    for l in range(len(y)):\n",
    "        if y[l]==0:\n",
    "            X_nonmerg.append(X[l])\n",
    "        else:\n",
    "            X_merg.append(X[l])\n",
    "            \n",
    "    \n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    print('std_scale mean', std_scale.mean_)\n",
    "    print('std_scale var', np.sqrt(std_scale.var_))\n",
    "    \n",
    "    \n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    \n",
    "    n_params=6\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    print('input priors', priors_list[i])\n",
    "    sklearn_lda = LDA(priors=priors_list[i], store_covariance=True)#store_covariance=False\n",
    "    #priors=[],\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    \n",
    "    \n",
    "    #print('predictsions', X_lda_sklearn)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    \n",
    "    print('coef', coef)\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    kf.get_n_splits(X, y)\n",
    "   \n",
    "    \n",
    "    \n",
    "    coef_list=[]\n",
    "    inter_list=[]\n",
    "    confusion_master=[]\n",
    "    y_test_master=[]\n",
    "    pred_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        \n",
    "        sklearn_lda = LDA( priors=priors_list[i],store_covariance=True)#store_covariance=False\n",
    "        #priors=[0.1,0.9],\n",
    "    \n",
    "    \n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        #print('coef kfold', coef)\n",
    "        coef_list.append(coef)\n",
    "        inter_list.append(inter)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred =sklearn_lda.predict(X_test)\n",
    "        \n",
    "        '''def predict_with_cutoff(colname, y_prob, df):\n",
    "            n_events = df[colname].values\n",
    "            event_rate = sum(n_events) / float(df.shape[0]) * 100\n",
    "            threshold = np.percentile(y_prob[:, 1], 100 - event_rate)\n",
    "            print \"Cutoff/threshold at: \" + str(threshold)\n",
    "            y_pred = [1 if x >= threshold else 0 for x in y_prob[:, 1]]\n",
    "            return y_pred'''\n",
    "        \n",
    "        '''plt.clf()\n",
    "        fig=plt.figure()#figsize=(6,6)\n",
    "        plot_confusion_matrix(confusion_matrix(pred,y_test)/np.sum(confusion_matrix(pred,y_test)), sklearn_lda.classes_, title='Normalized Confusion Matrix')\n",
    "        plt.savefig('../MaNGA_Papers/Paper_I/Confusion_matrix_'+str(run)+'_'+str(count)+'.pdf')\n",
    "        #This is from this website: http://www.science.smith.edu/~jcrouser/SDS293/labs/lab5-py.html\n",
    "        plt.clf()'''\n",
    "        \n",
    "        confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        pred_master.append(pred)\n",
    "        y_test_master.append(y_test)\n",
    "        \n",
    "        count+=1\n",
    "        \n",
    "        \n",
    "    print('~~~~~Stratified K-fold validation means  ~~~~~~')\n",
    "    print(np.mean(coef_list, axis=0))\n",
    "    print(np.mean(inter_list, axis=0))\n",
    "    print('~~~~~Stratified K-fold validation STD ~~~~~~')\n",
    "    print(np.std(coef_list, axis=0))\n",
    "    print(np.std(inter_list, axis=0))\n",
    "    \n",
    "    print(run+str(' & '))\n",
    "    for j in range(len(np.mean(coef_list,axis=0)[0])):\n",
    "        print(str(round(np.mean(coef_list,axis=0)[0][j],2))+r' $\\pm$ '+str(round(np.std(coef_list,axis=0)[0][j],2))+' & ')\n",
    "    print(str(round(np.mean(inter_list,axis=0)[0],2))+r' $\\pm$ '+str(round(np.std(inter_list,axis=0)[0],2))+ '//')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs=['Gini','M20','Concentration (C)','Asymmetry (A)','Sersic N','Shape Asymmetry',\n",
    "            'Gini*M20','Gini*C','Gini*A','Gini*n','Gini*A_S',\n",
    "            'M20*C','M20*A', 'M20*n', 'M20*A_S', \n",
    "            'C*A','C*n','C*A_S',\n",
    "           'A*n','A*A_S',\n",
    "           'n*A_S']\n",
    "    inputs_OG=inputs\n",
    "    coef_mean=[]\n",
    "    coef_std=[]\n",
    "    coef_mean_std=[]\n",
    "    accuracy=[]\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    \n",
    "    X = df[inputs].values\n",
    "        #'Clumpiness (S)',\n",
    "\n",
    "\n",
    "    y = df['class label'].values\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=21)\n",
    "    pca.fit(X)\n",
    "\n",
    "\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(pca.components_)\n",
    "    STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7) [ 7.24  0.14 23.67  3.77  0.   -3.07 24.22]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> (5, 7)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'STOP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6570b460e4f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m#plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../MaNGA_Papers/Paper_I/color_predictors_new.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mSTOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dark\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'STOP' is not defined"
     ]
    }
   ],
   "source": [
    "'''Make a confusion-matrix like graph for the importance of the predictors'''\n",
    "    \n",
    "    \n",
    "matrix = np.array([[7.24, 0.14, 23.67, 3.77, 0, -3.07,24.22],\n",
    "                   [17.69,0,0,20.81,0,73.81,0],\n",
    "          [9.74,0.52,15.91,9.56,-0.87,-2.99,59.97],\n",
    "          [41.35, -8.66,52.35,13.86,7.77,-3.56,55.17],\n",
    "          [1.97,-3.48,14.5,19.41,0,20.1, 39.27]])\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "print(matrix.shape,matrix[0])\n",
    "matrix_row_0=matrix[0]/max(matrix[0])\n",
    "matrix_row_1=matrix[1]/max(matrix[1])\n",
    "matrix_row_2=matrix[2]/max(matrix[2])\n",
    "matrix_row_3=matrix[3]/max(matrix[3])\n",
    "matrix_row_4=matrix[4]/max(matrix[4])\n",
    "\n",
    "matrix_new=[matrix_row_0,matrix_row_1,matrix_row_2,matrix_row_3,matrix_row_4]\n",
    "\n",
    "matrix_new=np.array(matrix_new)\n",
    "print(type(matrix),type(matrix_new), np.shape(matrix_new))\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "my_cmap = ListedColormap(sns.color_palette(\"BuGn\").as_hex())\n",
    "\n",
    "\n",
    "#sns.diverging_palette(10, 220, sep=80, n=7)\n",
    "sns.set_style('dark')\n",
    "plt.imshow(abs(matrix_new), cmap=my_cmap)\n",
    "tick_marks_x = np.arange(np.shape(matrix)[1])\n",
    "tick_marks_y = np.arange(np.shape(matrix)[0])\n",
    "\n",
    "target_names_x=[r'$Gini$',r'$M_{20}$',r'$C$',r'$A$',r'$S$',r'$n$',r'$A_S$']\n",
    "target_names_y=['All','q0.5_fg0.3', 'q0.333_fg0.1','q0.2_fg0.3_BT0.2','q0.1_fg0.3_BT0.2']\n",
    "plt.xticks(tick_marks_x, target_names_x)#, rotation=45)\n",
    "plt.yticks(tick_marks_y, target_names_y)\n",
    "plt.colorbar()\n",
    "\n",
    "\n",
    "fmt = '.2f' \n",
    "thresh = 1.5\n",
    "    \n",
    "for i, j in itertools.product(range(matrix_new.shape[0]), range(matrix_new.shape[1])):\n",
    "    plt.text(j, i, format(matrix_new[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if matrix_new[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('../MaNGA_Papers/Paper_I/color_predictors_new.pdf')\n",
    "STOP\n",
    "def plot_confusion_matrix(cm, target_names, title, cmap=plt.cm.Blues):\n",
    "    sns.set_style(\"dark\")\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    target_names=['Nonmerger','Merger']\n",
    "    plt.xticks(tick_marks, target_names)#, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('True label', size=20)\n",
    "    plt.xlabel('Predicted label', size=20)\n",
    "    \n",
    "    fmt = '.2f' \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGACAYAAAC6OPj9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbE+FRkRERGxPhUZERERs77+EUbjjYtSoPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('done')\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(k, avg_dec_0, color='red')\n",
    "\n",
    "plt.xlabel(r'# of k folds')\n",
    "plt.ylabel(r'% Accuracy')\n",
    "plt.axvline(x=10, color='red', ls='--')\n",
    "plt.xlim([0,25])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-06bfcc9bd58f>\", line 64, in <module>\n",
      "    sep='\\t'\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\", line 709, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\", line 449, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\", line 818, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1049, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1695, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 402, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 718, in pandas._libs.parsers.TextReader._setup_parser_source\n",
      "FileNotFoundError: File b'LDA_img_ratio_fg1_m13_early_late_all_things.txt' does not exist\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'FileNotFoundError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/inspect.py\", line 1454, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/inspect.py\", line 666, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/inspect.py\", line 695, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/inspect.py\", line 679, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/beckynevin/anaconda/lib/python3.6/posixpath.py\", line 374, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'LDA_img_ratio_fg1_m13_early_late_all_things.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A bootstrap method to determine errors by dropping each galaxy individually\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "~~~\n",
    "Now just for the imaging part of it!\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "add_on='fg1_m13'#,'fg1_m13']#,'fg1_m13']\n",
    "\n",
    "run=add_on\n",
    "c_0=[]\n",
    "c_1=[]\n",
    "c_2=[]\n",
    "c_3=[]\n",
    "c_4=[]\n",
    "c_5=[]\n",
    "c_6=[]\n",
    "\n",
    "\n",
    "for kz in range(len(df)):\n",
    "    df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "    header=[0],\n",
    "    sep='\\t'\n",
    "    )#,skiprows=10,nrows=10\n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "    df.drop(df.index[kz])\n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "\n",
    "        #Then, you can optionally change the class values of all of these viewpoints\n",
    "\n",
    "        #.set_value(index, col, value, \n",
    "            df.set_value(j,'class label',0.0)\n",
    "\n",
    "\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    \n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "\n",
    "    n_params=7\n",
    "\n",
    "\n",
    "    y = df['class label'].values\n",
    "    \n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    sklearn_lda = LDA(priors=[0.94,0.06])\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    \n",
    "    c_0.append(coef[0][0])\n",
    "    c_1.append(coef[0][1])\n",
    "    c_2.append(coef[0][2])\n",
    "    c_3.append(coef[0][3])\n",
    "    c_4.append(coef[0][4])\n",
    "    c_5.append(coef[0][5])\n",
    "    c_6.append(coef[0][6])\n",
    "    \n",
    "'''Now run the full out analysis please'''    \n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "    header=[0],\n",
    "    sep='\\t'\n",
    "    )#,skiprows=10,nrows=10\n",
    "df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "for j in range(len(df)):\n",
    "    if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "\n",
    "\n",
    "        #I use this part to check if there is any separation at these points in time\n",
    "        #Or if there are more than two bulges\n",
    "        #print(df[['class label','Myr','Viewpoint','# Bulges', 'Sep']].values[j])\n",
    "\n",
    "        #Then, you can optionally change the class values of all of these viewpoints\n",
    "\n",
    "        #.set_value(index, col, value, \n",
    "        df.set_value(j,'class label',0.0)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X)\n",
    "X = std_scale.transform(X)\n",
    "\n",
    "\n",
    "n_params=7\n",
    "\n",
    "\n",
    "y = df['class label'].values\n",
    "\n",
    "\n",
    "enc = LabelEncoder()\n",
    "label_encoder = enc.fit(y)\n",
    "y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# LDA\n",
    "sklearn_lda = LDA(priors=[0.94,0.06])\n",
    "X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "dec = sklearn_lda.score(X,y)\n",
    "prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "coef = sklearn_lda.coef_\n",
    "print(coef)\n",
    "print(np.mean(c_0),np.std(c_0))\n",
    "print(np.mean(c_1),np.std(c_1))\n",
    "print(np.mean(c_2),np.std(c_2))\n",
    "print(np.mean(c_3),np.std(c_3))\n",
    "print(np.mean(c_4),np.std(c_4))\n",
    "print(np.mean(c_5),np.std(c_5))\n",
    "print(np.mean(c_6),np.std(c_6))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run fg3_m12\n",
      "[1. 5. 0. 1. 0.]\n",
      "[ 1. 10.  0.  1.  0.]\n",
      "[ 1. 20.  0.  1.  0.]\n",
      "[ 1. 30.  0.  1.  0.]\n",
      "[1. 5. 1. 1. 0.]\n",
      "[ 1. 10.  1.  1.  0.]\n",
      "[ 1. 20.  1.  1.  0.]\n",
      "[ 1. 30.  1.  1.  0.]\n",
      "[1. 5. 2. 1. 0.]\n",
      "[ 1. 10.  2.  1.  0.]\n",
      "[ 1. 20.  2.  1.  0.]\n",
      "[ 1. 30.  2.  1.  0.]\n",
      "[1. 5. 3. 1. 0.]\n",
      "[ 1. 10.  3.  1.  0.]\n",
      "[ 1. 20.  3.  1.  0.]\n",
      "[1. 5. 4. 1. 0.]\n",
      "[ 1. 10.  4.  1.  0.]\n",
      "[ 1. 20.  4.  1.  0.]\n",
      "[ 1. 30.  4.  1.  0.]\n",
      "[1. 5. 5. 1. 0.]\n",
      "[ 1. 10.  5.  1.  0.]\n",
      "[ 1. 20.  5.  1.  0.]\n",
      "[ 1. 30.  5.  1.  0.]\n",
      "[1. 5. 6. 1. 0.]\n",
      "[ 1. 10.  6.  1.  0.]\n",
      "[ 1. 20.  6.  1.  0.]\n",
      "[0. 5. 0. 1. 0.]\n",
      "[0. 5. 0. 1. 0.]\n",
      "[0. 5. 1. 1. 0.]\n",
      "[0. 5. 1. 1. 0.]\n",
      "[0. 5. 2. 1. 0.]\n",
      "[0. 5. 2. 1. 0.]\n",
      "[0. 5. 3. 1. 0.]\n",
      "[0. 5. 3. 1. 0.]\n",
      "[0. 5. 4. 1. 0.]\n",
      "[0. 5. 4. 1. 0.]\n",
      "[0. 5. 5. 1. 0.]\n",
      "[0. 5. 5. 1. 0.]\n",
      "[0. 5. 6. 1. 0.]\n",
      "[0. 5. 6. 1. 0.]\n",
      "X before norm [[ 0.70978658 -0.79113272  4.42303291 ...  0.34526739  2.9482\n",
      "   0.35841947]\n",
      " [ 0.76440784 -0.84553525  4.3461586  ...  0.34911774  2.7168\n",
      "   0.36333205]\n",
      " [ 0.71709391 -2.65401726  4.51544993 ...  0.27113807  2.7951\n",
      "   0.60966631]\n",
      " ...\n",
      " [ 0.74797309 -1.43463724  2.72034022 ...  0.17243279  1.2946\n",
      "   0.07219759]\n",
      " [ 0.76757161 -1.83924521  2.91788293 ...  0.08947134  0.8205\n",
      "   0.12940721]\n",
      " [ 0.79288243 -2.11533177  3.11624645 ...  0.21211015  1.982\n",
      "   0.09409341]]\n",
      "X after norm [[-0.78457939  2.14009348  0.70981224 ...  0.82466546  1.80290494\n",
      "   0.52860272]\n",
      " [ 0.15125372  2.03500344  0.6196955  ...  0.85103818  1.4863141\n",
      "   0.55442342]\n",
      " [-0.65938194 -1.45846425  0.8181491  ...  0.31692122  1.59344056\n",
      "   1.8491652 ]\n",
      " ...\n",
      " [-0.13032487  0.89702763 -1.28618767 ... -0.35915457 -0.45947458\n",
      "  -0.97578976]\n",
      " [ 0.20545902  0.11544127 -1.05461609 ... -0.92739394 -1.10811641\n",
      "  -0.67509397]\n",
      " [ 0.63911264 -0.41787864 -0.82208231 ... -0.08738689  0.48099451\n",
      "  -0.86070458]]\n",
      "mean accuracy 0.921875\n",
      "[-0.00813543]\n",
      "shape X_lda_sklearn (192, 1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:82: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "shape X_qda_sklearn ()\n",
      "0.9947916666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x396 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABC8AAAJsCAYAAADdrYnFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwAAAECp/R8zLPi85Zz+RwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31715482 -2.57240147  4.45759542  6.70784565 -1.12017059  0.26683895\n",
      "   0.69988222]]\n",
      "     class label\n",
      "0              1\n",
      "1              1\n",
      "2              1\n",
      "3              1\n",
      "4              1\n",
      "5              1\n",
      "6              1\n",
      "7              1\n",
      "8              1\n",
      "9              1\n",
      "10             1\n",
      "11             1\n",
      "12             0\n",
      "13             0\n",
      "14             0\n",
      "15             0\n",
      "16             1\n",
      "17             1\n",
      "18             1\n",
      "19             1\n",
      "20             1\n",
      "21             1\n",
      "22             1\n",
      "23             1\n",
      "24             1\n",
      "25             1\n",
      "26             1\n",
      "27             1\n",
      "28             1\n",
      "29             1\n",
      "..           ...\n",
      "162            0\n",
      "163            0\n",
      "164            0\n",
      "165            0\n",
      "166            0\n",
      "167            0\n",
      "168            0\n",
      "169            0\n",
      "170            0\n",
      "171            0\n",
      "172            0\n",
      "173            0\n",
      "174            0\n",
      "175            0\n",
      "176            0\n",
      "177            0\n",
      "178            0\n",
      "179            0\n",
      "180            0\n",
      "181            0\n",
      "182            0\n",
      "183            0\n",
      "184            0\n",
      "185            0\n",
      "186            0\n",
      "187            0\n",
      "188            0\n",
      "189            0\n",
      "190            0\n",
      "191            0\n",
      "\n",
      "[192 rows x 1 columns]\n",
      "run fg1_m13\n",
      "[ 1. 10.  0.  1.  0.]\n",
      "[ 1. 10.  1.  1.  0.]\n",
      "[ 1. 10.  2.  1.  0.]\n",
      "[ 1. 10.  3.  1.  0.]\n",
      "[ 1. 10.  4.  1.  0.]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ 1. 10.  5.  1.  0.]\n",
      "[ 1. 10.  6.  1.  0.]\n",
      "[0. 5. 0. 1. 0.]\n",
      "[0. 5. 0. 1. 0.]\n",
      "[0. 5. 1. 1. 0.]\n",
      "[0. 5. 1. 1. 0.]\n",
      "[0. 5. 2. 1. 0.]\n",
      "[0. 5. 2. 1. 0.]\n",
      "[0. 5. 3. 1. 0.]\n",
      "[0. 5. 3. 1. 0.]\n",
      "[0. 5. 4. 1. 0.]\n",
      "[0. 5. 4. 1. 0.]\n",
      "[0. 5. 5. 1. 0.]\n",
      "[0. 5. 5. 1. 0.]\n",
      "[0. 5. 6. 1. 0.]\n",
      "[0. 5. 6. 1. 0.]\n",
      "X before norm [[ 0.61020128 -1.84076285  2.72034022 ...  0.03551586  0.8552\n",
      "   0.07418257]\n",
      " [ 0.61313577 -1.86532189  2.79654005 ...  0.12571824  0.8864\n",
      "   0.16252166]\n",
      " [ 0.72319029 -1.57674979  2.82135715 ...  0.23993998  0.5103\n",
      "   0.47637   ]\n",
      " ...\n",
      " [ 0.69359342 -1.83051587  2.72034022 ...  0.0593231   0.8355\n",
      "   0.04984751]\n",
      " [ 0.71240611 -1.788465    2.72034022 ...  0.08271237  0.9579\n",
      "   0.04851613]\n",
      " [ 0.72429504 -1.88212437  3.01029996 ...  0.30658355  1.6703\n",
      "   0.08324348]]\n",
      "X after norm [[-2.03854239  0.12943664 -1.51599442 ... -1.48483818 -1.21993582\n",
      "  -0.9141491 ]\n",
      " [-1.99062564  0.08372735 -1.41401758 ... -0.7766804  -1.16793862\n",
      "  -0.53664549]\n",
      " [-0.19356923  0.6208176  -1.38080532 ...  0.12004773 -1.7947381\n",
      "   0.80453742]\n",
      " ...\n",
      " [-0.67685004  0.14850831 -1.51599442 ... -1.29793311 -1.25276738\n",
      "  -1.01814125]\n",
      " [-0.36966167  0.22677336 -1.51599442 ... -1.11430947 -1.0487784\n",
      "  -1.02383071]\n",
      " [-0.17552991  0.0524546  -1.12794663 ...  0.64325073  0.1384908\n",
      "  -0.8754287 ]]\n",
      "mean accuracy 0.7010309278350515\n",
      "[-1.04187521]\n",
      "shape X_lda_sklearn (194, 1)\n",
      "shape X_qda_sklearn ()\n",
      "0.9432989690721649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x396 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABC8AAAJfCAYAAABfQ/zGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 1296x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.02264439 -2.06155472  2.21632597  2.5695055   0.44245812  0.36149426\n",
      "   1.24281559]]\n",
      "     class label\n",
      "0              0\n",
      "1              1\n",
      "2              1\n",
      "3              1\n",
      "4              1\n",
      "5              1\n",
      "6              1\n",
      "7              1\n",
      "8              1\n",
      "9              1\n",
      "10             1\n",
      "11             1\n",
      "12             1\n",
      "13             1\n",
      "14             1\n",
      "15             1\n",
      "16             1\n",
      "17             1\n",
      "18             1\n",
      "19             1\n",
      "20             1\n",
      "21             1\n",
      "22             0\n",
      "23             1\n",
      "24             1\n",
      "25             1\n",
      "26             1\n",
      "27             1\n",
      "28             1\n",
      "29             1\n",
      "..           ...\n",
      "164            0\n",
      "165            0\n",
      "166            0\n",
      "167            0\n",
      "168            0\n",
      "169            0\n",
      "170            0\n",
      "171            0\n",
      "172            0\n",
      "173            0\n",
      "174            0\n",
      "175            0\n",
      "176            0\n",
      "177            0\n",
      "178            0\n",
      "179            0\n",
      "180            0\n",
      "181            0\n",
      "182            0\n",
      "183            0\n",
      "184            0\n",
      "185            0\n",
      "186            0\n",
      "187            0\n",
      "188            0\n",
      "189            0\n",
      "190            0\n",
      "191            0\n",
      "192            0\n",
      "193            0\n",
      "\n",
      "[194 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A tool for separating things in the classification out by viewing angle or other things like\n",
    "myr snapshot :)\n",
    "'''\n",
    "\n",
    "'''\n",
    "~~~\n",
    "Now just for the imaging part of it!\n",
    "~~~\n",
    "'''\n",
    "import numpy.ma as ma\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_and_CI(mean, lb, ub, color_mean=None, color_shading=None):\n",
    "        # plot the shaded range of the confidence intervals\n",
    "        plt.fill_between(range(mean.shape[0]), ub, lb,\n",
    "                         color=color_shading, alpha=.5)\n",
    "        # plot the mean on top\n",
    "        plt.plot(mean, color_mean)\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12','fg1_m13']#,'fg1_m13']\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    print('run', add_on)\n",
    "\n",
    "\n",
    "    run=list_runs[i]\n",
    "    df = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "            \n",
    "            \n",
    "            #I use this part to check if there is any separation at these points in time\n",
    "            #Or if there are more than two bulges\n",
    "            print(df[['class label','Myr','Viewpoint','# Bulges', 'Sep']].values[j])\n",
    "            \n",
    "            #Then, you can optionally change the class values of all of these viewpoints\n",
    "            \n",
    "            #.set_value(index, col, value, \n",
    "            df.set_value(j,'class label',0.0)\n",
    "    \n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    print('X before norm', X)\n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "    print('X after norm', X)\n",
    "\n",
    "    n_params=7\n",
    "\n",
    "\n",
    "    y = df['class label'].values\n",
    "    \n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    sklearn_lda = LDA(priors=[0.94,0.04])\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    inter = sklearn_lda.intercept_\n",
    "    class_label = sklearn_lda.classes_\n",
    "    \n",
    "    \n",
    "   \n",
    "    print('mean accuracy',dec)#mean accuracy on the given test data and labels.\n",
    "    print('~~~Coefficients and Intercepts~~~')\n",
    "    print(coef,inter)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    '''Make a histogram'''\n",
    "    from scipy import stats\n",
    "    import seaborn as sns\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    X_lda_1=[]\n",
    "    X_lda_2=[]\n",
    "    for j in range(len(X_lda_sklearn)):\n",
    "        if y[j] ==1:\n",
    "            X_lda_1.append(X_lda_sklearn[j][0])\n",
    "        else:\n",
    "            X_lda_2.append(X_lda_sklearn[j][0])\n",
    "    input_hist=X_lda_sklearn\n",
    "    \n",
    "    ax.hist(X_lda_1, label='NonMerger',  color=sns.xkcd_rgb[\"sky blue\"],alpha = 0.75)\n",
    "    ax.hist(X_lda_2, label='Merger',  color=sns.xkcd_rgb[\"salmon\"],alpha = 0.75)\n",
    "\n",
    "    '''for label,col in zip(range(1,4),  ('blue', 'red')):\n",
    "        input_hist=X_lda_sklearn\n",
    "        input_all=X_lda_sklearn\n",
    "        ax.hist(input_hist,\n",
    "                       color=col,\n",
    "                       label='class %s' %label_dict[label],\n",
    "                       alpha=0.5,)#bins=bins,\n",
    "        xt = plt.xticks()[0]  \n",
    "        xmin, xmax = -0.1,0.7#min(xt), max(xt)  \n",
    "        lnspc = np.linspace(xmin, xmax, len(input_hist))\n",
    "\n",
    "        # lets try the normal distribution first\n",
    "        m, s = stats.norm.fit(input_hist) # get mean and standard deviation  \n",
    "        pdf_g = stats.norm.pdf(lnspc, m, s) # now get theoretical values in our interval  \n",
    "        #ax.plot(lnspc, pdf_g,  color=col) # plot it\n",
    "\n",
    "\n",
    "\n",
    "    ylims = ax.get_ylim()\n",
    "\n",
    "    # plot annotation\n",
    "    leg = ax.legend(loc='upper right', fancybox=True, fontsize=8)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    ax.set_ylim([0, max(ylims)+2])'''\n",
    "\n",
    "    ax.set_xlabel('LD1', size=20)\n",
    "    #ax.set_title('Histogram #%s' %str(cnt+1), size=20)\n",
    "\n",
    "    # hide axis ticks\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\", labelsize=20)\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    ax.set_ylabel('Count', size=20)\n",
    "    \n",
    "    \n",
    "    plt.legend(loc=\"upper right\", fontsize=20)\n",
    "    #fig.tight_layout() \n",
    "    #plt.annotate(str(add_on), xy=(0.02,0.95),xycoords='axes fraction', size=20)\n",
    "    #plt.annotate('Mean Accuracy = '+str(dec), xy=(0.02,0.9),xycoords='axes fraction', size=20)\n",
    "    #frame1 = plt.gca()\n",
    "    if run=='fg1_m_13':\n",
    "        plt.title('FG1M13')\n",
    "    if run=='fg3_m12':\n",
    "        plt.title('FG3M12')\n",
    "    plt.show()\n",
    "    print(coef)\n",
    "    #plt.savefig('../MaNGA_Papers/Paper_I/Marginalized_img_'+str(run)+'.pdf')\n",
    "    #plt.clf()\n",
    "    \n",
    "    '''Also, making those mountain plots for the imaging runs'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Now measure LD1 for every row and then plot that'''\n",
    "    import seaborn as sns\n",
    "    \n",
    "\n",
    "    n_params=7\n",
    "\n",
    "\n",
    "\n",
    "    #coef is how you get the eigvecs (doesn't matter what slope offset is)\n",
    "    #print('real eigvecs',(eigvec_sc.real))\n",
    "    #print(len(X_lda[:,0].real[y==2]))#[y == label]\n",
    "    xs=[]\n",
    "    LDA1=[]\n",
    "    if run=='fg3_m_12':\n",
    "        myr=[170,180,185,190,195,205,210,220,225,230,240,250,260]\n",
    "        myr_non=[5,200]\n",
    "    if run=='fg3_m12':\n",
    "        myr=[5,10,20,30,40,60,80,100,120,140,160,170,180,185,190,195,205,210,220,225,230,240,250,260]\n",
    "        myr_non=[5,100,200]\n",
    "        myr_non=[5,10,20,30,100,200]\n",
    "    if run=='fg1_m13':\n",
    "        myr=[10,40,50,60,70,90,100,120,130,140,170,180,185,190,195,200,205,210,215,220,225,230,235,240,250,260,270,280,290,300,310,320,330,340,350]\n",
    "        myr_non=[5,10,100,200]\n",
    "    if run=='fg1_m_13':\n",
    "        myr=[40,195,210,215,220,225,230,235,240,250,260,270,280,290,300,310,320,330,340,350]\n",
    "        myr_non=[5,200]\n",
    "    my_lists = {key:[] for key in myr}\n",
    "    my_lists_none = {key:[] for key in myr_non}\n",
    "    my_lists_non = []\n",
    "    separations = {key:[] for key in myr}\n",
    "\n",
    "    print(df[['class label']])\n",
    "    #STOP\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if df[['class label']].values[i]==0:\n",
    "            my_lists_non.append(X_lda_sklearn[i][0])\n",
    "            my_lists_none[df[['Myr']].values[i][0]].append(X_lda_sklearn[i][0])\n",
    "            continue\n",
    "        my_lists[df[['Myr']].values[i][0]].append(X_lda_sklearn[i][0])\n",
    "        separations[df[['Myr']].values[i][0]].append(df[['Sep']].values[i][0])\n",
    "        L=X_lda_sklearn[i][0]\n",
    "        #df[['Gini']].values[i][0]*coef[0][0]+df[['M20']].values[i][0]*coef[0][1]+df[['Concentration (C)']].values[i][0]*coef[0][2]+df[['Asymmetry (A)']].values[i][0]*coef[0][3]+df[['Clumpiness (S)']].values[i][0]*coef[0][4]+df[['Sersic N']].values[i][0]*coef[0][5]+df[['Shape Asymmetry']].values[i][0]*coef[0][6]\n",
    "        LDA1.append(L)\n",
    "        xs.append(df[['Myr']].values[i][0])\n",
    "\n",
    "    #print(mean(my_lists[180]))\n",
    "    \n",
    "    '''Make the beautiful list of colors'''\n",
    "    # These are the \"Tableau 20\" colors as RGB.    \n",
    "    tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "                 (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "                 (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "                 (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "                 (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    \n",
    "\n",
    "    # Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "    for i in range(len(tableau20)):    \n",
    "        r, g, b = tableau20[i]    \n",
    "        tableau20[i] = (r / 255., g / 255., b / 255.)    \n",
    "    \n",
    "    mean_non=np.mean(my_lists_non)+np.std(my_lists_non)\n",
    "    means=[]\n",
    "    std=[]\n",
    "    separation_value=[]\n",
    "    plt.clf()\n",
    "    \n",
    "    for i in range(len(myr)):\n",
    "        means.append(np.mean(my_lists[myr[i]]))\n",
    "        std.append(np.std(my_lists[myr[i]]))\n",
    "        separation_value.append(np.mean(separations[myr[i]]))\n",
    "    for i in range(len(myr_non)):\n",
    "        myr_plot=np.linspace(myr_non[i]/100,myr_non[i]/100,len(my_lists_none[myr_non[i]]))\n",
    "        #np.full((3, 5), 7) that last value is your fill\n",
    "        plt.scatter(myr_plot,my_lists_none[myr_non[i]], color=tableau20[i])\n",
    "    \n",
    "    \n",
    "    means=np.array(means)\n",
    "    std=np.array(std)\n",
    "    myr=np.array(myr)\n",
    "    \n",
    "    if run=='fg1_m13':\n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#-1.7583e-01\n",
    "        rescale_y_pm=7.13475416061/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "        #new_means=ma.masked_where(math.isnan(new_means),new_means)\n",
    "        #print('these are apparently the myrs', myr/100)\n",
    "        #print('these are the fills', new_means)\n",
    "        \n",
    "        plt.plot(myr/100, new_means, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.fill_between(myr/100, (new_means-std), (new_means+std),alpha=.5, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.xlabel(r'Merger Timeline [Gyr]', size=15)\n",
    "        plt.ylabel(r'Detection Sensitivity (LD1)', size=15)\n",
    "        #plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=215/100, color='black', ls='--')\n",
    "        plt.axvline(x=280/100, color='black', ls='--')\n",
    "\n",
    "        '''width and height 3.17421463155 0.87713041243\n",
    "        pos [ -1.6779e+00   2.6963e-16]\n",
    "        width and height 5.56843021209 2.94988106646\n",
    "        pos [  2.7636e-01   1.2800e-16]'''\n",
    "\n",
    "\n",
    "        '''fg1_m_13:\n",
    "        width and height 1.98151143695 1.33924739273\n",
    "        pos [  1.4067e+00   6.6911e-16]\n",
    "        width and height 7.13475416061 2.66110273731\n",
    "        pos [ -1.7583e-01  -1.3878e-16]'''\n",
    "\n",
    "        plt.axhline(y=mean_non, color='black')\n",
    "        #plt.annotate(r'$\\mu_{\\mathrm{Merger}}$', xy=(0.02,0.53), xycoords='axes fraction', size=15)\n",
    "        #plt.title(str(run))\n",
    "        plt.annotate('FG1M13', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(0.25,0.95), xycoords='axes fraction', size=9)\n",
    "        plt.annotate('Late', xy=(0.63,0.95), xycoords='axes fraction',size=9)\n",
    "        plt.annotate('Post Coalescence', xy=(0.76,1.02), xycoords='axes fraction', size=9)\n",
    "\n",
    "    if run=='fg1_m_13':\n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#-1.7583e-01\n",
    "        rescale_y_pm=7.13475416061/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        \n",
    "\n",
    "        plt.plot(myr/100, new_means, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.fill_between(myr/100, (new_means-std), (new_means+std),alpha=.5, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.xlabel(r'Merger Timeline [Gyr]', size=15)\n",
    "        plt.ylabel(r'Detection Sensitivity (LD1)', size=15)\n",
    "        #plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=215/100, color='black', ls='--')\n",
    "        plt.axvline(x=280/100, color='black', ls='--')\n",
    "\n",
    "        '''width and height 3.17421463155 0.87713041243\n",
    "        pos [ -1.6779e+00   2.6963e-16]\n",
    "        width and height 5.56843021209 2.94988106646\n",
    "        pos [  2.7636e-01   1.2800e-16]'''\n",
    "\n",
    "\n",
    "        '''fg1_m_13:\n",
    "        width and height 1.98151143695 1.33924739273\n",
    "        pos [  1.4067e+00   6.6911e-16]\n",
    "        width and height 7.13475416061 2.66110273731\n",
    "        pos [ -1.7583e-01  -1.3878e-16]'''\n",
    "\n",
    "        ys_LD1=np.array([-1.7583e-01 for x in myr])\n",
    "        #plt.plot(myr/100,ys_LD1)\n",
    "        #plt.fill_between(myr/100, ys_LD1-0.588/2, ys_LD1+0.588/2,alpha=.5)\n",
    "        plt.axhline(y=mean_non, color='black')\n",
    "        #plt.annotate(r'$\\mu_{\\mathrm{Merger}}$', xy=(0.02,0.53), xycoords='axes fraction', size=15)\n",
    "        #plt.title(str(run))\n",
    "        plt.annotate('FG1M13', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(0.25,0.95), xycoords='axes fraction', size=9)\n",
    "        plt.annotate('Late', xy=(0.63,0.95), xycoords='axes fraction',size=9)\n",
    "        plt.annotate('Post Coalescence', xy=(0.76,1.02), xycoords='axes fraction', size=9)\n",
    "    if run=='fg3_m_12':\n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        rescale_y_pm=5.5684302120/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        \n",
    "\n",
    "        plt.plot(myr/100, new_means, color='red')\n",
    "        plt.fill_between(myr/100, (new_means-std), (new_means+std),alpha=.5, color='red')\n",
    "        plt.xlabel(r'Merger Timeline [Gyr]', size=15)\n",
    "        plt.ylabel(r'Detection Sensitivity (LD1)', size=15)\n",
    "        plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "\n",
    "        '''width and height 3.17421463155 0.87713041243\n",
    "        pos [ -1.6779e+00   2.6963e-16]\n",
    "        width and height 5.56843021209 2.94988106646\n",
    "        pos [  2.7636e-01   1.2800e-16]'''\n",
    "\n",
    "\n",
    "        #plt.axhline(y=0, color='black')\n",
    "\n",
    "        #plt.annotate(r'$\\mu_{\\mathrm{Merger}}$', xy=(0.15,0.53), xycoords='axes fraction', size=15)\n",
    "        #plt.title(str(run))\n",
    "        plt.axhline(y=mean_non, color='black')\n",
    "        plt.annotate('FG3M12', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(0.03,0.95), xycoords='axes fraction', size=9)\n",
    "        plt.annotate('Late', xy=(0.3,0.95), xycoords='axes fraction',size=9)\n",
    "        plt.annotate('Post Coalescence', xy=(0.65,0.95), xycoords='axes fraction', size=9)\n",
    "    if run=='fg3_m12':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        rescale_y_pm=5.5684302120/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        \n",
    "\n",
    "        plt.plot(myr/100, new_means, color='red')\n",
    "        plt.fill_between(myr/100, (new_means-std), (new_means+std),alpha=.5, color='red')\n",
    "        plt.xlabel(r'Merger Timeline [Gyr]', size=15)\n",
    "        plt.ylabel(r'Detection Sensitivity (LD1)', size=15)\n",
    "        plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "\n",
    "        '''width and height 3.17421463155 0.87713041243\n",
    "        pos [ -1.6779e+00   2.6963e-16]\n",
    "        width and height 5.56843021209 2.94988106646\n",
    "        pos [  2.7636e-01   1.2800e-16]'''\n",
    "\n",
    "\n",
    "        #plt.axhline(y=0, color='black')\n",
    "\n",
    "        #plt.annotate(r'$\\mu_{\\mathrm{Merger}}$', xy=(0.15,0.53), xycoords='axes fraction', size=15)\n",
    "        #plt.title(str(run))\n",
    "        plt.axhline(y=mean_non, color='black')\n",
    "        plt.annotate('FG3M12', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(0.63,0.97), xycoords='axes fraction', size=9)\n",
    "        plt.annotate('Late', xy=(0.7,0.97), xycoords='axes fraction',size=9)\n",
    "        plt.annotate('Post Coalescence', xy=(0.85,1.01), xycoords='axes fraction', size=9)\n",
    "    #plt.ylim([-1,1])\n",
    "    #plt.xlim([min(myr)/100,max(myr)/100])\n",
    "    #plt.xlim([0,])\n",
    "    frame1 = plt.gca()\n",
    "    #frame1.axes.xaxis.set_ticklabels([])\n",
    "    frame1.axes.yaxis.set_ticklabels([])\n",
    "    #frame1.axes.yaxis.set_ticks([])\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/Mountain_plot_imaging_priors_colors_'+str(run)+'.pdf')\n",
    "\n",
    "\n",
    "\n",
    "    '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "    \n",
    "    \n",
    "#    savefig('../MaNGA_Papers/Paper_I/Bayesian_Hist_'+str(run)+'.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run fg3_m15\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'LDA_img_ratio_fg3_m15_early_late_all_things.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-551fe2f0aa18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'LDA_img_ratio_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_early_late_all_things.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m#'_view_all.txt',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         )#,skiprows=10,nrows=10\n\u001b[1;32m     71\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Shape Asymmetry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'LDA_img_ratio_fg3_m15_early_late_all_things.txt' does not exist"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now trying to do the same thing for different viewing angles\n",
    "'''\n",
    "'''\n",
    "A tool for separating things in the classification out by viewing angle or other things like\n",
    "myr snapshot :)\n",
    "'''\n",
    "\n",
    "'''\n",
    "~~~\n",
    "Now just for the imaging part of it!\n",
    "~~~\n",
    "'''\n",
    "import numpy.ma as ma\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_and_CI(mean, lb, ub, color_mean=None, color_shading=None):\n",
    "        # plot the shaded range of the confidence intervals\n",
    "        plt.fill_between(range(mean.shape[0]), ub, lb,\n",
    "                         color=color_shading, alpha=.5)\n",
    "        # plot the mean on top\n",
    "        plt.plot(mean, color_mean)\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m15','fg3_m12','fg1_m13']#,'fg1_m13']\n",
    "\n",
    "for i in range(len(list_runs)):\n",
    "   \n",
    "    add_on=list_runs[i]\n",
    "    print('run', add_on)\n",
    "\n",
    "\n",
    "    run=list_runs[i]\n",
    "    df = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "            \n",
    "            \n",
    "            #I use this part to check if there is any separation at these points in time\n",
    "            #Or if there are more than two bulges\n",
    "            #print(df[['class label','Myr','Viewpoint','# Bulges', 'Sep']].values[j])\n",
    "            \n",
    "            #Then, you can optionally change the class values of all of these viewpoints\n",
    "            \n",
    "            #.set_value(index, col, value, \n",
    "            df.set_value(j,'class label',0.0)\n",
    "    \n",
    "    \n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    n_params=7\n",
    "\n",
    "\n",
    "    y = df['class label'].values\n",
    "    \n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    sklearn_lda = LDA(priors=[0.94,0.04])\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    inter = sklearn_lda.intercept_\n",
    "    class_label = sklearn_lda.classes_\n",
    "    \n",
    "    \n",
    "   \n",
    "    print('mean accuracy',dec)#mean accuracy on the given test data and labels.\n",
    "    \n",
    "    print(inter)\n",
    "    \n",
    "    from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "    \n",
    "    # QDA\n",
    "    sklearn_qda = QDA(priors=[0.94,0.04])\n",
    "    X_qda_sklearn = sklearn_qda.fit(X, y)\n",
    "    dec_qda = sklearn_qda.score(X,y)\n",
    "    \n",
    "    #coef = sklearn_qda.coef_\n",
    "    #inter = sklearn_qda.intercept_\n",
    "    #print(dec_qda)#mean accuracy on the given test data and labels.\n",
    "\n",
    "    '''Make a histogram'''\n",
    "    from scipy import stats\n",
    "    import seaborn as sns\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(18,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    X_lda_1=[]\n",
    "    X_lda_2=[]\n",
    "    for j in range(len(X_lda_sklearn)):\n",
    "        if y[j] ==1:\n",
    "            X_lda_1.append(X_lda_sklearn[j][0])\n",
    "        else:\n",
    "            X_lda_2.append(X_lda_sklearn[j][0])\n",
    "    input_hist=X_lda_sklearn\n",
    "    \n",
    "    ax.hist(X_lda_1, label='NonMerger',  color=sns.xkcd_rgb[\"sky blue\"],alpha = 0.75)\n",
    "    ax.hist(X_lda_2, label='Merger',  color=sns.xkcd_rgb[\"salmon\"],alpha = 0.75)\n",
    "\n",
    "    '''for label,col in zip(range(1,4),  ('blue', 'red')):\n",
    "        input_hist=X_lda_sklearn\n",
    "        input_all=X_lda_sklearn\n",
    "        ax.hist(input_hist,\n",
    "                       color=col,\n",
    "                       label='class %s' %label_dict[label],\n",
    "                       alpha=0.5,)#bins=bins,\n",
    "        xt = plt.xticks()[0]  \n",
    "        xmin, xmax = -0.1,0.7#min(xt), max(xt)  \n",
    "        lnspc = np.linspace(xmin, xmax, len(input_hist))\n",
    "\n",
    "        # lets try the normal distribution first\n",
    "        m, s = stats.norm.fit(input_hist) # get mean and standard deviation  \n",
    "        pdf_g = stats.norm.pdf(lnspc, m, s) # now get theoretical values in our interval  \n",
    "        #ax.plot(lnspc, pdf_g,  color=col) # plot it\n",
    "\n",
    "\n",
    "\n",
    "    ylims = ax.get_ylim()\n",
    "\n",
    "    # plot annotation\n",
    "    leg = ax.legend(loc='upper right', fancybox=True, fontsize=8)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    ax.set_ylim([0, max(ylims)+2])'''\n",
    "\n",
    "    ax.set_xlabel('LD1', size=20)\n",
    "    #ax.set_title('Histogram #%s' %str(cnt+1), size=20)\n",
    "\n",
    "    # hide axis ticks\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\", labelsize=20)\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    ax.set_ylabel('Count', size=20)\n",
    "    \n",
    "    \n",
    "    plt.legend(loc=\"upper right\", fontsize=20)\n",
    "    #fig.tight_layout() \n",
    "    #plt.annotate(str(add_on), xy=(0.02,0.95),xycoords='axes fraction', size=20)\n",
    "    #plt.annotate('Mean Accuracy = '+str(dec), xy=(0.02,0.9),xycoords='axes fraction', size=20)\n",
    "    #frame1 = plt.gca()\n",
    "    if run=='fg1_m_13':\n",
    "        plt.title('FG1M13')\n",
    "    if run=='fg3_m12':\n",
    "        plt.title('FG3M12')\n",
    "    if run=='fg3_m15':\n",
    "        plt.tilte('FG3M15')\n",
    "    plt.show()\n",
    "    print(coef)\n",
    "    #plt.savefig('../MaNGA_Papers/Paper_I/Marginalized_img_'+str(run)+'.pdf')\n",
    "    #plt.clf()\n",
    "    \n",
    "    '''Also, making those mountain plots for the imaging runs'''\n",
    "    \n",
    "    \n",
    "    \n",
    "    '''Now measure LD1 for every row and then plot that'''\n",
    "    import seaborn as sns\n",
    "    \n",
    "\n",
    "    n_params=7\n",
    "\n",
    "\n",
    "\n",
    "    #coef is how you get the eigvecs (doesn't matter what slope offset is)\n",
    "    #print('real eigvecs',(eigvec_sc.real))\n",
    "    #print(len(X_lda[:,0].real[y==2]))#[y == label]\n",
    "    xs=[]\n",
    "    LDA1=[]\n",
    "    if run=='fg3_m15':\n",
    "        myr=[320,340,360,400,420]\n",
    "    if run=='fg3_m_12':\n",
    "        myr=[170,180,185,190,195,205,210,220,225,230,240,250,260]\n",
    "        myr_non=[5,200]\n",
    "    if run=='fg3_m12':\n",
    "        myr=[5,10,20,30,40,60,80,100,120,140,160,170,180,185,190,195,205,210,220,225,230,240,250,260]\n",
    "        myr_non=[5,100,200]\n",
    "        myr_non=[5,10,20,30,100,200]\n",
    "    if run=='fg1_m13':\n",
    "        myr=[10,40,50,60,70,90,100,120,130,140,170,180,185,190,195,200,205,210,215,220,225,230,235,240,250,260,270,280,290,300,310,320,330,340,350]\n",
    "        myr_non=[5,10,100,200]\n",
    "    if run=='fg1_m_13':\n",
    "        myr=[40,195,210,215,220,225,230,235,240,250,260,270,280,290,300,310,320,330,340,350]\n",
    "        myr_non=[5,200]\n",
    "        \n",
    "    myr_non=[0,1,2,3,4,5,6]\n",
    "    my_lists = {key:[] for key in myr}\n",
    "    my_lists_none = {key:[] for key in myr_non}\n",
    "    myr_lists_none = {key:[] for key in myr_non}\n",
    "    \n",
    "    \n",
    "    my_lists_non = []\n",
    "    separations = {key:[] for key in myr}\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if df[['class label']].values[i]==0:\n",
    "            my_lists_non.append(X_lda_sklearn[i][0])\n",
    "            my_lists_none[df[['Viewpoint']].values[i][0]].append(X_lda_sklearn[i][0])\n",
    "            myr_lists_none[df[['Viewpoint']].values[i][0]].append(df[['Myr']].values[i][0]/100)\n",
    "            continue\n",
    "        my_lists[df[['Myr']].values[i][0]].append(X_lda_sklearn[i][0])\n",
    "        separations[df[['Myr']].values[i][0]].append(df[['Sep']].values[i][0])\n",
    "        L=X_lda_sklearn[i][0]\n",
    "        #df[['Gini']].values[i][0]*coef[0][0]+df[['M20']].values[i][0]*coef[0][1]+df[['Concentration (C)']].values[i][0]*coef[0][2]+df[['Asymmetry (A)']].values[i][0]*coef[0][3]+df[['Clumpiness (S)']].values[i][0]*coef[0][4]+df[['Sersic N']].values[i][0]*coef[0][5]+df[['Shape Asymmetry']].values[i][0]*coef[0][6]\n",
    "        LDA1.append(L)\n",
    "        xs.append(df[['Myr']].values[i][0])\n",
    "    \n",
    "    \n",
    "    '''Make the beautiful list of colors'''\n",
    "    # These are the \"Tableau 20\" colors as RGB.    \n",
    "    tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "                 (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "                 (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "                 (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "                 (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    \n",
    "\n",
    "    # Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "    for i in range(len(tableau20)):    \n",
    "        r, g, b = tableau20[i]    \n",
    "        tableau20[i] = (r / 255., g / 255., b / 255.)    \n",
    "    \n",
    "    mean_non=np.mean(my_lists_non)+np.std(my_lists_non)\n",
    "    means=[]\n",
    "    std=[]\n",
    "    separation_value=[]\n",
    "    plt.clf()\n",
    "    \n",
    "    for i in range(len(myr)):\n",
    "        means.append(np.mean(my_lists[myr[i]]))\n",
    "        std.append(np.std(my_lists[myr[i]]))\n",
    "        separation_value.append(np.mean(separations[myr[i]]))\n",
    "    for i in range(len(myr_non)):\n",
    "        print('viewpoint', i, 'color', tableau20[i])\n",
    "        print('xs',myr_lists_none[i])\n",
    "        print('ys',my_lists_none[i])\n",
    "        plt.scatter(myr_lists_none[i],my_lists_none[i], color=tableau20[i], label='Viewpoint '+str(i))\n",
    "    \n",
    "    \n",
    "    means=np.array(means)\n",
    "    std=np.array(std)\n",
    "    myr=np.array(myr)\n",
    "    \n",
    "    if run=='fg1_m13':\n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#-1.7583e-01\n",
    "        rescale_y_pm=7.13475416061/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "        #new_means=ma.masked_where(math.isnan(new_means),new_means)\n",
    "        #print('these are apparently the myrs', myr/100)\n",
    "        #print('these are the fills', new_means)\n",
    "        \n",
    "        plt.plot(myr/100, new_means, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.fill_between(myr/100, (new_means-std), (new_means+std),alpha=.5, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.xlabel(r'Merger Timeline [Gyr]', size=15)\n",
    "        plt.ylabel(r'Detection Sensitivity (LD1)', size=15)\n",
    "        #plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=215/100, color='black', ls='--')\n",
    "        plt.axvline(x=280/100, color='black', ls='--')\n",
    "\n",
    "        '''width and height 3.17421463155 0.87713041243\n",
    "        pos [ -1.6779e+00   2.6963e-16]\n",
    "        width and height 5.56843021209 2.94988106646\n",
    "        pos [  2.7636e-01   1.2800e-16]'''\n",
    "\n",
    "\n",
    "        '''fg1_m_13:\n",
    "        width and height 1.98151143695 1.33924739273\n",
    "        pos [  1.4067e+00   6.6911e-16]\n",
    "        width and height 7.13475416061 2.66110273731\n",
    "        pos [ -1.7583e-01  -1.3878e-16]'''\n",
    "\n",
    "        plt.axhline(y=mean_non, color='black')\n",
    "        #plt.annotate(r'$\\mu_{\\mathrm{Merger}}$', xy=(0.02,0.53), xycoords='axes fraction', size=15)\n",
    "        #plt.title(str(run))\n",
    "        plt.annotate('FG1M13', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(0.25,0.95), xycoords='axes fraction', size=9)\n",
    "        plt.annotate('Late', xy=(0.63,0.95), xycoords='axes fraction',size=9)\n",
    "        plt.annotate('Post Coalescence', xy=(0.76,1.02), xycoords='axes fraction', size=9)\n",
    "\n",
    "    if run=='fg1_m_13':\n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#-1.7583e-01\n",
    "        rescale_y_pm=7.13475416061/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        \n",
    "\n",
    "        plt.plot(myr/100, new_means, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.fill_between(myr/100, (new_means-std), (new_means+std),alpha=.5, color=sns.xkcd_rgb[\"amber\"])\n",
    "        plt.xlabel(r'Merger Timeline [Gyr]', size=15)\n",
    "        plt.ylabel(r'Detection Sensitivity (LD1)', size=15)\n",
    "        #plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=215/100, color='black', ls='--')\n",
    "        plt.axvline(x=280/100, color='black', ls='--')\n",
    "\n",
    "        '''width and height 3.17421463155 0.87713041243\n",
    "        pos [ -1.6779e+00   2.6963e-16]\n",
    "        width and height 5.56843021209 2.94988106646\n",
    "        pos [  2.7636e-01   1.2800e-16]'''\n",
    "\n",
    "\n",
    "        '''fg1_m_13:\n",
    "        width and height 1.98151143695 1.33924739273\n",
    "        pos [  1.4067e+00   6.6911e-16]\n",
    "        width and height 7.13475416061 2.66110273731\n",
    "        pos [ -1.7583e-01  -1.3878e-16]'''\n",
    "\n",
    "        ys_LD1=np.array([-1.7583e-01 for x in myr])\n",
    "        #plt.plot(myr/100,ys_LD1)\n",
    "        #plt.fill_between(myr/100, ys_LD1-0.588/2, ys_LD1+0.588/2,alpha=.5)\n",
    "        plt.axhline(y=mean_non, color='black')\n",
    "        #plt.annotate(r'$\\mu_{\\mathrm{Merger}}$', xy=(0.02,0.53), xycoords='axes fraction', size=15)\n",
    "        #plt.title(str(run))\n",
    "        plt.annotate('FG1M13', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(0.25,0.95), xycoords='axes fraction', size=9)\n",
    "        plt.annotate('Late', xy=(0.63,0.95), xycoords='axes fraction',size=9)\n",
    "        plt.annotate('Post Coalescence', xy=(0.76,1.02), xycoords='axes fraction', size=9)\n",
    "    if run=='fg3_m_12':\n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        rescale_y_pm=5.5684302120/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        \n",
    "\n",
    "        plt.plot(myr/100, new_means, color='red')\n",
    "        plt.fill_between(myr/100, (new_means-std), (new_means+std),alpha=.5, color='red')\n",
    "        plt.xlabel(r'Merger Timeline [Gyr]', size=15)\n",
    "        plt.ylabel(r'Detection Sensitivity (LD1)', size=15)\n",
    "        plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "\n",
    "        '''width and height 3.17421463155 0.87713041243\n",
    "        pos [ -1.6779e+00   2.6963e-16]\n",
    "        width and height 5.56843021209 2.94988106646\n",
    "        pos [  2.7636e-01   1.2800e-16]'''\n",
    "\n",
    "\n",
    "        #plt.axhline(y=0, color='black')\n",
    "\n",
    "        #plt.annotate(r'$\\mu_{\\mathrm{Merger}}$', xy=(0.15,0.53), xycoords='axes fraction', size=15)\n",
    "        #plt.title(str(run))\n",
    "        plt.axhline(y=mean_non, color='black')\n",
    "        plt.annotate('FG3M12', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(0.03,0.95), xycoords='axes fraction', size=9)\n",
    "        plt.annotate('Late', xy=(0.3,0.95), xycoords='axes fraction',size=9)\n",
    "        plt.annotate('Post Coalescence', xy=(0.65,0.95), xycoords='axes fraction', size=9)\n",
    "    if run=='fg3_m12':\n",
    "    \n",
    "        '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "        rescale_y_mean=0#2.7636e-01\n",
    "        rescale_y_pm=5.5684302120/2\n",
    "\n",
    "\n",
    "        new_means=np.array([(x-rescale_y_mean) for x in means])\n",
    "\n",
    "        \n",
    "\n",
    "        plt.plot(myr/100, new_means, color='red')\n",
    "        plt.fill_between(myr/100, (new_means-std), (new_means+std),alpha=.5, color='red')\n",
    "        plt.xlabel(r'Merger Timeline [Gyr]', size=15)\n",
    "        plt.ylabel(r'Detection Sensitivity (LD1)', size=15)\n",
    "        plt.axvline(x=220/100, color='black', ls='--')\n",
    "        plt.axvline(x=180/100, color='black', ls='--')\n",
    "\n",
    "\n",
    "\n",
    "        '''width and height 3.17421463155 0.87713041243\n",
    "        pos [ -1.6779e+00   2.6963e-16]\n",
    "        width and height 5.56843021209 2.94988106646\n",
    "        pos [  2.7636e-01   1.2800e-16]'''\n",
    "\n",
    "\n",
    "        #plt.axhline(y=0, color='black')\n",
    "\n",
    "        #plt.annotate(r'$\\mu_{\\mathrm{Merger}}$', xy=(0.15,0.53), xycoords='axes fraction', size=15)\n",
    "        #plt.title(str(run))\n",
    "        plt.axhline(y=mean_non, color='black')\n",
    "        plt.annotate('FG3M12', xy=(0.02,1.02), xycoords='axes fraction', size=20)\n",
    "        plt.annotate('Early', xy=(0.63,0.97), xycoords='axes fraction', size=9)\n",
    "        plt.annotate('Late', xy=(0.7,0.97), xycoords='axes fraction',size=9)\n",
    "        plt.annotate('Post Coalescence', xy=(0.85,1.01), xycoords='axes fraction', size=9)\n",
    "    #plt.ylim([-1,1])\n",
    "    #plt.xlim([min(myr)/100,max(myr)/100])\n",
    "    #plt.xlim([0,])\n",
    "    frame1 = plt.gca()\n",
    "    #frame1.axes.xaxis.set_ticklabels([])\n",
    "    frame1.axes.yaxis.set_ticklabels([])\n",
    "    #frame1.axes.yaxis.set_ticks([])\n",
    "    plt.legend()\n",
    "    plt.savefig('../MaNGA_Papers/Paper_I/Mountain_plot_imaging_priors_view_colors_'+str(run)+'.pdf')\n",
    "\n",
    "\n",
    "\n",
    "    '''Try to replot with a dimensionless y axis with just means and std'''\n",
    "    \n",
    "    \n",
    "#    savefig('../MaNGA_Papers/Paper_I/Bayesian_Hist_'+str(run)+'.pdf')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior_1 [0.   0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1  0.11 0.12 0.13\n",
      " 0.14 0.15 0.16 0.17 0.18 0.19 0.2  0.21 0.22 0.23 0.24 0.25 0.26 0.27\n",
      " 0.28 0.29 0.3  0.31 0.32 0.33 0.34 0.35 0.36 0.37 0.38 0.39 0.4  0.41\n",
      " 0.42 0.43 0.44 0.45 0.46 0.47 0.48 0.49 0.5  0.51 0.52 0.53 0.54 0.55\n",
      " 0.56 0.57 0.58 0.59 0.6  0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69\n",
      " 0.7  0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.8  0.81 0.82 0.83\n",
      " 0.84 0.85 0.86 0.87 0.88 0.89 0.9  0.91 0.92 0.93 0.94 0.95 0.96 0.97\n",
      " 0.98 0.99 1.  ]\n",
      "run fg3_m12\n",
      "0.0 1.0\n",
      "[[ 0.   0. ]\n",
      " [ 6.1 13.1]]\n",
      "run fg3_m12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:51: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:401: RuntimeWarning: invalid value encountered in true_divide\n",
      "  S**2))[:self._max_components]\n",
      "/Users/beckynevin/anaconda/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:406: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.priors_))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.99\n",
      "[[ 5.   0.1]\n",
      " [ 1.1 13. ]]\n",
      "run fg3_m12\n",
      "0.02 0.98\n",
      "[[ 5.4  0.2]\n",
      " [ 0.7 12.9]]\n",
      "run fg3_m12\n",
      "0.03 0.97\n",
      "[[ 5.6  0.2]\n",
      " [ 0.5 12.9]]\n",
      "run fg3_m12\n",
      "0.04 0.96\n",
      "[[ 5.7  0.3]\n",
      " [ 0.4 12.8]]\n",
      "run fg3_m12\n",
      "0.05 0.95\n",
      "[[ 5.7  0.3]\n",
      " [ 0.4 12.8]]\n",
      "run fg3_m12\n",
      "0.06 0.94\n",
      "[[ 5.7  0.3]\n",
      " [ 0.4 12.8]]\n",
      "run fg3_m12\n",
      "0.07 0.9299999999999999\n",
      "[[ 5.7  0.3]\n",
      " [ 0.4 12.8]]\n",
      "run fg3_m12\n",
      "0.08 0.92\n",
      "[[ 5.8  0.3]\n",
      " [ 0.3 12.8]]\n",
      "run fg3_m12\n",
      "0.09 0.91\n",
      "[[ 5.8  0.4]\n",
      " [ 0.3 12.7]]\n",
      "run fg3_m12\n",
      "0.1 0.9\n",
      "[[ 5.8  0.4]\n",
      " [ 0.3 12.7]]\n",
      "run fg3_m12\n",
      "0.11 0.89\n",
      "[[ 5.9  0.4]\n",
      " [ 0.2 12.7]]\n",
      "run fg3_m12\n",
      "0.12 0.88\n",
      "[[ 5.9  0.4]\n",
      " [ 0.2 12.7]]\n",
      "run fg3_m12\n",
      "0.13 0.87\n",
      "[[ 5.9  0.4]\n",
      " [ 0.2 12.7]]\n",
      "run fg3_m12\n",
      "0.14 0.86\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.15 0.85\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.16 0.84\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.17 0.83\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.18 0.8200000000000001\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.19 0.81\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.2 0.8\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.21 0.79\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.22 0.78\n",
      "[[ 5.9  0.5]\n",
      " [ 0.2 12.6]]\n",
      "run fg3_m12\n",
      "0.23 0.77\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.24 0.76\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.25 0.75\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.26 0.74\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.27 0.73\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.28 0.72\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.29 0.71\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.3 0.7\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.31 0.69\n",
      "[[ 5.9  0.6]\n",
      " [ 0.2 12.5]]\n",
      "run fg3_m12\n",
      "0.32 0.6799999999999999\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.33 0.6699999999999999\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.34 0.6599999999999999\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.35000000000000003 0.6499999999999999\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.36 0.64\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.37 0.63\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.38 0.62\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.39 0.61\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.4 0.6\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.41000000000000003 0.59\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.42 0.5800000000000001\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.43 0.5700000000000001\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.44 0.56\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.45 0.55\n",
      "[[ 5.9  0.7]\n",
      " [ 0.2 12.4]]\n",
      "run fg3_m12\n",
      "0.46 0.54\n",
      "[[ 5.9  0.8]\n",
      " [ 0.2 12.3]]\n",
      "run fg3_m12\n",
      "0.47000000000000003 0.53\n",
      "[[ 5.9  0.8]\n",
      " [ 0.2 12.3]]\n",
      "run fg3_m12\n",
      "0.48 0.52\n",
      "[[ 5.9  0.8]\n",
      " [ 0.2 12.3]]\n",
      "run fg3_m12\n",
      "0.49 0.51\n",
      "[[ 5.9  0.8]\n",
      " [ 0.2 12.3]]\n",
      "run fg3_m12\n",
      "0.5 0.5\n",
      "[[ 5.9  0.8]\n",
      " [ 0.2 12.3]]\n",
      "run fg3_m12\n",
      "0.51 0.49\n",
      "[[ 5.9  0.8]\n",
      " [ 0.2 12.3]]\n",
      "run fg3_m12\n",
      "0.52 0.48\n",
      "[[ 5.9  0.8]\n",
      " [ 0.2 12.3]]\n",
      "run fg3_m12\n",
      "0.53 0.47\n",
      "[[ 5.9  0.8]\n",
      " [ 0.2 12.3]]\n",
      "run fg3_m12\n",
      "0.54 0.45999999999999996\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.55 0.44999999999999996\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.56 0.43999999999999995\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.5700000000000001 0.42999999999999994\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.58 0.42000000000000004\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.59 0.41000000000000003\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.6 0.4\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.61 0.39\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.62 0.38\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.63 0.37\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.64 0.36\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.65 0.35\n",
      "[[ 5.9  0.9]\n",
      " [ 0.2 12.2]]\n",
      "run fg3_m12\n",
      "0.66 0.33999999999999997\n",
      "[[ 6.   1. ]\n",
      " [ 0.1 12.1]]\n",
      "run fg3_m12\n",
      "0.67 0.32999999999999996\n",
      "[[ 6.   1. ]\n",
      " [ 0.1 12.1]]\n",
      "run fg3_m12\n",
      "0.68 0.31999999999999995\n",
      "[[ 6.   1. ]\n",
      " [ 0.1 12.1]]\n",
      "run fg3_m12\n",
      "0.6900000000000001 0.30999999999999994\n",
      "[[ 6.   1. ]\n",
      " [ 0.1 12.1]]\n",
      "run fg3_m12\n",
      "0.7000000000000001 0.29999999999999993\n",
      "[[ 6.   1. ]\n",
      " [ 0.1 12.1]]\n",
      "run fg3_m12\n",
      "0.71 0.29000000000000004\n",
      "[[ 6.   1. ]\n",
      " [ 0.1 12.1]]\n",
      "run fg3_m12\n",
      "0.72 0.28\n",
      "[[ 6.   1. ]\n",
      " [ 0.1 12.1]]\n",
      "run fg3_m12\n",
      "0.73 0.27\n",
      "[[ 6.   1. ]\n",
      " [ 0.1 12.1]]\n",
      "run fg3_m12\n",
      "0.74 0.26\n",
      "[[ 6.   1.1]\n",
      " [ 0.1 12. ]]\n",
      "run fg3_m12\n",
      "0.75 0.25\n",
      "[[ 6.   1.1]\n",
      " [ 0.1 12. ]]\n",
      "run fg3_m12\n",
      "0.76 0.24\n",
      "[[ 6.   1.1]\n",
      " [ 0.1 12. ]]\n",
      "run fg3_m12\n",
      "0.77 0.22999999999999998\n",
      "[[ 6.   1.1]\n",
      " [ 0.1 12. ]]\n",
      "run fg3_m12\n",
      "0.78 0.21999999999999997\n",
      "[[ 6.   1.1]\n",
      " [ 0.1 12. ]]\n",
      "run fg3_m12\n",
      "0.79 0.20999999999999996\n",
      "[[ 6.   1.2]\n",
      " [ 0.1 11.9]]\n",
      "run fg3_m12\n",
      "0.8 0.19999999999999996\n",
      "[[ 6.   1.2]\n",
      " [ 0.1 11.9]]\n",
      "run fg3_m12\n",
      "0.81 0.18999999999999995\n",
      "[[ 6.   1.2]\n",
      " [ 0.1 11.9]]\n",
      "run fg3_m12\n",
      "0.8200000000000001 0.17999999999999994\n",
      "[[ 6.   1.2]\n",
      " [ 0.1 11.9]]\n",
      "run fg3_m12\n",
      "0.8300000000000001 0.16999999999999993\n",
      "[[ 6.   1.2]\n",
      " [ 0.1 11.9]]\n",
      "run fg3_m12\n",
      "0.84 0.16000000000000003\n",
      "[[ 6.   1.2]\n",
      " [ 0.1 11.9]]\n",
      "run fg3_m12\n",
      "0.85 0.15000000000000002\n",
      "[[ 6.   1.3]\n",
      " [ 0.1 11.8]]\n",
      "run fg3_m12\n",
      "0.86 0.14\n",
      "[[ 6.   1.4]\n",
      " [ 0.1 11.7]]\n",
      "run fg3_m12\n",
      "0.87 0.13\n",
      "[[ 6.   1.4]\n",
      " [ 0.1 11.7]]\n",
      "run fg3_m12\n",
      "0.88 0.12\n",
      "[[ 6.   1.5]\n",
      " [ 0.1 11.6]]\n",
      "run fg3_m12\n",
      "0.89 0.10999999999999999\n",
      "[[ 6.   1.5]\n",
      " [ 0.1 11.6]]\n",
      "run fg3_m12\n",
      "0.9 0.09999999999999998\n",
      "[[ 6.   1.6]\n",
      " [ 0.1 11.5]]\n",
      "run fg3_m12\n",
      "0.91 0.08999999999999997\n",
      "[[ 6.   1.6]\n",
      " [ 0.1 11.5]]\n",
      "run fg3_m12\n",
      "0.92 0.07999999999999996\n",
      "[[ 6.   1.7]\n",
      " [ 0.1 11.4]]\n",
      "run fg3_m12\n",
      "0.93 0.06999999999999995\n",
      "[[ 6.   1.8]\n",
      " [ 0.1 11.3]]\n",
      "run fg3_m12\n",
      "0.9400000000000001 0.05999999999999994\n",
      "[[ 6.   1.8]\n",
      " [ 0.1 11.3]]\n",
      "run fg3_m12\n",
      "0.9500000000000001 0.04999999999999993\n",
      "[[ 6.   2. ]\n",
      " [ 0.1 11.1]]\n",
      "run fg3_m12\n",
      "0.96 0.040000000000000036\n",
      "[[ 6.   2.4]\n",
      " [ 0.1 10.7]]\n",
      "run fg3_m12\n",
      "0.97 0.030000000000000027\n",
      "[[ 6.   2.7]\n",
      " [ 0.1 10.4]]\n",
      "run fg3_m12\n",
      "0.98 0.020000000000000018\n",
      "[[ 6.   2.9]\n",
      " [ 0.1 10.2]]\n",
      "run fg3_m12\n",
      "0.99 0.010000000000000009\n",
      "[[6.  3.4]\n",
      " [0.1 9.7]]\n",
      "run fg3_m12\n",
      "1.0 0.0\n",
      "[[ 6.1 13.1]\n",
      " [ 0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "'''This section is for testing if the LDA is sensitive to priors'''\n",
    "\n",
    "\n",
    "\n",
    "prior_1=np.linspace(0,1,101)\n",
    "print('prior_1', prior_1)\n",
    "#this is fraction nonmerg\n",
    "\n",
    "acc_12=[]\n",
    "fp_12=[]\n",
    "fn_12=[]\n",
    "\n",
    "\n",
    "for i in range(len(prior_1)):\n",
    "   \n",
    "    add_on='fg3_m12'#'fg3_m12'\n",
    "    print('run', add_on)\n",
    "\n",
    "\n",
    "    run=add_on\n",
    "    df = pd.io.parsers.read_table(\n",
    "        filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "        header=[0],\n",
    "        sep='\\t'\n",
    "        )#,skiprows=10,nrows=10\n",
    "    df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "    df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "    \n",
    "    for j in range(len(df)):\n",
    "        if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "            df.set_value(j,'class label',0.0)\n",
    "    \n",
    "    df.dropna(inplace=True) # to drop the empty line at file-end\n",
    "    #print(df)\n",
    "\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "    X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "    \n",
    "    from sklearn import preprocessing\n",
    "\n",
    "    \n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X)\n",
    "    X = std_scale.transform(X)\n",
    "    \n",
    "    n_params=6\n",
    "\n",
    "\n",
    "    y = df['class label'].values\n",
    "    \n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    label_encoder = enc.fit(y)\n",
    "    y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "    label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "    # LDA\n",
    "    '''sklearn_lda = LDA(priors=[prior_1[i],1-prior_1[i]])\n",
    "    X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "    dec = sklearn_lda.score(X,y)\n",
    "    prob = sklearn_lda.predict_proba(X)\n",
    "    \n",
    "    coef = sklearn_lda.coef_\n",
    "    inter = sklearn_lda.intercept_\n",
    "    class_label = sklearn_lda.classes_'''\n",
    "    \n",
    "    '''New method'''\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)#len(X))\n",
    "    \n",
    "    \n",
    "    kf.get_n_splits(X)\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    confusion_master=[]\n",
    "    count=0\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        sklearn_lda = LDA(priors=[prior_1[i],1-prior_1[i]], store_covariance=True)#store_covariance=False\n",
    "    \n",
    "    \n",
    "    \n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X_train, y_train)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        pred =sklearn_lda.predict(X_test)\n",
    "        \n",
    "        \n",
    "        confusion_master.append(confusion_matrix(pred,y_test))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(prior_1[i],1-prior_1[i])\n",
    "    print(np.mean(confusion_master, axis=0))\n",
    "    new_conf=np.mean(confusion_master, axis=0)\n",
    "    #print(new_conf[0][0], new_conf[1][1])\n",
    "    accuracy=(new_conf[0][0]+new_conf[1][1])/(np.sum(new_conf))\n",
    "    \n",
    "    \n",
    "   \n",
    "    #print('mean accuracy',dec)#mean accuracy on the given test data and labels.\n",
    "    acc_12.append(accuracy)\n",
    "    fp_12.append(new_conf[0][1]/(new_conf[0][0]+new_conf[1][0]+new_conf[0][1]+new_conf[1][1]))\n",
    "    fn_12.append(new_conf[1][0]/(new_conf[0][0]+new_conf[1][0]+new_conf[0][1]+new_conf[1][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAFhCAYAAABzg9PKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(prior_1, np.array(fp_13)-np.array(fn_13),  label='q0.333_fg0.1')\n",
    "plt.plot(prior_1, np.array(fp_12)-np.array(fn_12),  label='q0.5_fg0.3')\n",
    "plt.plot(prior_1, np.array(fp_15)-np.array(fn_15),  label='q0.2_fg0.3_BT0.2')\n",
    "plt.plot(prior_1, np.array(fp_10)-np.array(fn_10),  label='q0.1_fg0.3_BT0.2')\n",
    "plt.xlabel(r'$f_{\\mathrm{nonmerg}}$', size=15)\n",
    "plt.ylabel('Fraction False Positives', size=15)\n",
    "plt.axvline(x=0.9, ls='--', color='black')\n",
    "plt.axvline(x=0.7, ls='-.', color='black')\n",
    "plt.axhline(y=0, color='black')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(prior_1, acc_13,  label='q0.333_fg0.1')\n",
    "plt.plot(prior_1, acc_12,  label='q0.5_fg0.3')\n",
    "plt.plot(prior_1, acc_15,  label='q0.2_fg0.3_BT0.2')\n",
    "plt.plot(prior_1, acc_10,  label='q0.1_fg0.3_BT0.2')\n",
    "plt.xlabel(r'$f_{\\mathrm{nonmerg}}$', size=15)\n",
    "plt.ylabel('LDA Accuracy', size=15)\n",
    "plt.axvline(x=0.9, ls='--', color='black')\n",
    "plt.axvline(x=0.7, ls='-.', color='black')\n",
    "plt.legend()\n",
    "plt.xlim([0,1])\n",
    "#plt.show()\n",
    "plt.savefig('../MaNGA_Papers/Paper_I/insensitive_to_priors.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q0.5_fg0.3 vs q0.5_fg0.3 0.0\n",
      "q0.5_fg0.3 vs q0.333_fg0.1 35.00562395799082\n",
      "q0.5_fg0.3 vs q0.2_fg0.3 48.159754311711765\n",
      "q0.333_fg0.1 vs q0.5_fg0.3 35.00562395799082\n",
      "q0.333_fg0.1 vs q0.333_fg0.1 0.0\n",
      "q0.333_fg0.1 vs q0.2_fg0.3 22.585970746417956\n",
      "q0.2_fg0.3 vs q0.5_fg0.3 48.159754311711765\n",
      "q0.2_fg0.3 vs q0.333_fg0.1 22.585970746417956\n",
      "Domain error q0.2_fg0.3 vs q0.2_fg0.3\n",
      "q0.2_fg0.3 vs q0.2_fg0.3 22.585970746417956\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "fg3_m12_eig=[4.3,-0.7,1.4,3.2,-2.2,2.5,1.8]\n",
    "fg1_m13_eig=[3.0,-1.7,3.9,3.7,-2.7,-0.2,1.1]\n",
    "fg3_m15_eig=[14.0, -1.0, 24.4, 9.7, -14.0, -6.0, 6.2]\n",
    "\n",
    "list_names=[fg3_m12_eig,fg1_m13_eig,fg3_m15_eig]\n",
    "act_names=['q0.5_fg0.3','q0.333_fg0.1', 'q0.2_fg0.3']\n",
    "for x in range(len(list_names)):\n",
    "    for y in range(len(list_names)):\n",
    "        try:\n",
    "            exp=math.degrees(math.acos(np.dot(list_names[x],list_names[y])/(np.linalg.norm(list_names[x])*np.linalg.norm(list_names[y]))))\n",
    "        except ValueError:\n",
    "            print('Domain error', act_names[x], 'vs', act_names[y])\n",
    "        if exp <90:\n",
    "            expnow=exp\n",
    "        else:\n",
    "            expnow=abs(180-exp)\n",
    "        print(act_names[x], 'vs', act_names[y], expnow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.24905461]\n",
      " [-1.68091976]\n",
      " [ 6.11884828]\n",
      " [ 5.47198309]\n",
      " [ 4.60309771]\n",
      " [ 4.87954727]\n",
      " [ 4.17413156]\n",
      " [ 2.41719754]\n",
      " [ 2.97902972]\n",
      " [ 3.25976892]\n",
      " [ 3.36865114]\n",
      " [ 3.5545208 ]\n",
      " [ 3.75685733]\n",
      " [ 3.84589582]\n",
      " [-1.54500051]\n",
      " [-1.42974055]\n",
      " [ 4.22642622]\n",
      " [ 3.33484153]\n",
      " [ 3.81751928]\n",
      " [ 3.06943415]\n",
      " [ 3.27857911]\n",
      " [ 2.3236804 ]\n",
      " [ 4.03394623]\n",
      " [ 4.21368238]\n",
      " [ 3.49088418]\n",
      " [ 3.57496975]\n",
      " [ 3.95586172]\n",
      " [ 3.37118699]\n",
      " [-1.58020943]\n",
      " [-0.89848461]\n",
      " [ 4.14912498]\n",
      " [ 4.82284989]\n",
      " [ 3.81352123]\n",
      " [ 3.91659071]\n",
      " [ 3.85951445]\n",
      " [ 2.34015896]\n",
      " [ 2.63493089]\n",
      " [ 3.07472385]\n",
      " [ 3.9168378 ]\n",
      " [ 3.29674971]\n",
      " [ 3.6968283 ]\n",
      " [ 2.42648068]\n",
      " [-1.70062429]\n",
      " [-1.08279531]\n",
      " [ 4.64566041]\n",
      " [ 2.53592523]\n",
      " [ 3.69385845]\n",
      " [ 4.23612936]\n",
      " [ 4.19900727]\n",
      " [ 2.78530766]\n",
      " [ 4.36577064]\n",
      " [ 4.67723876]\n",
      " [ 4.62902936]\n",
      " [ 2.9028692 ]\n",
      " [ 3.9237619 ]\n",
      " [ 2.82556094]\n",
      " [-0.6409273 ]\n",
      " [-0.12130954]\n",
      " [ 5.06461006]\n",
      " [ 4.92248169]\n",
      " [ 2.81614121]\n",
      " [ 5.44111939]\n",
      " [ 3.62730409]\n",
      " [ 4.05635161]\n",
      " [ 3.83527829]\n",
      " [ 4.03960082]\n",
      " [ 3.73802247]\n",
      " [ 2.96499894]\n",
      " [ 2.22000116]\n",
      " [ 2.32899665]\n",
      " [-0.55000439]\n",
      " [ 0.44774166]\n",
      " [ 3.6365453 ]\n",
      " [ 4.26161378]\n",
      " [ 6.94232498]\n",
      " [ 5.45799833]\n",
      " [ 2.0121493 ]\n",
      " [ 1.65244679]\n",
      " [ 2.74577448]\n",
      " [ 2.16668699]\n",
      " [ 2.30086837]\n",
      " [ 1.57605309]\n",
      " [ 1.79350285]\n",
      " [ 2.41279288]\n",
      " [-0.63209532]\n",
      " [ 0.25435787]\n",
      " [ 4.49372681]\n",
      " [ 3.72761484]\n",
      " [ 2.83895246]\n",
      " [ 3.36051157]\n",
      " [ 1.82887468]\n",
      " [ 3.07686672]\n",
      " [ 3.7596658 ]\n",
      " [ 3.14380381]\n",
      " [ 3.7143936 ]\n",
      " [ 3.290735  ]\n",
      " [ 2.53883788]\n",
      " [ 1.54096777]]\n",
      "0.979591836735\n",
      "[[-25.68071472   0.03452496   5.58761818  31.85126869 -25.11539707\n",
      "    2.12714878   2.84596643  -5.44687753  16.13223911]]\n",
      "[-10.32850329]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# LDA\n",
    "sklearn_lda = LDA(priors=[0.8,0.2])\n",
    "X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "dec = sklearn_lda.score(X,y)\n",
    "print(X_lda_sklearn)\n",
    "coef = sklearn_lda.coef_\n",
    "inter = sklearn_lda.intercept_\n",
    "print(dec)\n",
    "print(coef)\n",
    "print(inter)\n",
    "\n",
    "#plot_scikit_lda(X_lda_sklearn, title='Default LDA via scikit-learn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_scikit_lda(X, title):\n",
    "\n",
    "    ax = plt.subplot(111)\n",
    "    for label,marker,color in zip(\n",
    "        range(1,4),('^', 's', 'o'),('blue', 'red', 'green')):\n",
    "\n",
    "        plt.scatter(x=X[:,0][y == label],\n",
    "                    y=0 * -1, # flip the figure\n",
    "                    marker=marker,\n",
    "                    color=color,\n",
    "                    alpha=0.5,\n",
    "                    label=label_dict[label])\n",
    "\n",
    "    plt.xlabel('LD1')\n",
    "    plt.ylabel('LD2')\n",
    "\n",
    "    leg = plt.legend(loc='upper right', fancybox=True)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    plt.title(title)\n",
    "\n",
    "    # hide axis ticks\n",
    "    plt.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "            labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\")\n",
    "\n",
    "    # remove axis spines\n",
    "    ax.spines[\"top\"].set_visible(False)  \n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "    plt.grid()\n",
    "    plt.tight_layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prior_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bb5ad6e21927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mpriors_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.94\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.06\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.85\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.06\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.94\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prior_list' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is to test how sensitive or insensitive the process is to the priors\n",
    "Priors vary:\n",
    "Lotz2011 f_merg = 15%\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "~~~\n",
    "Now just for the imaging part of it!\n",
    "~~~\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_mean_and_CI(mean, lb, ub, color_mean=None, color_shading=None):\n",
    "        # plot the shaded range of the confidence intervals\n",
    "        plt.fill_between(range(mean.shape[0]), ub, lb,\n",
    "                         color=color_shading, alpha=.5)\n",
    "        # plot the mean on top\n",
    "        plt.plot(mean, color_mean)\n",
    "\n",
    "\n",
    "feature_dict = {i:label for i,label in zip(\n",
    "                range(14),\n",
    "                  ('Counter',\n",
    "                  'Image',\n",
    "                  'class label',\n",
    "                  'Myr',\n",
    "                  'Viewpoint',\n",
    "                '# Bulges',\n",
    "                   'Sep',\n",
    "                   'Flux Ratio',\n",
    "                  'Gini',\n",
    "                  'M20',\n",
    "                  'Concentration (C)',\n",
    "                  'Asymmetry (A)',\n",
    "                  'Clumpiness (S)',\n",
    "                  'Sersic N',\n",
    "                  'Shape Asymmetry (A_S)'))}\n",
    "\n",
    "#Counter\tImage\tMerger (0 = no, 1 = yes)\tMyr\tViewpoint\tGini\tM20\tC\tA\tS\tSersic n\n",
    "'''view=0\n",
    "df = pd.io.parsers.read_table(\n",
    "    filepath_or_buffer='PCA_img_0.txt',\n",
    "    header=[0],\n",
    "    sep='\\t', skiprows=14*view,nrows=14\n",
    "    )#,skiprows=10,nrows=10'''\n",
    "\n",
    "\n",
    "#list_runs=['fg3_m_12','fg1_m_13']\n",
    "list_runs=['fg3_m12']#,'fg1_m13']#,'fg1_m13']\n",
    "priors_list=[[0.94,0.06],[0.85,0.15],[0.06,0.94],[0.999,0.001],[0.001,0.999]]\n",
    "\n",
    "for k in range(len(prior_list)):\n",
    "    for i in range(len(list_runs)):\n",
    "   \n",
    "        add_on=list_runs[i]\n",
    "        print('run', add_on)\n",
    "\n",
    "\n",
    "        run=list_runs[i]\n",
    "        df = pd.io.parsers.read_table(\n",
    "            filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',#filepath_or_buffer='LDA_img_ratio_'+str(run)+'_early_late_all_things.txt',#'_view_all.txt',\n",
    "            header=[0],\n",
    "            sep='\\t'\n",
    "            )#,skiprows=10,nrows=10\n",
    "        ##filepath_or_buffer='LDA_img_ratio_statmorph_'+str(run)+'.txt',#'_view_all.txt',\n",
    "\n",
    "        df.columns = [l for i,l in sorted(feature_dict.items())] + ['Shape Asymmetry']\n",
    "        df.dropna(how=\"all\", inplace=True) # to drop the empty line at file-end\n",
    "\n",
    "        for j in range(len(df)):\n",
    "            if df[['Myr']].values[j][0]<40 and df[['Sep']].values[j][0]==0.0 and df[['# Bulges']].values[j][0]==1:#df[['Myr']].values[i][0]\n",
    "\n",
    "\n",
    "                #I use this part to check if there is any separation at these points in time\n",
    "                #Or if there are more than two bulges\n",
    "                #print(df[['class label','Myr','Viewpoint','# Bulges', 'Sep']].values[j])\n",
    "\n",
    "                #Then, you can optionally change the class values of all of these viewpoints\n",
    "\n",
    "                #.set_value(index, col, value, \n",
    "                df.set_value(j,'class label',0.0)\n",
    "\n",
    "\n",
    "\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "        X = df[['Gini','M20','Concentration (C)', 'Asymmetry (A)', 'Clumpiness (S)', 'Sersic N', 'Shape Asymmetry']].values\n",
    "\n",
    "        from sklearn import preprocessing\n",
    "\n",
    "        #print('X before norm', X)\n",
    "\n",
    "        std_scale = preprocessing.StandardScaler().fit(X)\n",
    "        X = std_scale.transform(X)\n",
    "        #print('X after norm', X)\n",
    "\n",
    "        n_params=7\n",
    "\n",
    "\n",
    "        y = df['class label'].values\n",
    "\n",
    "\n",
    "        enc = LabelEncoder()\n",
    "        label_encoder = enc.fit(y)\n",
    "        y = label_encoder.transform(y) + 1\n",
    "\n",
    "\n",
    "        label_dict = {1: 'NonMerger', 2: 'Merger'}\n",
    "        from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "        # LDA\n",
    "        sklearn_lda = LDA(priors=priors_list[k])\n",
    "        X_lda_sklearn = sklearn_lda.fit_transform(X, y)\n",
    "        dec = sklearn_lda.score(X,y)\n",
    "        prob = sklearn_lda.predict_proba(X)\n",
    "\n",
    "        coef = sklearn_lda.coef_\n",
    "        inter = sklearn_lda.intercept_\n",
    "        class_label = sklearn_lda.classes_\n",
    "\n",
    "        print('~~~Coefficients and Intercepts~~~')\n",
    "        print(coef,inter)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        print('priors', priors_list[k])\n",
    "        print('mean accuracy',dec)#mean accuracy on the given test data and labels.\n",
    "\n",
    "        print(inter)\n",
    "        '''Make a histogram'''\n",
    "        from scipy import stats\n",
    "        import seaborn as sns\n",
    "        plt.clf()\n",
    "        fig = plt.figure(figsize=(18,10))\n",
    "        ax = fig.add_subplot(111)\n",
    "        X_lda_1=[]\n",
    "        X_lda_2=[]\n",
    "        for j in range(len(X_lda_sklearn)):\n",
    "            if y[j] ==1:\n",
    "                X_lda_1.append(X_lda_sklearn[j][0])\n",
    "            else:\n",
    "                X_lda_2.append(X_lda_sklearn[j][0])\n",
    "        input_hist=X_lda_sklearn\n",
    "\n",
    "        ax.hist(X_lda_1, label='NonMerger',  color=sns.xkcd_rgb[\"sky blue\"],alpha = 0.75)\n",
    "        ax.hist(X_lda_2, label='Merger',  color=sns.xkcd_rgb[\"salmon\"],alpha = 0.75)\n",
    "\n",
    "        '''for label,col in zip(range(1,4),  ('blue', 'red')):\n",
    "            input_hist=X_lda_sklearn\n",
    "            input_all=X_lda_sklearn\n",
    "            ax.hist(input_hist,\n",
    "                           color=col,\n",
    "                           label='class %s' %label_dict[label],\n",
    "                           alpha=0.5,)#bins=bins,\n",
    "            xt = plt.xticks()[0]  \n",
    "            xmin, xmax = -0.1,0.7#min(xt), max(xt)  \n",
    "            lnspc = np.linspace(xmin, xmax, len(input_hist))\n",
    "\n",
    "            # lets try the normal distribution first\n",
    "            m, s = stats.norm.fit(input_hist) # get mean and standard deviation  \n",
    "            pdf_g = stats.norm.pdf(lnspc, m, s) # now get theoretical values in our interval  \n",
    "            #ax.plot(lnspc, pdf_g,  color=col) # plot it\n",
    "\n",
    "\n",
    "\n",
    "        ylims = ax.get_ylim()\n",
    "\n",
    "        # plot annotation\n",
    "        leg = ax.legend(loc='upper right', fancybox=True, fontsize=8)\n",
    "        leg.get_frame().set_alpha(0.5)\n",
    "        ax.set_ylim([0, max(ylims)+2])'''\n",
    "\n",
    "        ax.set_xlabel('LD1', size=20)\n",
    "        #ax.set_title('Histogram #%s' %str(cnt+1), size=20)\n",
    "\n",
    "        # hide axis ticks\n",
    "        ax.tick_params(axis=\"both\", which=\"both\", bottom=\"off\", top=\"off\",  \n",
    "                labelbottom=\"on\", left=\"off\", right=\"off\", labelleft=\"on\", labelsize=20)\n",
    "\n",
    "        # remove axis spines\n",
    "        ax.spines[\"top\"].set_visible(False)  \n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.spines[\"bottom\"].set_visible(False)\n",
    "        ax.spines[\"left\"].set_visible(False)    \n",
    "\n",
    "        ax.set_ylabel('Count', size=20)\n",
    "\n",
    "\n",
    "        plt.legend(loc=\"upper right\", fontsize=20)\n",
    "        #fig.tight_layout() \n",
    "        #plt.annotate(str(add_on), xy=(0.02,0.95),xycoords='axes fraction', size=20)\n",
    "        #plt.annotate('Mean Accuracy = '+str(dec), xy=(0.02,0.9),xycoords='axes fraction', size=20)\n",
    "        #frame1 = plt.gca()\n",
    "        if run=='fg1_m_13':\n",
    "            plt.title('FG1M13')\n",
    "        if run=='fg3_m12':\n",
    "            plt.title('FG3M12')\n",
    "        plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
